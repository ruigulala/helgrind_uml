--- linux-2.6.22.5-old/arch/um/include/valgrind.h	1969-12-31 16:00:00.000000000 -0800
+++ linux-2.6.22.5/arch/um/include/valgrind.h	2007-12-18 08:11:46.000000000 -0800
@@ -0,0 +1,3947 @@
+/* -*- c -*-
+   ----------------------------------------------------------------
+
+   Notice that the following BSD-style license applies to this one
+   file (valgrind.h) only.  The rest of Valgrind is licensed under the
+   terms of the GNU General Public License, version 2, unless
+   otherwise indicated.  See the COPYING file in the source
+   distribution for details.
+
+   ----------------------------------------------------------------
+
+   This file is part of Valgrind, a dynamic binary instrumentation
+   framework.
+
+   Copyright (C) 2000-2007 Julian Seward.  All rights reserved.
+
+   Redistribution and use in source and binary forms, with or without
+   modification, are permitted provided that the following conditions
+   are met:
+
+   1. Redistributions of source code must retain the above copyright
+      notice, this list of conditions and the following disclaimer.
+
+   2. The origin of this software must not be misrepresented; you must 
+      not claim that you wrote the original software.  If you use this 
+      software in a product, an acknowledgment in the product 
+      documentation would be appreciated but is not required.
+
+   3. Altered source versions must be plainly marked as such, and must
+      not be misrepresented as being the original software.
+
+   4. The name of the author may not be used to endorse or promote 
+      products derived from this software without specific prior written 
+      permission.
+
+   THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS
+   OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+   WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+   ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+   DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+   DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE
+   GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+   INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+   WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+   NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+   SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+   ----------------------------------------------------------------
+
+   Notice that the above BSD-style license applies to this one file
+   (valgrind.h) only.  The entire rest of Valgrind is licensed under
+   the terms of the GNU General Public License, version 2.  See the
+   COPYING file in the source distribution for details.
+
+   ---------------------------------------------------------------- 
+*/
+
+
+/* This file is for inclusion into client (your!) code.
+
+   You can use these macros to manipulate and query Valgrind's 
+   execution inside your own programs.
+
+   The resulting executables will still run without Valgrind, just a
+   little bit more slowly than they otherwise would, but otherwise
+   unchanged.  When not running on valgrind, each client request
+   consumes very few (eg. 7) instructions, so the resulting performance
+   loss is negligible unless you plan to execute client requests
+   millions of times per second.  Nevertheless, if that is still a
+   problem, you can compile with the NVALGRIND symbol defined (gcc
+   -DNVALGRIND) so that client requests are not even compiled in.  */
+
+#ifndef __VALGRIND_H
+#define __VALGRIND_H
+
+#include <stdarg.h>
+
+/* Nb: this file might be included in a file compiled with -ansi.  So
+   we can't use C++ style "//" comments nor the "asm" keyword (instead
+   use "__asm__"). */
+
+/* Derive some tags indicating what the target platform is.  Note
+   that in this file we're using the compiler's CPP symbols for
+   identifying architectures, which are different to the ones we use
+   within the rest of Valgrind.  Note, __powerpc__ is active for both
+   32 and 64-bit PPC, whereas __powerpc64__ is only active for the
+   latter (on Linux, that is). */
+#undef PLAT_x86_linux
+#undef PLAT_amd64_linux
+#undef PLAT_ppc32_linux
+#undef PLAT_ppc64_linux
+#undef PLAT_ppc32_aix5
+#undef PLAT_ppc64_aix5
+
+#if defined(__arch_um__)
+#  define PLAT_x86_linux 1
+#else  /*{*/
+#  if !defined(_AIX) && defined(__i386__)
+#    define PLAT_x86_linux 1
+#  elif !defined(_AIX) && defined(__x86_64__)
+#    define PLAT_amd64_linux 1
+#  elif !defined(_AIX) && defined(__powerpc__) && !defined(__powerpc64__)
+#    define PLAT_ppc32_linux 1
+#  elif !defined(_AIX) && defined(__powerpc__) && defined(__powerpc64__)
+#    define PLAT_ppc64_linux 1
+#  elif defined(_AIX) && defined(__64BIT__)
+#    define PLAT_ppc64_aix5 1
+#  elif defined(_AIX) && !defined(__64BIT__)
+#    define PLAT_ppc32_aix5 1
+#  endif
+#endif  /*}*/
+
+
+/* If we're not compiling for our target platform, don't generate
+   any inline asms.  */
+#if !defined(PLAT_x86_linux) && !defined(PLAT_amd64_linux) \
+    && !defined(PLAT_ppc32_linux) && !defined(PLAT_ppc64_linux) \
+    && !defined(PLAT_ppc32_aix5) && !defined(PLAT_ppc64_aix5)
+#  if !defined(NVALGRIND)
+#    define NVALGRIND 1
+#  endif
+#endif
+
+
+/* ------------------------------------------------------------------ */
+/* ARCHITECTURE SPECIFICS for SPECIAL INSTRUCTIONS.  There is nothing */
+/* in here of use to end-users -- skip to the next section.           */
+/* ------------------------------------------------------------------ */
+
+#if defined(NVALGRIND)
+
+/* Define NVALGRIND to completely remove the Valgrind magic sequence
+   from the compiled code (analogous to NDEBUG's effects on
+   assert()) */
+#define VALGRIND_DO_CLIENT_REQUEST(                               \
+        _zzq_rlval, _zzq_default, _zzq_request,                   \
+        _zzq_arg1, _zzq_arg2, _zzq_arg3, _zzq_arg4, _zzq_arg5)    \
+   {                                                              \
+      (_zzq_rlval) = (_zzq_default);                              \
+   }
+
+#else  /* ! NVALGRIND */
+
+/* The following defines the magic code sequences which the JITter
+   spots and handles magically.  Don't look too closely at them as
+   they will rot your brain.
+
+   The assembly code sequences for all architectures is in this one
+   file.  This is because this file must be stand-alone, and we don't
+   want to have multiple files.
+
+   For VALGRIND_DO_CLIENT_REQUEST, we must ensure that the default
+   value gets put in the return slot, so that everything works when
+   this is executed not under Valgrind.  Args are passed in a memory
+   block, and so there's no intrinsic limit to the number that could
+   be passed, but it's currently five.
+   
+   The macro args are: 
+      _zzq_rlval    result lvalue
+      _zzq_default  default value (result returned when running on real CPU)
+      _zzq_request  request code
+      _zzq_arg1..5  request params
+
+   The other two macros are used to support function wrapping, and are
+   a lot simpler.  VALGRIND_GET_NR_CONTEXT returns the value of the
+   guest's NRADDR pseudo-register and whatever other information is
+   needed to safely run the call original from the wrapper: on
+   ppc64-linux, the R2 value at the divert point is also needed.  This
+   information is abstracted into a user-visible type, OrigFn.
+
+   VALGRIND_CALL_NOREDIR_* behaves the same as the following on the
+   guest, but guarantees that the branch instruction will not be
+   redirected: x86: call *%eax, amd64: call *%rax, ppc32/ppc64:
+   branch-and-link-to-r11.  VALGRIND_CALL_NOREDIR is just text, not a
+   complete inline asm, since it needs to be combined with more magic
+   inline asm stuff to be useful.
+*/
+
+/* ------------------------- x86-linux ------------------------- */
+
+#if defined(PLAT_x86_linux)
+
+typedef
+   struct { 
+      unsigned int nraddr; /* where's the code? */
+   }
+   OrigFn;
+
+#define __SPECIAL_INSTRUCTION_PREAMBLE                            \
+                     "roll $3,  %%edi ; roll $13, %%edi\n\t"      \
+                     "roll $29, %%edi ; roll $19, %%edi\n\t"
+
+#define VALGRIND_DO_CLIENT_REQUEST(                               \
+        _zzq_rlval, _zzq_default, _zzq_request,                   \
+        _zzq_arg1, _zzq_arg2, _zzq_arg3, _zzq_arg4, _zzq_arg5)    \
+  { volatile unsigned int _zzq_args[6];                           \
+    volatile unsigned int _zzq_result;                            \
+    _zzq_args[0] = (unsigned int)(_zzq_request);                  \
+    _zzq_args[1] = (unsigned int)(_zzq_arg1);                     \
+    _zzq_args[2] = (unsigned int)(_zzq_arg2);                     \
+    _zzq_args[3] = (unsigned int)(_zzq_arg3);                     \
+    _zzq_args[4] = (unsigned int)(_zzq_arg4);                     \
+    _zzq_args[5] = (unsigned int)(_zzq_arg5);                     \
+    __asm__ volatile(__SPECIAL_INSTRUCTION_PREAMBLE               \
+                     /* %EDX = client_request ( %EAX ) */         \
+                     "xchgl %%ebx,%%ebx"                          \
+                     : "=d" (_zzq_result)                         \
+                     : "a" (&_zzq_args[0]), "0" (_zzq_default)    \
+                     : "cc", "memory"                             \
+                    );                                            \
+    _zzq_rlval = _zzq_result;                                     \
+  }
+
+#define VALGRIND_GET_NR_CONTEXT(_zzq_rlval)                       \
+  { volatile OrigFn* _zzq_orig = &(_zzq_rlval);                   \
+    volatile unsigned int __addr;                                 \
+    __asm__ volatile(__SPECIAL_INSTRUCTION_PREAMBLE               \
+                     /* %EAX = guest_NRADDR */                    \
+                     "xchgl %%ecx,%%ecx"                          \
+                     : "=a" (__addr)                              \
+                     :                                            \
+                     : "cc", "memory"                             \
+                    );                                            \
+    _zzq_orig->nraddr = __addr;                                   \
+  }
+
+#define VALGRIND_CALL_NOREDIR_EAX                                 \
+                     __SPECIAL_INSTRUCTION_PREAMBLE               \
+                     /* call-noredir *%EAX */                     \
+                     "xchgl %%edx,%%edx\n\t"
+#endif /* PLAT_x86_linux */
+
+/* ------------------------ amd64-linux ------------------------ */
+
+#if defined(PLAT_amd64_linux)
+
+typedef
+   struct { 
+      unsigned long long int nraddr; /* where's the code? */
+   }
+   OrigFn;
+
+#define __SPECIAL_INSTRUCTION_PREAMBLE                            \
+                     "rolq $3,  %%rdi ; rolq $13, %%rdi\n\t"      \
+                     "rolq $61, %%rdi ; rolq $51, %%rdi\n\t"
+
+#define VALGRIND_DO_CLIENT_REQUEST(                               \
+        _zzq_rlval, _zzq_default, _zzq_request,                   \
+        _zzq_arg1, _zzq_arg2, _zzq_arg3, _zzq_arg4, _zzq_arg5)    \
+  { volatile unsigned long long int _zzq_args[6];                 \
+    volatile unsigned long long int _zzq_result;                  \
+    _zzq_args[0] = (unsigned long long int)(_zzq_request);        \
+    _zzq_args[1] = (unsigned long long int)(_zzq_arg1);           \
+    _zzq_args[2] = (unsigned long long int)(_zzq_arg2);           \
+    _zzq_args[3] = (unsigned long long int)(_zzq_arg3);           \
+    _zzq_args[4] = (unsigned long long int)(_zzq_arg4);           \
+    _zzq_args[5] = (unsigned long long int)(_zzq_arg5);           \
+    __asm__ volatile(__SPECIAL_INSTRUCTION_PREAMBLE               \
+                     /* %RDX = client_request ( %RAX ) */         \
+                     "xchgq %%rbx,%%rbx"                          \
+                     : "=d" (_zzq_result)                         \
+                     : "a" (&_zzq_args[0]), "0" (_zzq_default)    \
+                     : "cc", "memory"                             \
+                    );                                            \
+    _zzq_rlval = _zzq_result;                                     \
+  }
+
+#define VALGRIND_GET_NR_CONTEXT(_zzq_rlval)                       \
+  { volatile OrigFn* _zzq_orig = &(_zzq_rlval);                   \
+    volatile unsigned long long int __addr;                       \
+    __asm__ volatile(__SPECIAL_INSTRUCTION_PREAMBLE               \
+                     /* %RAX = guest_NRADDR */                    \
+                     "xchgq %%rcx,%%rcx"                          \
+                     : "=a" (__addr)                              \
+                     :                                            \
+                     : "cc", "memory"                             \
+                    );                                            \
+    _zzq_orig->nraddr = __addr;                                   \
+  }
+
+#define VALGRIND_CALL_NOREDIR_RAX                                 \
+                     __SPECIAL_INSTRUCTION_PREAMBLE               \
+                     /* call-noredir *%RAX */                     \
+                     "xchgq %%rdx,%%rdx\n\t"
+#endif /* PLAT_amd64_linux */
+
+/* ------------------------ ppc32-linux ------------------------ */
+
+#if defined(PLAT_ppc32_linux)
+
+typedef
+   struct { 
+      unsigned int nraddr; /* where's the code? */
+   }
+   OrigFn;
+
+#define __SPECIAL_INSTRUCTION_PREAMBLE                            \
+                     "rlwinm 0,0,3,0,0  ; rlwinm 0,0,13,0,0\n\t"  \
+                     "rlwinm 0,0,29,0,0 ; rlwinm 0,0,19,0,0\n\t"
+
+#define VALGRIND_DO_CLIENT_REQUEST(                               \
+        _zzq_rlval, _zzq_default, _zzq_request,                   \
+        _zzq_arg1, _zzq_arg2, _zzq_arg3, _zzq_arg4, _zzq_arg5)    \
+                                                                  \
+  {          unsigned int  _zzq_args[6];                          \
+             unsigned int  _zzq_result;                           \
+             unsigned int* _zzq_ptr;                              \
+    _zzq_args[0] = (unsigned int)(_zzq_request);                  \
+    _zzq_args[1] = (unsigned int)(_zzq_arg1);                     \
+    _zzq_args[2] = (unsigned int)(_zzq_arg2);                     \
+    _zzq_args[3] = (unsigned int)(_zzq_arg3);                     \
+    _zzq_args[4] = (unsigned int)(_zzq_arg4);                     \
+    _zzq_args[5] = (unsigned int)(_zzq_arg5);                     \
+    _zzq_ptr = _zzq_args;                                         \
+    __asm__ volatile("mr 3,%1\n\t" /*default*/                    \
+                     "mr 4,%2\n\t" /*ptr*/                        \
+                     __SPECIAL_INSTRUCTION_PREAMBLE               \
+                     /* %R3 = client_request ( %R4 ) */           \
+                     "or 1,1,1\n\t"                               \
+                     "mr %0,3"     /*result*/                     \
+                     : "=b" (_zzq_result)                         \
+                     : "b" (_zzq_default), "b" (_zzq_ptr)         \
+                     : "cc", "memory", "r3", "r4");               \
+    _zzq_rlval = _zzq_result;                                     \
+  }
+
+#define VALGRIND_GET_NR_CONTEXT(_zzq_rlval)                       \
+  { volatile OrigFn* _zzq_orig = &(_zzq_rlval);                   \
+    unsigned int __addr;                                          \
+    __asm__ volatile(__SPECIAL_INSTRUCTION_PREAMBLE               \
+                     /* %R3 = guest_NRADDR */                     \
+                     "or 2,2,2\n\t"                               \
+                     "mr %0,3"                                    \
+                     : "=b" (__addr)                              \
+                     :                                            \
+                     : "cc", "memory", "r3"                       \
+                    );                                            \
+    _zzq_orig->nraddr = __addr;                                   \
+  }
+
+#define VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                   \
+                     __SPECIAL_INSTRUCTION_PREAMBLE               \
+                     /* branch-and-link-to-noredir *%R11 */       \
+                     "or 3,3,3\n\t"
+#endif /* PLAT_ppc32_linux */
+
+/* ------------------------ ppc64-linux ------------------------ */
+
+#if defined(PLAT_ppc64_linux)
+
+typedef
+   struct { 
+      unsigned long long int nraddr; /* where's the code? */
+      unsigned long long int r2;  /* what tocptr do we need? */
+   }
+   OrigFn;
+
+#define __SPECIAL_INSTRUCTION_PREAMBLE                            \
+                     "rotldi 0,0,3  ; rotldi 0,0,13\n\t"          \
+                     "rotldi 0,0,61 ; rotldi 0,0,51\n\t"
+
+#define VALGRIND_DO_CLIENT_REQUEST(                               \
+        _zzq_rlval, _zzq_default, _zzq_request,                   \
+        _zzq_arg1, _zzq_arg2, _zzq_arg3, _zzq_arg4, _zzq_arg5)    \
+                                                                  \
+  {          unsigned long long int  _zzq_args[6];                \
+    register unsigned long long int  _zzq_result __asm__("r3");   \
+    register unsigned long long int* _zzq_ptr __asm__("r4");      \
+    _zzq_args[0] = (unsigned long long int)(_zzq_request);        \
+    _zzq_args[1] = (unsigned long long int)(_zzq_arg1);           \
+    _zzq_args[2] = (unsigned long long int)(_zzq_arg2);           \
+    _zzq_args[3] = (unsigned long long int)(_zzq_arg3);           \
+    _zzq_args[4] = (unsigned long long int)(_zzq_arg4);           \
+    _zzq_args[5] = (unsigned long long int)(_zzq_arg5);           \
+    _zzq_ptr = _zzq_args;                                         \
+    __asm__ volatile(__SPECIAL_INSTRUCTION_PREAMBLE               \
+                     /* %R3 = client_request ( %R4 ) */           \
+                     "or 1,1,1"                                   \
+                     : "=r" (_zzq_result)                         \
+                     : "0" (_zzq_default), "r" (_zzq_ptr)         \
+                     : "cc", "memory");                           \
+    _zzq_rlval = _zzq_result;                                     \
+  }
+
+#define VALGRIND_GET_NR_CONTEXT(_zzq_rlval)                       \
+  { volatile OrigFn* _zzq_orig = &(_zzq_rlval);                   \
+    register unsigned long long int __addr __asm__("r3");         \
+    __asm__ volatile(__SPECIAL_INSTRUCTION_PREAMBLE               \
+                     /* %R3 = guest_NRADDR */                     \
+                     "or 2,2,2"                                   \
+                     : "=r" (__addr)                              \
+                     :                                            \
+                     : "cc", "memory"                             \
+                    );                                            \
+    _zzq_orig->nraddr = __addr;                                   \
+    __asm__ volatile(__SPECIAL_INSTRUCTION_PREAMBLE               \
+                     /* %R3 = guest_NRADDR_GPR2 */                \
+                     "or 4,4,4"                                   \
+                     : "=r" (__addr)                              \
+                     :                                            \
+                     : "cc", "memory"                             \
+                    );                                            \
+    _zzq_orig->r2 = __addr;                                       \
+  }
+
+#define VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                   \
+                     __SPECIAL_INSTRUCTION_PREAMBLE               \
+                     /* branch-and-link-to-noredir *%R11 */       \
+                     "or 3,3,3\n\t"
+
+#endif /* PLAT_ppc64_linux */
+
+/* ------------------------ ppc32-aix5 ------------------------- */
+
+#if defined(PLAT_ppc32_aix5)
+
+typedef
+   struct { 
+      unsigned int nraddr; /* where's the code? */
+      unsigned int r2;  /* what tocptr do we need? */
+   }
+   OrigFn;
+
+#define __SPECIAL_INSTRUCTION_PREAMBLE                            \
+                     "rlwinm 0,0,3,0,0  ; rlwinm 0,0,13,0,0\n\t"  \
+                     "rlwinm 0,0,29,0,0 ; rlwinm 0,0,19,0,0\n\t"
+
+#define VALGRIND_DO_CLIENT_REQUEST(                               \
+        _zzq_rlval, _zzq_default, _zzq_request,                   \
+        _zzq_arg1, _zzq_arg2, _zzq_arg3, _zzq_arg4, _zzq_arg5)    \
+                                                                  \
+  {          unsigned int  _zzq_args[7];                          \
+    register unsigned int  _zzq_result;                           \
+    register unsigned int* _zzq_ptr;                              \
+    _zzq_args[0] = (unsigned int)(_zzq_request);                  \
+    _zzq_args[1] = (unsigned int)(_zzq_arg1);                     \
+    _zzq_args[2] = (unsigned int)(_zzq_arg2);                     \
+    _zzq_args[3] = (unsigned int)(_zzq_arg3);                     \
+    _zzq_args[4] = (unsigned int)(_zzq_arg4);                     \
+    _zzq_args[5] = (unsigned int)(_zzq_arg5);                     \
+    _zzq_args[6] = (unsigned int)(_zzq_default);                  \
+    _zzq_ptr = _zzq_args;                                         \
+    __asm__ volatile("mr 4,%1\n\t"                                \
+                     "lwz 3, 24(4)\n\t"                           \
+                     __SPECIAL_INSTRUCTION_PREAMBLE               \
+                     /* %R3 = client_request ( %R4 ) */           \
+                     "or 1,1,1\n\t"                               \
+                     "mr %0,3"                                    \
+                     : "=b" (_zzq_result)                         \
+                     : "b" (_zzq_ptr)                             \
+                     : "r3", "r4", "cc", "memory");               \
+    _zzq_rlval = _zzq_result;                                     \
+  }
+
+#define VALGRIND_GET_NR_CONTEXT(_zzq_rlval)                       \
+  { volatile OrigFn* _zzq_orig = &(_zzq_rlval);                   \
+    register unsigned int __addr;                                 \
+    __asm__ volatile(__SPECIAL_INSTRUCTION_PREAMBLE               \
+                     /* %R3 = guest_NRADDR */                     \
+                     "or 2,2,2\n\t"                               \
+                     "mr %0,3"                                    \
+                     : "=b" (__addr)                              \
+                     :                                            \
+                     : "r3", "cc", "memory"                       \
+                    );                                            \
+    _zzq_orig->nraddr = __addr;                                   \
+    __asm__ volatile(__SPECIAL_INSTRUCTION_PREAMBLE               \
+                     /* %R3 = guest_NRADDR_GPR2 */                \
+                     "or 4,4,4\n\t"                               \
+                     "mr %0,3"                                    \
+                     : "=b" (__addr)                              \
+                     :                                            \
+                     : "r3", "cc", "memory"                       \
+                    );                                            \
+    _zzq_orig->r2 = __addr;                                       \
+  }
+
+#define VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                   \
+                     __SPECIAL_INSTRUCTION_PREAMBLE               \
+                     /* branch-and-link-to-noredir *%R11 */       \
+                     "or 3,3,3\n\t"
+
+#endif /* PLAT_ppc32_aix5 */
+
+/* ------------------------ ppc64-aix5 ------------------------- */
+
+#if defined(PLAT_ppc64_aix5)
+
+typedef
+   struct { 
+      unsigned long long int nraddr; /* where's the code? */
+      unsigned long long int r2;  /* what tocptr do we need? */
+   }
+   OrigFn;
+
+#define __SPECIAL_INSTRUCTION_PREAMBLE                            \
+                     "rotldi 0,0,3  ; rotldi 0,0,13\n\t"          \
+                     "rotldi 0,0,61 ; rotldi 0,0,51\n\t"
+
+#define VALGRIND_DO_CLIENT_REQUEST(                               \
+        _zzq_rlval, _zzq_default, _zzq_request,                   \
+        _zzq_arg1, _zzq_arg2, _zzq_arg3, _zzq_arg4, _zzq_arg5)    \
+                                                                  \
+  {          unsigned long long int  _zzq_args[7];                \
+    register unsigned long long int  _zzq_result;                 \
+    register unsigned long long int* _zzq_ptr;                    \
+    _zzq_args[0] = (unsigned int long long)(_zzq_request);        \
+    _zzq_args[1] = (unsigned int long long)(_zzq_arg1);           \
+    _zzq_args[2] = (unsigned int long long)(_zzq_arg2);           \
+    _zzq_args[3] = (unsigned int long long)(_zzq_arg3);           \
+    _zzq_args[4] = (unsigned int long long)(_zzq_arg4);           \
+    _zzq_args[5] = (unsigned int long long)(_zzq_arg5);           \
+    _zzq_args[6] = (unsigned int long long)(_zzq_default);        \
+    _zzq_ptr = _zzq_args;                                         \
+    __asm__ volatile("mr 4,%1\n\t"                                \
+                     "ld 3, 48(4)\n\t"                            \
+                     __SPECIAL_INSTRUCTION_PREAMBLE               \
+                     /* %R3 = client_request ( %R4 ) */           \
+                     "or 1,1,1\n\t"                               \
+                     "mr %0,3"                                    \
+                     : "=b" (_zzq_result)                         \
+                     : "b" (_zzq_ptr)                             \
+                     : "r3", "r4", "cc", "memory");               \
+    _zzq_rlval = _zzq_result;                                     \
+  }
+
+#define VALGRIND_GET_NR_CONTEXT(_zzq_rlval)                       \
+  { volatile OrigFn* _zzq_orig = &(_zzq_rlval);                   \
+    register unsigned long long int __addr;                       \
+    __asm__ volatile(__SPECIAL_INSTRUCTION_PREAMBLE               \
+                     /* %R3 = guest_NRADDR */                     \
+                     "or 2,2,2\n\t"                               \
+                     "mr %0,3"                                    \
+                     : "=b" (__addr)                              \
+                     :                                            \
+                     : "r3", "cc", "memory"                       \
+                    );                                            \
+    _zzq_orig->nraddr = __addr;                                   \
+    __asm__ volatile(__SPECIAL_INSTRUCTION_PREAMBLE               \
+                     /* %R3 = guest_NRADDR_GPR2 */                \
+                     "or 4,4,4\n\t"                               \
+                     "mr %0,3"                                    \
+                     : "=b" (__addr)                              \
+                     :                                            \
+                     : "r3", "cc", "memory"                       \
+                    );                                            \
+    _zzq_orig->r2 = __addr;                                       \
+  }
+
+#define VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                   \
+                     __SPECIAL_INSTRUCTION_PREAMBLE               \
+                     /* branch-and-link-to-noredir *%R11 */       \
+                     "or 3,3,3\n\t"
+
+#endif /* PLAT_ppc64_aix5 */
+
+/* Insert assembly code for other platforms here... */
+
+#endif /* NVALGRIND */
+
+
+/* ------------------------------------------------------------------ */
+/* PLATFORM SPECIFICS for FUNCTION WRAPPING.  This is all very        */
+/* ugly.  It's the least-worst tradeoff I can think of.               */
+/* ------------------------------------------------------------------ */
+
+/* This section defines magic (a.k.a appalling-hack) macros for doing
+   guaranteed-no-redirection macros, so as to get from function
+   wrappers to the functions they are wrapping.  The whole point is to
+   construct standard call sequences, but to do the call itself with a
+   special no-redirect call pseudo-instruction that the JIT
+   understands and handles specially.  This section is long and
+   repetitious, and I can't see a way to make it shorter.
+
+   The naming scheme is as follows:
+
+      CALL_FN_{W,v}_{v,W,WW,WWW,WWWW,5W,6W,7W,etc}
+
+   'W' stands for "word" and 'v' for "void".  Hence there are
+   different macros for calling arity 0, 1, 2, 3, 4, etc, functions,
+   and for each, the possibility of returning a word-typed result, or
+   no result.
+*/
+
+/* Use these to write the name of your wrapper.  NOTE: duplicates
+   VG_WRAP_FUNCTION_Z{U,Z} in pub_tool_redir.h. */
+
+#define I_WRAP_SONAME_FNNAME_ZU(soname,fnname)                    \
+   _vgwZU_##soname##_##fnname
+
+#define I_WRAP_SONAME_FNNAME_ZZ(soname,fnname)                    \
+   _vgwZZ_##soname##_##fnname
+
+/* Use this macro from within a wrapper function to collect the
+   context (address and possibly other info) of the original function.
+   Once you have that you can then use it in one of the CALL_FN_
+   macros.  The type of the argument _lval is OrigFn. */
+#define VALGRIND_GET_ORIG_FN(_lval)  VALGRIND_GET_NR_CONTEXT(_lval)
+
+/* Derivatives of the main macros below, for calling functions
+   returning void. */
+
+#define CALL_FN_v_v(fnptr)                                        \
+   do { volatile unsigned long _junk;                             \
+        CALL_FN_W_v(_junk,fnptr); } while (0)
+
+#define CALL_FN_v_W(fnptr, arg1)                                  \
+   do { volatile unsigned long _junk;                             \
+        CALL_FN_W_W(_junk,fnptr,arg1); } while (0)
+
+#define CALL_FN_v_WW(fnptr, arg1,arg2)                            \
+   do { volatile unsigned long _junk;                             \
+        CALL_FN_W_WW(_junk,fnptr,arg1,arg2); } while (0)
+
+#define CALL_FN_v_WWW(fnptr, arg1,arg2,arg3)                      \
+   do { volatile unsigned long _junk;                             \
+        CALL_FN_W_WWW(_junk,fnptr,arg1,arg2,arg3); } while (0)
+
+/* ------------------------- x86-linux ------------------------- */
+
+#if defined(PLAT_x86_linux)
+
+/* These regs are trashed by the hidden call.  No need to mention eax
+   as gcc can already see that, plus causes gcc to bomb. */
+#define __CALLER_SAVED_REGS /*"eax"*/ "ecx", "edx"
+
+/* These CALL_FN_ macros assume that on x86-linux, sizeof(unsigned
+   long) == 4. */
+
+#define CALL_FN_W_v(lval, orig)                                   \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[1];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      __asm__ volatile(                                           \
+         "movl (%%eax), %%eax\n\t"  /* target->%eax */            \
+         VALGRIND_CALL_NOREDIR_EAX                                \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_W(lval, orig, arg1)                             \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[2];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      __asm__ volatile(                                           \
+         "pushl 4(%%eax)\n\t"                                     \
+         "movl (%%eax), %%eax\n\t"  /* target->%eax */            \
+         VALGRIND_CALL_NOREDIR_EAX                                \
+         "addl $4, %%esp\n"                                       \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_WW(lval, orig, arg1,arg2)                       \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      _argvec[2] = (unsigned long)(arg2);                         \
+      __asm__ volatile(                                           \
+         "pushl 8(%%eax)\n\t"                                     \
+         "pushl 4(%%eax)\n\t"                                     \
+         "movl (%%eax), %%eax\n\t"  /* target->%eax */            \
+         VALGRIND_CALL_NOREDIR_EAX                                \
+         "addl $8, %%esp\n"                                       \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_WWW(lval, orig, arg1,arg2,arg3)                 \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[4];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      _argvec[2] = (unsigned long)(arg2);                         \
+      _argvec[3] = (unsigned long)(arg3);                         \
+      __asm__ volatile(                                           \
+         "pushl 12(%%eax)\n\t"                                    \
+         "pushl 8(%%eax)\n\t"                                     \
+         "pushl 4(%%eax)\n\t"                                     \
+         "movl (%%eax), %%eax\n\t"  /* target->%eax */            \
+         VALGRIND_CALL_NOREDIR_EAX                                \
+         "addl $12, %%esp\n"                                      \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_WWWW(lval, orig, arg1,arg2,arg3,arg4)           \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[5];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      _argvec[2] = (unsigned long)(arg2);                         \
+      _argvec[3] = (unsigned long)(arg3);                         \
+      _argvec[4] = (unsigned long)(arg4);                         \
+      __asm__ volatile(                                           \
+         "pushl 16(%%eax)\n\t"                                    \
+         "pushl 12(%%eax)\n\t"                                    \
+         "pushl 8(%%eax)\n\t"                                     \
+         "pushl 4(%%eax)\n\t"                                     \
+         "movl (%%eax), %%eax\n\t"  /* target->%eax */            \
+         VALGRIND_CALL_NOREDIR_EAX                                \
+         "addl $16, %%esp\n"                                      \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_5W(lval, orig, arg1,arg2,arg3,arg4,arg5)        \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[6];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      _argvec[2] = (unsigned long)(arg2);                         \
+      _argvec[3] = (unsigned long)(arg3);                         \
+      _argvec[4] = (unsigned long)(arg4);                         \
+      _argvec[5] = (unsigned long)(arg5);                         \
+      __asm__ volatile(                                           \
+         "pushl 20(%%eax)\n\t"                                    \
+         "pushl 16(%%eax)\n\t"                                    \
+         "pushl 12(%%eax)\n\t"                                    \
+         "pushl 8(%%eax)\n\t"                                     \
+         "pushl 4(%%eax)\n\t"                                     \
+         "movl (%%eax), %%eax\n\t"  /* target->%eax */            \
+         VALGRIND_CALL_NOREDIR_EAX                                \
+         "addl $20, %%esp\n"                                      \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_6W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6)   \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[7];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      _argvec[2] = (unsigned long)(arg2);                         \
+      _argvec[3] = (unsigned long)(arg3);                         \
+      _argvec[4] = (unsigned long)(arg4);                         \
+      _argvec[5] = (unsigned long)(arg5);                         \
+      _argvec[6] = (unsigned long)(arg6);                         \
+      __asm__ volatile(                                           \
+         "pushl 24(%%eax)\n\t"                                    \
+         "pushl 20(%%eax)\n\t"                                    \
+         "pushl 16(%%eax)\n\t"                                    \
+         "pushl 12(%%eax)\n\t"                                    \
+         "pushl 8(%%eax)\n\t"                                     \
+         "pushl 4(%%eax)\n\t"                                     \
+         "movl (%%eax), %%eax\n\t"  /* target->%eax */            \
+         VALGRIND_CALL_NOREDIR_EAX                                \
+         "addl $24, %%esp\n"                                      \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_7W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,   \
+                                 arg7)                            \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[8];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      _argvec[2] = (unsigned long)(arg2);                         \
+      _argvec[3] = (unsigned long)(arg3);                         \
+      _argvec[4] = (unsigned long)(arg4);                         \
+      _argvec[5] = (unsigned long)(arg5);                         \
+      _argvec[6] = (unsigned long)(arg6);                         \
+      _argvec[7] = (unsigned long)(arg7);                         \
+      __asm__ volatile(                                           \
+         "pushl 28(%%eax)\n\t"                                    \
+         "pushl 24(%%eax)\n\t"                                    \
+         "pushl 20(%%eax)\n\t"                                    \
+         "pushl 16(%%eax)\n\t"                                    \
+         "pushl 12(%%eax)\n\t"                                    \
+         "pushl 8(%%eax)\n\t"                                     \
+         "pushl 4(%%eax)\n\t"                                     \
+         "movl (%%eax), %%eax\n\t"  /* target->%eax */            \
+         VALGRIND_CALL_NOREDIR_EAX                                \
+         "addl $28, %%esp\n"                                      \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_8W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,   \
+                                 arg7,arg8)                       \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[9];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      _argvec[2] = (unsigned long)(arg2);                         \
+      _argvec[3] = (unsigned long)(arg3);                         \
+      _argvec[4] = (unsigned long)(arg4);                         \
+      _argvec[5] = (unsigned long)(arg5);                         \
+      _argvec[6] = (unsigned long)(arg6);                         \
+      _argvec[7] = (unsigned long)(arg7);                         \
+      _argvec[8] = (unsigned long)(arg8);                         \
+      __asm__ volatile(                                           \
+         "pushl 32(%%eax)\n\t"                                    \
+         "pushl 28(%%eax)\n\t"                                    \
+         "pushl 24(%%eax)\n\t"                                    \
+         "pushl 20(%%eax)\n\t"                                    \
+         "pushl 16(%%eax)\n\t"                                    \
+         "pushl 12(%%eax)\n\t"                                    \
+         "pushl 8(%%eax)\n\t"                                     \
+         "pushl 4(%%eax)\n\t"                                     \
+         "movl (%%eax), %%eax\n\t"  /* target->%eax */            \
+         VALGRIND_CALL_NOREDIR_EAX                                \
+         "addl $32, %%esp\n"                                      \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_9W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,   \
+                                 arg7,arg8,arg9)                  \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[10];                         \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      _argvec[2] = (unsigned long)(arg2);                         \
+      _argvec[3] = (unsigned long)(arg3);                         \
+      _argvec[4] = (unsigned long)(arg4);                         \
+      _argvec[5] = (unsigned long)(arg5);                         \
+      _argvec[6] = (unsigned long)(arg6);                         \
+      _argvec[7] = (unsigned long)(arg7);                         \
+      _argvec[8] = (unsigned long)(arg8);                         \
+      _argvec[9] = (unsigned long)(arg9);                         \
+      __asm__ volatile(                                           \
+         "pushl 36(%%eax)\n\t"                                    \
+         "pushl 32(%%eax)\n\t"                                    \
+         "pushl 28(%%eax)\n\t"                                    \
+         "pushl 24(%%eax)\n\t"                                    \
+         "pushl 20(%%eax)\n\t"                                    \
+         "pushl 16(%%eax)\n\t"                                    \
+         "pushl 12(%%eax)\n\t"                                    \
+         "pushl 8(%%eax)\n\t"                                     \
+         "pushl 4(%%eax)\n\t"                                     \
+         "movl (%%eax), %%eax\n\t"  /* target->%eax */            \
+         VALGRIND_CALL_NOREDIR_EAX                                \
+         "addl $36, %%esp\n"                                      \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_10W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,  \
+                                  arg7,arg8,arg9,arg10)           \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[11];                         \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      _argvec[2] = (unsigned long)(arg2);                         \
+      _argvec[3] = (unsigned long)(arg3);                         \
+      _argvec[4] = (unsigned long)(arg4);                         \
+      _argvec[5] = (unsigned long)(arg5);                         \
+      _argvec[6] = (unsigned long)(arg6);                         \
+      _argvec[7] = (unsigned long)(arg7);                         \
+      _argvec[8] = (unsigned long)(arg8);                         \
+      _argvec[9] = (unsigned long)(arg9);                         \
+      _argvec[10] = (unsigned long)(arg10);                       \
+      __asm__ volatile(                                           \
+         "pushl 40(%%eax)\n\t"                                    \
+         "pushl 36(%%eax)\n\t"                                    \
+         "pushl 32(%%eax)\n\t"                                    \
+         "pushl 28(%%eax)\n\t"                                    \
+         "pushl 24(%%eax)\n\t"                                    \
+         "pushl 20(%%eax)\n\t"                                    \
+         "pushl 16(%%eax)\n\t"                                    \
+         "pushl 12(%%eax)\n\t"                                    \
+         "pushl 8(%%eax)\n\t"                                     \
+         "pushl 4(%%eax)\n\t"                                     \
+         "movl (%%eax), %%eax\n\t"  /* target->%eax */            \
+         VALGRIND_CALL_NOREDIR_EAX                                \
+         "addl $40, %%esp\n"                                      \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_11W(lval, orig, arg1,arg2,arg3,arg4,arg5,       \
+                                  arg6,arg7,arg8,arg9,arg10,      \
+                                  arg11)                          \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[12];                         \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      _argvec[2] = (unsigned long)(arg2);                         \
+      _argvec[3] = (unsigned long)(arg3);                         \
+      _argvec[4] = (unsigned long)(arg4);                         \
+      _argvec[5] = (unsigned long)(arg5);                         \
+      _argvec[6] = (unsigned long)(arg6);                         \
+      _argvec[7] = (unsigned long)(arg7);                         \
+      _argvec[8] = (unsigned long)(arg8);                         \
+      _argvec[9] = (unsigned long)(arg9);                         \
+      _argvec[10] = (unsigned long)(arg10);                       \
+      _argvec[11] = (unsigned long)(arg11);                       \
+      __asm__ volatile(                                           \
+         "pushl 44(%%eax)\n\t"                                    \
+         "pushl 40(%%eax)\n\t"                                    \
+         "pushl 36(%%eax)\n\t"                                    \
+         "pushl 32(%%eax)\n\t"                                    \
+         "pushl 28(%%eax)\n\t"                                    \
+         "pushl 24(%%eax)\n\t"                                    \
+         "pushl 20(%%eax)\n\t"                                    \
+         "pushl 16(%%eax)\n\t"                                    \
+         "pushl 12(%%eax)\n\t"                                    \
+         "pushl 8(%%eax)\n\t"                                     \
+         "pushl 4(%%eax)\n\t"                                     \
+         "movl (%%eax), %%eax\n\t"  /* target->%eax */            \
+         VALGRIND_CALL_NOREDIR_EAX                                \
+         "addl $44, %%esp\n"                                      \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_12W(lval, orig, arg1,arg2,arg3,arg4,arg5,       \
+                                  arg6,arg7,arg8,arg9,arg10,      \
+                                  arg11,arg12)                    \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[13];                         \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      _argvec[2] = (unsigned long)(arg2);                         \
+      _argvec[3] = (unsigned long)(arg3);                         \
+      _argvec[4] = (unsigned long)(arg4);                         \
+      _argvec[5] = (unsigned long)(arg5);                         \
+      _argvec[6] = (unsigned long)(arg6);                         \
+      _argvec[7] = (unsigned long)(arg7);                         \
+      _argvec[8] = (unsigned long)(arg8);                         \
+      _argvec[9] = (unsigned long)(arg9);                         \
+      _argvec[10] = (unsigned long)(arg10);                       \
+      _argvec[11] = (unsigned long)(arg11);                       \
+      _argvec[12] = (unsigned long)(arg12);                       \
+      __asm__ volatile(                                           \
+         "pushl 48(%%eax)\n\t"                                    \
+         "pushl 44(%%eax)\n\t"                                    \
+         "pushl 40(%%eax)\n\t"                                    \
+         "pushl 36(%%eax)\n\t"                                    \
+         "pushl 32(%%eax)\n\t"                                    \
+         "pushl 28(%%eax)\n\t"                                    \
+         "pushl 24(%%eax)\n\t"                                    \
+         "pushl 20(%%eax)\n\t"                                    \
+         "pushl 16(%%eax)\n\t"                                    \
+         "pushl 12(%%eax)\n\t"                                    \
+         "pushl 8(%%eax)\n\t"                                     \
+         "pushl 4(%%eax)\n\t"                                     \
+         "movl (%%eax), %%eax\n\t"  /* target->%eax */            \
+         VALGRIND_CALL_NOREDIR_EAX                                \
+         "addl $48, %%esp\n"                                      \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#endif /* PLAT_x86_linux */
+
+/* ------------------------ amd64-linux ------------------------ */
+
+#if defined(PLAT_amd64_linux)
+
+/* ARGREGS: rdi rsi rdx rcx r8 r9 (the rest on stack in R-to-L order) */
+
+/* These regs are trashed by the hidden call. */
+#define __CALLER_SAVED_REGS /*"rax",*/ "rcx", "rdx", "rsi",       \
+                            "rdi", "r8", "r9", "r10", "r11"
+
+/* These CALL_FN_ macros assume that on amd64-linux, sizeof(unsigned
+   long) == 8. */
+
+/* NB 9 Sept 07.  There is a nasty kludge here in all these CALL_FN_
+   macros.  In order not to trash the stack redzone, we need to drop
+   %rsp by 128 before the hidden call, and restore afterwards.  The
+   nastyness is that it is only by luck that the stack still appears
+   to be unwindable during the hidden call - since then the behaviour
+   of any routine using this macro does not match what the CFI data
+   says.  Sigh.
+
+   Why is this important?  Imagine that a wrapper has a stack
+   allocated local, and passes to the hidden call, a pointer to it.
+   Because gcc does not know about the hidden call, it may allocate
+   that local in the redzone.  Unfortunately the hidden call may then
+   trash it before it comes to use it.  So we must step clear of the
+   redzone, for the duration of the hidden call, to make it safe.
+
+   Probably the same problem afflicts the other redzone-style ABIs too
+   (ppc64-linux, ppc32-aix5, ppc64-aix5); but for those, the stack is
+   self describing (none of this CFI nonsense) so at least messing
+   with the stack pointer doesn't give a danger of non-unwindable
+   stack. */
+
+#define CALL_FN_W_v(lval, orig)                                   \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[1];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      __asm__ volatile(                                           \
+         "subq $128,%%rsp\n\t"                                    \
+         "movq (%%rax), %%rax\n\t"  /* target->%rax */            \
+         VALGRIND_CALL_NOREDIR_RAX                                \
+         "addq $128,%%rsp\n\t"                                    \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_W(lval, orig, arg1)                             \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[2];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      __asm__ volatile(                                           \
+         "subq $128,%%rsp\n\t"                                    \
+         "movq 8(%%rax), %%rdi\n\t"                               \
+         "movq (%%rax), %%rax\n\t"  /* target->%rax */            \
+         VALGRIND_CALL_NOREDIR_RAX                                \
+         "addq $128,%%rsp\n\t"                                    \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_WW(lval, orig, arg1,arg2)                       \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      _argvec[2] = (unsigned long)(arg2);                         \
+      __asm__ volatile(                                           \
+         "subq $128,%%rsp\n\t"                                    \
+         "movq 16(%%rax), %%rsi\n\t"                              \
+         "movq 8(%%rax), %%rdi\n\t"                               \
+         "movq (%%rax), %%rax\n\t"  /* target->%rax */            \
+         VALGRIND_CALL_NOREDIR_RAX                                \
+         "addq $128,%%rsp\n\t"                                    \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_WWW(lval, orig, arg1,arg2,arg3)                 \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[4];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      _argvec[2] = (unsigned long)(arg2);                         \
+      _argvec[3] = (unsigned long)(arg3);                         \
+      __asm__ volatile(                                           \
+         "subq $128,%%rsp\n\t"                                    \
+         "movq 24(%%rax), %%rdx\n\t"                              \
+         "movq 16(%%rax), %%rsi\n\t"                              \
+         "movq 8(%%rax), %%rdi\n\t"                               \
+         "movq (%%rax), %%rax\n\t"  /* target->%rax */            \
+         VALGRIND_CALL_NOREDIR_RAX                                \
+         "addq $128,%%rsp\n\t"                                    \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_WWWW(lval, orig, arg1,arg2,arg3,arg4)           \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[5];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      _argvec[2] = (unsigned long)(arg2);                         \
+      _argvec[3] = (unsigned long)(arg3);                         \
+      _argvec[4] = (unsigned long)(arg4);                         \
+      __asm__ volatile(                                           \
+         "subq $128,%%rsp\n\t"                                    \
+         "movq 32(%%rax), %%rcx\n\t"                              \
+         "movq 24(%%rax), %%rdx\n\t"                              \
+         "movq 16(%%rax), %%rsi\n\t"                              \
+         "movq 8(%%rax), %%rdi\n\t"                               \
+         "movq (%%rax), %%rax\n\t"  /* target->%rax */            \
+         VALGRIND_CALL_NOREDIR_RAX                                \
+         "addq $128,%%rsp\n\t"                                    \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_5W(lval, orig, arg1,arg2,arg3,arg4,arg5)        \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[6];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      _argvec[2] = (unsigned long)(arg2);                         \
+      _argvec[3] = (unsigned long)(arg3);                         \
+      _argvec[4] = (unsigned long)(arg4);                         \
+      _argvec[5] = (unsigned long)(arg5);                         \
+      __asm__ volatile(                                           \
+         "subq $128,%%rsp\n\t"                                    \
+         "movq 40(%%rax), %%r8\n\t"                               \
+         "movq 32(%%rax), %%rcx\n\t"                              \
+         "movq 24(%%rax), %%rdx\n\t"                              \
+         "movq 16(%%rax), %%rsi\n\t"                              \
+         "movq 8(%%rax), %%rdi\n\t"                               \
+         "movq (%%rax), %%rax\n\t"  /* target->%rax */            \
+         VALGRIND_CALL_NOREDIR_RAX                                \
+         "addq $128,%%rsp\n\t"                                    \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_6W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6)   \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[7];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      _argvec[2] = (unsigned long)(arg2);                         \
+      _argvec[3] = (unsigned long)(arg3);                         \
+      _argvec[4] = (unsigned long)(arg4);                         \
+      _argvec[5] = (unsigned long)(arg5);                         \
+      _argvec[6] = (unsigned long)(arg6);                         \
+      __asm__ volatile(                                           \
+         "subq $128,%%rsp\n\t"                                    \
+         "movq 48(%%rax), %%r9\n\t"                               \
+         "movq 40(%%rax), %%r8\n\t"                               \
+         "movq 32(%%rax), %%rcx\n\t"                              \
+         "movq 24(%%rax), %%rdx\n\t"                              \
+         "movq 16(%%rax), %%rsi\n\t"                              \
+         "movq 8(%%rax), %%rdi\n\t"                               \
+         "movq (%%rax), %%rax\n\t"  /* target->%rax */            \
+         "addq $128,%%rsp\n\t"                                    \
+         VALGRIND_CALL_NOREDIR_RAX                                \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_7W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,   \
+                                 arg7)                            \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[8];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      _argvec[2] = (unsigned long)(arg2);                         \
+      _argvec[3] = (unsigned long)(arg3);                         \
+      _argvec[4] = (unsigned long)(arg4);                         \
+      _argvec[5] = (unsigned long)(arg5);                         \
+      _argvec[6] = (unsigned long)(arg6);                         \
+      _argvec[7] = (unsigned long)(arg7);                         \
+      __asm__ volatile(                                           \
+         "subq $128,%%rsp\n\t"                                    \
+         "pushq 56(%%rax)\n\t"                                    \
+         "movq 48(%%rax), %%r9\n\t"                               \
+         "movq 40(%%rax), %%r8\n\t"                               \
+         "movq 32(%%rax), %%rcx\n\t"                              \
+         "movq 24(%%rax), %%rdx\n\t"                              \
+         "movq 16(%%rax), %%rsi\n\t"                              \
+         "movq 8(%%rax), %%rdi\n\t"                               \
+         "movq (%%rax), %%rax\n\t"  /* target->%rax */            \
+         VALGRIND_CALL_NOREDIR_RAX                                \
+         "addq $8, %%rsp\n"                                       \
+         "addq $128,%%rsp\n\t"                                    \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_8W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,   \
+                                 arg7,arg8)                       \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[9];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      _argvec[2] = (unsigned long)(arg2);                         \
+      _argvec[3] = (unsigned long)(arg3);                         \
+      _argvec[4] = (unsigned long)(arg4);                         \
+      _argvec[5] = (unsigned long)(arg5);                         \
+      _argvec[6] = (unsigned long)(arg6);                         \
+      _argvec[7] = (unsigned long)(arg7);                         \
+      _argvec[8] = (unsigned long)(arg8);                         \
+      __asm__ volatile(                                           \
+         "subq $128,%%rsp\n\t"                                    \
+         "pushq 64(%%rax)\n\t"                                    \
+         "pushq 56(%%rax)\n\t"                                    \
+         "movq 48(%%rax), %%r9\n\t"                               \
+         "movq 40(%%rax), %%r8\n\t"                               \
+         "movq 32(%%rax), %%rcx\n\t"                              \
+         "movq 24(%%rax), %%rdx\n\t"                              \
+         "movq 16(%%rax), %%rsi\n\t"                              \
+         "movq 8(%%rax), %%rdi\n\t"                               \
+         "movq (%%rax), %%rax\n\t"  /* target->%rax */            \
+         VALGRIND_CALL_NOREDIR_RAX                                \
+         "addq $16, %%rsp\n"                                      \
+         "addq $128,%%rsp\n\t"                                    \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_9W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,   \
+                                 arg7,arg8,arg9)                  \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[10];                         \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      _argvec[2] = (unsigned long)(arg2);                         \
+      _argvec[3] = (unsigned long)(arg3);                         \
+      _argvec[4] = (unsigned long)(arg4);                         \
+      _argvec[5] = (unsigned long)(arg5);                         \
+      _argvec[6] = (unsigned long)(arg6);                         \
+      _argvec[7] = (unsigned long)(arg7);                         \
+      _argvec[8] = (unsigned long)(arg8);                         \
+      _argvec[9] = (unsigned long)(arg9);                         \
+      __asm__ volatile(                                           \
+         "subq $128,%%rsp\n\t"                                    \
+         "pushq 72(%%rax)\n\t"                                    \
+         "pushq 64(%%rax)\n\t"                                    \
+         "pushq 56(%%rax)\n\t"                                    \
+         "movq 48(%%rax), %%r9\n\t"                               \
+         "movq 40(%%rax), %%r8\n\t"                               \
+         "movq 32(%%rax), %%rcx\n\t"                              \
+         "movq 24(%%rax), %%rdx\n\t"                              \
+         "movq 16(%%rax), %%rsi\n\t"                              \
+         "movq 8(%%rax), %%rdi\n\t"                               \
+         "movq (%%rax), %%rax\n\t"  /* target->%rax */            \
+         VALGRIND_CALL_NOREDIR_RAX                                \
+         "addq $24, %%rsp\n"                                      \
+         "addq $128,%%rsp\n\t"                                    \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_10W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,  \
+                                  arg7,arg8,arg9,arg10)           \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[11];                         \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      _argvec[2] = (unsigned long)(arg2);                         \
+      _argvec[3] = (unsigned long)(arg3);                         \
+      _argvec[4] = (unsigned long)(arg4);                         \
+      _argvec[5] = (unsigned long)(arg5);                         \
+      _argvec[6] = (unsigned long)(arg6);                         \
+      _argvec[7] = (unsigned long)(arg7);                         \
+      _argvec[8] = (unsigned long)(arg8);                         \
+      _argvec[9] = (unsigned long)(arg9);                         \
+      _argvec[10] = (unsigned long)(arg10);                       \
+      __asm__ volatile(                                           \
+         "subq $128,%%rsp\n\t"                                    \
+         "pushq 80(%%rax)\n\t"                                    \
+         "pushq 72(%%rax)\n\t"                                    \
+         "pushq 64(%%rax)\n\t"                                    \
+         "pushq 56(%%rax)\n\t"                                    \
+         "movq 48(%%rax), %%r9\n\t"                               \
+         "movq 40(%%rax), %%r8\n\t"                               \
+         "movq 32(%%rax), %%rcx\n\t"                              \
+         "movq 24(%%rax), %%rdx\n\t"                              \
+         "movq 16(%%rax), %%rsi\n\t"                              \
+         "movq 8(%%rax), %%rdi\n\t"                               \
+         "movq (%%rax), %%rax\n\t"  /* target->%rax */            \
+         VALGRIND_CALL_NOREDIR_RAX                                \
+         "addq $32, %%rsp\n"                                      \
+         "addq $128,%%rsp\n\t"                                    \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_11W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,  \
+                                  arg7,arg8,arg9,arg10,arg11)     \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[12];                         \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      _argvec[2] = (unsigned long)(arg2);                         \
+      _argvec[3] = (unsigned long)(arg3);                         \
+      _argvec[4] = (unsigned long)(arg4);                         \
+      _argvec[5] = (unsigned long)(arg5);                         \
+      _argvec[6] = (unsigned long)(arg6);                         \
+      _argvec[7] = (unsigned long)(arg7);                         \
+      _argvec[8] = (unsigned long)(arg8);                         \
+      _argvec[9] = (unsigned long)(arg9);                         \
+      _argvec[10] = (unsigned long)(arg10);                       \
+      _argvec[11] = (unsigned long)(arg11);                       \
+      __asm__ volatile(                                           \
+         "subq $128,%%rsp\n\t"                                    \
+         "pushq 88(%%rax)\n\t"                                    \
+         "pushq 80(%%rax)\n\t"                                    \
+         "pushq 72(%%rax)\n\t"                                    \
+         "pushq 64(%%rax)\n\t"                                    \
+         "pushq 56(%%rax)\n\t"                                    \
+         "movq 48(%%rax), %%r9\n\t"                               \
+         "movq 40(%%rax), %%r8\n\t"                               \
+         "movq 32(%%rax), %%rcx\n\t"                              \
+         "movq 24(%%rax), %%rdx\n\t"                              \
+         "movq 16(%%rax), %%rsi\n\t"                              \
+         "movq 8(%%rax), %%rdi\n\t"                               \
+         "movq (%%rax), %%rax\n\t"  /* target->%rax */            \
+         VALGRIND_CALL_NOREDIR_RAX                                \
+         "addq $40, %%rsp\n"                                      \
+         "addq $128,%%rsp\n\t"                                    \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_12W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,  \
+                                arg7,arg8,arg9,arg10,arg11,arg12) \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[13];                         \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)(arg1);                         \
+      _argvec[2] = (unsigned long)(arg2);                         \
+      _argvec[3] = (unsigned long)(arg3);                         \
+      _argvec[4] = (unsigned long)(arg4);                         \
+      _argvec[5] = (unsigned long)(arg5);                         \
+      _argvec[6] = (unsigned long)(arg6);                         \
+      _argvec[7] = (unsigned long)(arg7);                         \
+      _argvec[8] = (unsigned long)(arg8);                         \
+      _argvec[9] = (unsigned long)(arg9);                         \
+      _argvec[10] = (unsigned long)(arg10);                       \
+      _argvec[11] = (unsigned long)(arg11);                       \
+      _argvec[12] = (unsigned long)(arg12);                       \
+      __asm__ volatile(                                           \
+         "subq $128,%%rsp\n\t"                                    \
+         "pushq 96(%%rax)\n\t"                                    \
+         "pushq 88(%%rax)\n\t"                                    \
+         "pushq 80(%%rax)\n\t"                                    \
+         "pushq 72(%%rax)\n\t"                                    \
+         "pushq 64(%%rax)\n\t"                                    \
+         "pushq 56(%%rax)\n\t"                                    \
+         "movq 48(%%rax), %%r9\n\t"                               \
+         "movq 40(%%rax), %%r8\n\t"                               \
+         "movq 32(%%rax), %%rcx\n\t"                              \
+         "movq 24(%%rax), %%rdx\n\t"                              \
+         "movq 16(%%rax), %%rsi\n\t"                              \
+         "movq 8(%%rax), %%rdi\n\t"                               \
+         "movq (%%rax), %%rax\n\t"  /* target->%rax */            \
+         VALGRIND_CALL_NOREDIR_RAX                                \
+         "addq $48, %%rsp\n"                                      \
+         "addq $128,%%rsp\n\t"                                    \
+         : /*out*/   "=a" (_res)                                  \
+         : /*in*/    "a" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#endif /* PLAT_amd64_linux */
+
+/* ------------------------ ppc32-linux ------------------------ */
+
+#if defined(PLAT_ppc32_linux)
+
+/* This is useful for finding out about the on-stack stuff:
+
+   extern int f9  ( int,int,int,int,int,int,int,int,int );
+   extern int f10 ( int,int,int,int,int,int,int,int,int,int );
+   extern int f11 ( int,int,int,int,int,int,int,int,int,int,int );
+   extern int f12 ( int,int,int,int,int,int,int,int,int,int,int,int );
+
+   int g9 ( void ) {
+      return f9(11,22,33,44,55,66,77,88,99);
+   }
+   int g10 ( void ) {
+      return f10(11,22,33,44,55,66,77,88,99,110);
+   }
+   int g11 ( void ) {
+      return f11(11,22,33,44,55,66,77,88,99,110,121);
+   }
+   int g12 ( void ) {
+      return f12(11,22,33,44,55,66,77,88,99,110,121,132);
+   }
+*/
+
+/* ARGREGS: r3 r4 r5 r6 r7 r8 r9 r10 (the rest on stack somewhere) */
+
+/* These regs are trashed by the hidden call. */
+#define __CALLER_SAVED_REGS                                       \
+   "lr", "ctr", "xer",                                            \
+   "cr0", "cr1", "cr2", "cr3", "cr4", "cr5", "cr6", "cr7",        \
+   "r0", "r2", "r3", "r4", "r5", "r6", "r7", "r8", "r9", "r10",   \
+   "r11", "r12", "r13"
+
+/* These CALL_FN_ macros assume that on ppc32-linux, 
+   sizeof(unsigned long) == 4. */
+
+#define CALL_FN_W_v(lval, orig)                                   \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[1];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "lwz 11,0(11)\n\t"  /* target->r11 */                    \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr %0,3"                                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_W(lval, orig, arg1)                             \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[2];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)arg1;                           \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "lwz 3,4(11)\n\t"   /* arg1->r3 */                       \
+         "lwz 11,0(11)\n\t"  /* target->r11 */                    \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr %0,3"                                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_WW(lval, orig, arg1,arg2)                       \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)arg1;                           \
+      _argvec[2] = (unsigned long)arg2;                           \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "lwz 3,4(11)\n\t"   /* arg1->r3 */                       \
+         "lwz 4,8(11)\n\t"                                        \
+         "lwz 11,0(11)\n\t"  /* target->r11 */                    \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr %0,3"                                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_WWW(lval, orig, arg1,arg2,arg3)                 \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[4];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)arg1;                           \
+      _argvec[2] = (unsigned long)arg2;                           \
+      _argvec[3] = (unsigned long)arg3;                           \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "lwz 3,4(11)\n\t"   /* arg1->r3 */                       \
+         "lwz 4,8(11)\n\t"                                        \
+         "lwz 5,12(11)\n\t"                                       \
+         "lwz 11,0(11)\n\t"  /* target->r11 */                    \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr %0,3"                                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_WWWW(lval, orig, arg1,arg2,arg3,arg4)           \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[5];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)arg1;                           \
+      _argvec[2] = (unsigned long)arg2;                           \
+      _argvec[3] = (unsigned long)arg3;                           \
+      _argvec[4] = (unsigned long)arg4;                           \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "lwz 3,4(11)\n\t"   /* arg1->r3 */                       \
+         "lwz 4,8(11)\n\t"                                        \
+         "lwz 5,12(11)\n\t"                                       \
+         "lwz 6,16(11)\n\t"  /* arg4->r6 */                       \
+         "lwz 11,0(11)\n\t"  /* target->r11 */                    \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr %0,3"                                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_5W(lval, orig, arg1,arg2,arg3,arg4,arg5)        \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[6];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)arg1;                           \
+      _argvec[2] = (unsigned long)arg2;                           \
+      _argvec[3] = (unsigned long)arg3;                           \
+      _argvec[4] = (unsigned long)arg4;                           \
+      _argvec[5] = (unsigned long)arg5;                           \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "lwz 3,4(11)\n\t"   /* arg1->r3 */                       \
+         "lwz 4,8(11)\n\t"                                        \
+         "lwz 5,12(11)\n\t"                                       \
+         "lwz 6,16(11)\n\t"  /* arg4->r6 */                       \
+         "lwz 7,20(11)\n\t"                                       \
+         "lwz 11,0(11)\n\t"  /* target->r11 */                    \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr %0,3"                                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_6W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6)   \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[7];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)arg1;                           \
+      _argvec[2] = (unsigned long)arg2;                           \
+      _argvec[3] = (unsigned long)arg3;                           \
+      _argvec[4] = (unsigned long)arg4;                           \
+      _argvec[5] = (unsigned long)arg5;                           \
+      _argvec[6] = (unsigned long)arg6;                           \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "lwz 3,4(11)\n\t"   /* arg1->r3 */                       \
+         "lwz 4,8(11)\n\t"                                        \
+         "lwz 5,12(11)\n\t"                                       \
+         "lwz 6,16(11)\n\t"  /* arg4->r6 */                       \
+         "lwz 7,20(11)\n\t"                                       \
+         "lwz 8,24(11)\n\t"                                       \
+         "lwz 11,0(11)\n\t"  /* target->r11 */                    \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr %0,3"                                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_7W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,   \
+                                 arg7)                            \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[8];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)arg1;                           \
+      _argvec[2] = (unsigned long)arg2;                           \
+      _argvec[3] = (unsigned long)arg3;                           \
+      _argvec[4] = (unsigned long)arg4;                           \
+      _argvec[5] = (unsigned long)arg5;                           \
+      _argvec[6] = (unsigned long)arg6;                           \
+      _argvec[7] = (unsigned long)arg7;                           \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "lwz 3,4(11)\n\t"   /* arg1->r3 */                       \
+         "lwz 4,8(11)\n\t"                                        \
+         "lwz 5,12(11)\n\t"                                       \
+         "lwz 6,16(11)\n\t"  /* arg4->r6 */                       \
+         "lwz 7,20(11)\n\t"                                       \
+         "lwz 8,24(11)\n\t"                                       \
+         "lwz 9,28(11)\n\t"                                       \
+         "lwz 11,0(11)\n\t"  /* target->r11 */                    \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr %0,3"                                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_8W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,   \
+                                 arg7,arg8)                       \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[9];                          \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)arg1;                           \
+      _argvec[2] = (unsigned long)arg2;                           \
+      _argvec[3] = (unsigned long)arg3;                           \
+      _argvec[4] = (unsigned long)arg4;                           \
+      _argvec[5] = (unsigned long)arg5;                           \
+      _argvec[6] = (unsigned long)arg6;                           \
+      _argvec[7] = (unsigned long)arg7;                           \
+      _argvec[8] = (unsigned long)arg8;                           \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "lwz 3,4(11)\n\t"   /* arg1->r3 */                       \
+         "lwz 4,8(11)\n\t"                                        \
+         "lwz 5,12(11)\n\t"                                       \
+         "lwz 6,16(11)\n\t"  /* arg4->r6 */                       \
+         "lwz 7,20(11)\n\t"                                       \
+         "lwz 8,24(11)\n\t"                                       \
+         "lwz 9,28(11)\n\t"                                       \
+         "lwz 10,32(11)\n\t" /* arg8->r10 */                      \
+         "lwz 11,0(11)\n\t"  /* target->r11 */                    \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr %0,3"                                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_9W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,   \
+                                 arg7,arg8,arg9)                  \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[10];                         \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)arg1;                           \
+      _argvec[2] = (unsigned long)arg2;                           \
+      _argvec[3] = (unsigned long)arg3;                           \
+      _argvec[4] = (unsigned long)arg4;                           \
+      _argvec[5] = (unsigned long)arg5;                           \
+      _argvec[6] = (unsigned long)arg6;                           \
+      _argvec[7] = (unsigned long)arg7;                           \
+      _argvec[8] = (unsigned long)arg8;                           \
+      _argvec[9] = (unsigned long)arg9;                           \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "addi 1,1,-16\n\t"                                       \
+         /* arg9 */                                               \
+         "lwz 3,36(11)\n\t"                                       \
+         "stw 3,8(1)\n\t"                                         \
+         /* args1-8 */                                            \
+         "lwz 3,4(11)\n\t"   /* arg1->r3 */                       \
+         "lwz 4,8(11)\n\t"                                        \
+         "lwz 5,12(11)\n\t"                                       \
+         "lwz 6,16(11)\n\t"  /* arg4->r6 */                       \
+         "lwz 7,20(11)\n\t"                                       \
+         "lwz 8,24(11)\n\t"                                       \
+         "lwz 9,28(11)\n\t"                                       \
+         "lwz 10,32(11)\n\t" /* arg8->r10 */                      \
+         "lwz 11,0(11)\n\t"  /* target->r11 */                    \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "addi 1,1,16\n\t"                                        \
+         "mr %0,3"                                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_10W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,  \
+                                  arg7,arg8,arg9,arg10)           \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[11];                         \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)arg1;                           \
+      _argvec[2] = (unsigned long)arg2;                           \
+      _argvec[3] = (unsigned long)arg3;                           \
+      _argvec[4] = (unsigned long)arg4;                           \
+      _argvec[5] = (unsigned long)arg5;                           \
+      _argvec[6] = (unsigned long)arg6;                           \
+      _argvec[7] = (unsigned long)arg7;                           \
+      _argvec[8] = (unsigned long)arg8;                           \
+      _argvec[9] = (unsigned long)arg9;                           \
+      _argvec[10] = (unsigned long)arg10;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "addi 1,1,-16\n\t"                                       \
+         /* arg10 */                                              \
+         "lwz 3,40(11)\n\t"                                       \
+         "stw 3,12(1)\n\t"                                        \
+         /* arg9 */                                               \
+         "lwz 3,36(11)\n\t"                                       \
+         "stw 3,8(1)\n\t"                                         \
+         /* args1-8 */                                            \
+         "lwz 3,4(11)\n\t"   /* arg1->r3 */                       \
+         "lwz 4,8(11)\n\t"                                        \
+         "lwz 5,12(11)\n\t"                                       \
+         "lwz 6,16(11)\n\t"  /* arg4->r6 */                       \
+         "lwz 7,20(11)\n\t"                                       \
+         "lwz 8,24(11)\n\t"                                       \
+         "lwz 9,28(11)\n\t"                                       \
+         "lwz 10,32(11)\n\t" /* arg8->r10 */                      \
+         "lwz 11,0(11)\n\t"  /* target->r11 */                    \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "addi 1,1,16\n\t"                                        \
+         "mr %0,3"                                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_11W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,  \
+                                  arg7,arg8,arg9,arg10,arg11)     \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[12];                         \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)arg1;                           \
+      _argvec[2] = (unsigned long)arg2;                           \
+      _argvec[3] = (unsigned long)arg3;                           \
+      _argvec[4] = (unsigned long)arg4;                           \
+      _argvec[5] = (unsigned long)arg5;                           \
+      _argvec[6] = (unsigned long)arg6;                           \
+      _argvec[7] = (unsigned long)arg7;                           \
+      _argvec[8] = (unsigned long)arg8;                           \
+      _argvec[9] = (unsigned long)arg9;                           \
+      _argvec[10] = (unsigned long)arg10;                         \
+      _argvec[11] = (unsigned long)arg11;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "addi 1,1,-32\n\t"                                       \
+         /* arg11 */                                              \
+         "lwz 3,44(11)\n\t"                                       \
+         "stw 3,16(1)\n\t"                                        \
+         /* arg10 */                                              \
+         "lwz 3,40(11)\n\t"                                       \
+         "stw 3,12(1)\n\t"                                        \
+         /* arg9 */                                               \
+         "lwz 3,36(11)\n\t"                                       \
+         "stw 3,8(1)\n\t"                                         \
+         /* args1-8 */                                            \
+         "lwz 3,4(11)\n\t"   /* arg1->r3 */                       \
+         "lwz 4,8(11)\n\t"                                        \
+         "lwz 5,12(11)\n\t"                                       \
+         "lwz 6,16(11)\n\t"  /* arg4->r6 */                       \
+         "lwz 7,20(11)\n\t"                                       \
+         "lwz 8,24(11)\n\t"                                       \
+         "lwz 9,28(11)\n\t"                                       \
+         "lwz 10,32(11)\n\t" /* arg8->r10 */                      \
+         "lwz 11,0(11)\n\t"  /* target->r11 */                    \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "addi 1,1,32\n\t"                                        \
+         "mr %0,3"                                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_12W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,  \
+                                arg7,arg8,arg9,arg10,arg11,arg12) \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[13];                         \
+      volatile unsigned long _res;                                \
+      _argvec[0] = (unsigned long)_orig.nraddr;                   \
+      _argvec[1] = (unsigned long)arg1;                           \
+      _argvec[2] = (unsigned long)arg2;                           \
+      _argvec[3] = (unsigned long)arg3;                           \
+      _argvec[4] = (unsigned long)arg4;                           \
+      _argvec[5] = (unsigned long)arg5;                           \
+      _argvec[6] = (unsigned long)arg6;                           \
+      _argvec[7] = (unsigned long)arg7;                           \
+      _argvec[8] = (unsigned long)arg8;                           \
+      _argvec[9] = (unsigned long)arg9;                           \
+      _argvec[10] = (unsigned long)arg10;                         \
+      _argvec[11] = (unsigned long)arg11;                         \
+      _argvec[12] = (unsigned long)arg12;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "addi 1,1,-32\n\t"                                       \
+         /* arg12 */                                              \
+         "lwz 3,48(11)\n\t"                                       \
+         "stw 3,20(1)\n\t"                                        \
+         /* arg11 */                                              \
+         "lwz 3,44(11)\n\t"                                       \
+         "stw 3,16(1)\n\t"                                        \
+         /* arg10 */                                              \
+         "lwz 3,40(11)\n\t"                                       \
+         "stw 3,12(1)\n\t"                                        \
+         /* arg9 */                                               \
+         "lwz 3,36(11)\n\t"                                       \
+         "stw 3,8(1)\n\t"                                         \
+         /* args1-8 */                                            \
+         "lwz 3,4(11)\n\t"   /* arg1->r3 */                       \
+         "lwz 4,8(11)\n\t"                                        \
+         "lwz 5,12(11)\n\t"                                       \
+         "lwz 6,16(11)\n\t"  /* arg4->r6 */                       \
+         "lwz 7,20(11)\n\t"                                       \
+         "lwz 8,24(11)\n\t"                                       \
+         "lwz 9,28(11)\n\t"                                       \
+         "lwz 10,32(11)\n\t" /* arg8->r10 */                      \
+         "lwz 11,0(11)\n\t"  /* target->r11 */                    \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "addi 1,1,32\n\t"                                        \
+         "mr %0,3"                                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[0])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#endif /* PLAT_ppc32_linux */
+
+/* ------------------------ ppc64-linux ------------------------ */
+
+#if defined(PLAT_ppc64_linux)
+
+/* ARGREGS: r3 r4 r5 r6 r7 r8 r9 r10 (the rest on stack somewhere) */
+
+/* These regs are trashed by the hidden call. */
+#define __CALLER_SAVED_REGS                                       \
+   "lr", "ctr", "xer",                                            \
+   "cr0", "cr1", "cr2", "cr3", "cr4", "cr5", "cr6", "cr7",        \
+   "r0", "r2", "r3", "r4", "r5", "r6", "r7", "r8", "r9", "r10",   \
+   "r11", "r12", "r13"
+
+/* These CALL_FN_ macros assume that on ppc64-linux, sizeof(unsigned
+   long) == 8. */
+
+#define CALL_FN_W_v(lval, orig)                                   \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+0];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1] = (unsigned long)_orig.r2;                       \
+      _argvec[2] = (unsigned long)_orig.nraddr;                   \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "std 2,-16(11)\n\t"  /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld 2,-16(11)" /* restore tocptr */                      \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_W(lval, orig, arg1)                             \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+1];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "std 2,-16(11)\n\t"  /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld 2,-16(11)" /* restore tocptr */                      \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_WW(lval, orig, arg1,arg2)                       \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+2];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "std 2,-16(11)\n\t"  /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld   4, 16(11)\n\t" /* arg2->r4 */                      \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld 2,-16(11)" /* restore tocptr */                      \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_WWW(lval, orig, arg1,arg2,arg3)                 \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+3];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "std 2,-16(11)\n\t"  /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld   4, 16(11)\n\t" /* arg2->r4 */                      \
+         "ld   5, 24(11)\n\t" /* arg3->r5 */                      \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld 2,-16(11)" /* restore tocptr */                      \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_WWWW(lval, orig, arg1,arg2,arg3,arg4)           \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+4];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "std 2,-16(11)\n\t"  /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld   4, 16(11)\n\t" /* arg2->r4 */                      \
+         "ld   5, 24(11)\n\t" /* arg3->r5 */                      \
+         "ld   6, 32(11)\n\t" /* arg4->r6 */                      \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld 2,-16(11)" /* restore tocptr */                      \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_5W(lval, orig, arg1,arg2,arg3,arg4,arg5)        \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+5];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "std 2,-16(11)\n\t"  /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld   4, 16(11)\n\t" /* arg2->r4 */                      \
+         "ld   5, 24(11)\n\t" /* arg3->r5 */                      \
+         "ld   6, 32(11)\n\t" /* arg4->r6 */                      \
+         "ld   7, 40(11)\n\t" /* arg5->r7 */                      \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld 2,-16(11)" /* restore tocptr */                      \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_6W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6)   \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+6];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      _argvec[2+6] = (unsigned long)arg6;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "std 2,-16(11)\n\t"  /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld   4, 16(11)\n\t" /* arg2->r4 */                      \
+         "ld   5, 24(11)\n\t" /* arg3->r5 */                      \
+         "ld   6, 32(11)\n\t" /* arg4->r6 */                      \
+         "ld   7, 40(11)\n\t" /* arg5->r7 */                      \
+         "ld   8, 48(11)\n\t" /* arg6->r8 */                      \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld 2,-16(11)" /* restore tocptr */                      \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_7W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,   \
+                                 arg7)                            \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+7];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      _argvec[2+6] = (unsigned long)arg6;                         \
+      _argvec[2+7] = (unsigned long)arg7;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "std 2,-16(11)\n\t"  /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld   4, 16(11)\n\t" /* arg2->r4 */                      \
+         "ld   5, 24(11)\n\t" /* arg3->r5 */                      \
+         "ld   6, 32(11)\n\t" /* arg4->r6 */                      \
+         "ld   7, 40(11)\n\t" /* arg5->r7 */                      \
+         "ld   8, 48(11)\n\t" /* arg6->r8 */                      \
+         "ld   9, 56(11)\n\t" /* arg7->r9 */                      \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld 2,-16(11)" /* restore tocptr */                      \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_8W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,   \
+                                 arg7,arg8)                       \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+8];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      _argvec[2+6] = (unsigned long)arg6;                         \
+      _argvec[2+7] = (unsigned long)arg7;                         \
+      _argvec[2+8] = (unsigned long)arg8;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "std 2,-16(11)\n\t"  /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld   4, 16(11)\n\t" /* arg2->r4 */                      \
+         "ld   5, 24(11)\n\t" /* arg3->r5 */                      \
+         "ld   6, 32(11)\n\t" /* arg4->r6 */                      \
+         "ld   7, 40(11)\n\t" /* arg5->r7 */                      \
+         "ld   8, 48(11)\n\t" /* arg6->r8 */                      \
+         "ld   9, 56(11)\n\t" /* arg7->r9 */                      \
+         "ld  10, 64(11)\n\t" /* arg8->r10 */                     \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld 2,-16(11)" /* restore tocptr */                      \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_9W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,   \
+                                 arg7,arg8,arg9)                  \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+9];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      _argvec[2+6] = (unsigned long)arg6;                         \
+      _argvec[2+7] = (unsigned long)arg7;                         \
+      _argvec[2+8] = (unsigned long)arg8;                         \
+      _argvec[2+9] = (unsigned long)arg9;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "std 2,-16(11)\n\t"  /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         "addi 1,1,-128\n\t"  /* expand stack frame */            \
+         /* arg9 */                                               \
+         "ld  3,72(11)\n\t"                                       \
+         "std 3,112(1)\n\t"                                       \
+         /* args1-8 */                                            \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld   4, 16(11)\n\t" /* arg2->r4 */                      \
+         "ld   5, 24(11)\n\t" /* arg3->r5 */                      \
+         "ld   6, 32(11)\n\t" /* arg4->r6 */                      \
+         "ld   7, 40(11)\n\t" /* arg5->r7 */                      \
+         "ld   8, 48(11)\n\t" /* arg6->r8 */                      \
+         "ld   9, 56(11)\n\t" /* arg7->r9 */                      \
+         "ld  10, 64(11)\n\t" /* arg8->r10 */                     \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld 2,-16(11)\n\t" /* restore tocptr */                  \
+         "addi 1,1,128"     /* restore frame */                   \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_10W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,  \
+                                  arg7,arg8,arg9,arg10)           \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+10];                       \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      _argvec[2+6] = (unsigned long)arg6;                         \
+      _argvec[2+7] = (unsigned long)arg7;                         \
+      _argvec[2+8] = (unsigned long)arg8;                         \
+      _argvec[2+9] = (unsigned long)arg9;                         \
+      _argvec[2+10] = (unsigned long)arg10;                       \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "std 2,-16(11)\n\t"  /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         "addi 1,1,-128\n\t"  /* expand stack frame */            \
+         /* arg10 */                                              \
+         "ld  3,80(11)\n\t"                                       \
+         "std 3,120(1)\n\t"                                       \
+         /* arg9 */                                               \
+         "ld  3,72(11)\n\t"                                       \
+         "std 3,112(1)\n\t"                                       \
+         /* args1-8 */                                            \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld   4, 16(11)\n\t" /* arg2->r4 */                      \
+         "ld   5, 24(11)\n\t" /* arg3->r5 */                      \
+         "ld   6, 32(11)\n\t" /* arg4->r6 */                      \
+         "ld   7, 40(11)\n\t" /* arg5->r7 */                      \
+         "ld   8, 48(11)\n\t" /* arg6->r8 */                      \
+         "ld   9, 56(11)\n\t" /* arg7->r9 */                      \
+         "ld  10, 64(11)\n\t" /* arg8->r10 */                     \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld 2,-16(11)\n\t" /* restore tocptr */                  \
+         "addi 1,1,128"     /* restore frame */                   \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_11W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,  \
+                                  arg7,arg8,arg9,arg10,arg11)     \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+11];                       \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      _argvec[2+6] = (unsigned long)arg6;                         \
+      _argvec[2+7] = (unsigned long)arg7;                         \
+      _argvec[2+8] = (unsigned long)arg8;                         \
+      _argvec[2+9] = (unsigned long)arg9;                         \
+      _argvec[2+10] = (unsigned long)arg10;                       \
+      _argvec[2+11] = (unsigned long)arg11;                       \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "std 2,-16(11)\n\t"  /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         "addi 1,1,-144\n\t"  /* expand stack frame */            \
+         /* arg11 */                                              \
+         "ld  3,88(11)\n\t"                                       \
+         "std 3,128(1)\n\t"                                       \
+         /* arg10 */                                              \
+         "ld  3,80(11)\n\t"                                       \
+         "std 3,120(1)\n\t"                                       \
+         /* arg9 */                                               \
+         "ld  3,72(11)\n\t"                                       \
+         "std 3,112(1)\n\t"                                       \
+         /* args1-8 */                                            \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld   4, 16(11)\n\t" /* arg2->r4 */                      \
+         "ld   5, 24(11)\n\t" /* arg3->r5 */                      \
+         "ld   6, 32(11)\n\t" /* arg4->r6 */                      \
+         "ld   7, 40(11)\n\t" /* arg5->r7 */                      \
+         "ld   8, 48(11)\n\t" /* arg6->r8 */                      \
+         "ld   9, 56(11)\n\t" /* arg7->r9 */                      \
+         "ld  10, 64(11)\n\t" /* arg8->r10 */                     \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld 2,-16(11)\n\t" /* restore tocptr */                  \
+         "addi 1,1,144"     /* restore frame */                   \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_12W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,  \
+                                arg7,arg8,arg9,arg10,arg11,arg12) \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+12];                       \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      _argvec[2+6] = (unsigned long)arg6;                         \
+      _argvec[2+7] = (unsigned long)arg7;                         \
+      _argvec[2+8] = (unsigned long)arg8;                         \
+      _argvec[2+9] = (unsigned long)arg9;                         \
+      _argvec[2+10] = (unsigned long)arg10;                       \
+      _argvec[2+11] = (unsigned long)arg11;                       \
+      _argvec[2+12] = (unsigned long)arg12;                       \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         "std 2,-16(11)\n\t"  /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         "addi 1,1,-144\n\t"  /* expand stack frame */            \
+         /* arg12 */                                              \
+         "ld  3,96(11)\n\t"                                       \
+         "std 3,136(1)\n\t"                                       \
+         /* arg11 */                                              \
+         "ld  3,88(11)\n\t"                                       \
+         "std 3,128(1)\n\t"                                       \
+         /* arg10 */                                              \
+         "ld  3,80(11)\n\t"                                       \
+         "std 3,120(1)\n\t"                                       \
+         /* arg9 */                                               \
+         "ld  3,72(11)\n\t"                                       \
+         "std 3,112(1)\n\t"                                       \
+         /* args1-8 */                                            \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld   4, 16(11)\n\t" /* arg2->r4 */                      \
+         "ld   5, 24(11)\n\t" /* arg3->r5 */                      \
+         "ld   6, 32(11)\n\t" /* arg4->r6 */                      \
+         "ld   7, 40(11)\n\t" /* arg5->r7 */                      \
+         "ld   8, 48(11)\n\t" /* arg6->r8 */                      \
+         "ld   9, 56(11)\n\t" /* arg7->r9 */                      \
+         "ld  10, 64(11)\n\t" /* arg8->r10 */                     \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld 2,-16(11)\n\t" /* restore tocptr */                  \
+         "addi 1,1,144"     /* restore frame */                   \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#endif /* PLAT_ppc64_linux */
+
+/* ------------------------ ppc32-aix5 ------------------------- */
+
+#if defined(PLAT_ppc32_aix5)
+
+/* ARGREGS: r3 r4 r5 r6 r7 r8 r9 r10 (the rest on stack somewhere) */
+
+/* These regs are trashed by the hidden call. */
+#define __CALLER_SAVED_REGS                                       \
+   "lr", "ctr", "xer",                                            \
+   "cr0", "cr1", "cr2", "cr3", "cr4", "cr5", "cr6", "cr7",        \
+   "r0", "r2", "r3", "r4", "r5", "r6", "r7", "r8", "r9", "r10",   \
+   "r11", "r12", "r13"
+
+/* Expand the stack frame, copying enough info that unwinding
+   still works.  Trashes r3. */
+
+#define VG_EXPAND_FRAME_BY_trashes_r3(_n_fr)                      \
+         "addi 1,1,-" #_n_fr "\n\t"                               \
+         "lwz  3," #_n_fr "(1)\n\t"                               \
+         "stw  3,0(1)\n\t"
+
+#define VG_CONTRACT_FRAME_BY(_n_fr)                               \
+         "addi 1,1," #_n_fr "\n\t"
+
+/* These CALL_FN_ macros assume that on ppc32-aix5, sizeof(unsigned
+   long) == 4. */
+
+#define CALL_FN_W_v(lval, orig)                                   \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+0];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1] = (unsigned long)_orig.r2;                       \
+      _argvec[2] = (unsigned long)_orig.nraddr;                   \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "stw  2,-8(11)\n\t"  /* save tocptr */                   \
+         "lwz  2,-4(11)\n\t"  /* use nraddr's tocptr */           \
+         "lwz 11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "lwz 2,-8(11)\n\t" /* restore tocptr */                  \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_W(lval, orig, arg1)                             \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+1];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "stw  2,-8(11)\n\t"  /* save tocptr */                   \
+         "lwz  2,-4(11)\n\t"  /* use nraddr's tocptr */           \
+         "lwz  3, 4(11)\n\t"  /* arg1->r3 */                      \
+         "lwz 11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "lwz 2,-8(11)\n\t" /* restore tocptr */                  \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_WW(lval, orig, arg1,arg2)                       \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+2];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "stw  2,-8(11)\n\t"  /* save tocptr */                   \
+         "lwz  2,-4(11)\n\t"  /* use nraddr's tocptr */           \
+         "lwz  3, 4(11)\n\t"  /* arg1->r3 */                      \
+         "lwz  4, 8(11)\n\t"  /* arg2->r4 */                      \
+         "lwz 11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "lwz 2,-8(11)\n\t" /* restore tocptr */                  \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_WWW(lval, orig, arg1,arg2,arg3)                 \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+3];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "stw  2,-8(11)\n\t"  /* save tocptr */                   \
+         "lwz  2,-4(11)\n\t"  /* use nraddr's tocptr */           \
+         "lwz  3, 4(11)\n\t"  /* arg1->r3 */                      \
+         "lwz  4, 8(11)\n\t"  /* arg2->r4 */                      \
+         "lwz  5, 12(11)\n\t" /* arg3->r5 */                      \
+         "lwz 11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "lwz 2,-8(11)\n\t" /* restore tocptr */                  \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_WWWW(lval, orig, arg1,arg2,arg3,arg4)           \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+4];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "stw  2,-8(11)\n\t"  /* save tocptr */                   \
+         "lwz  2,-4(11)\n\t"  /* use nraddr's tocptr */           \
+         "lwz  3, 4(11)\n\t"  /* arg1->r3 */                      \
+         "lwz  4, 8(11)\n\t"  /* arg2->r4 */                      \
+         "lwz  5, 12(11)\n\t" /* arg3->r5 */                      \
+         "lwz  6, 16(11)\n\t" /* arg4->r6 */                      \
+         "lwz 11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "lwz 2,-8(11)\n\t" /* restore tocptr */                  \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_5W(lval, orig, arg1,arg2,arg3,arg4,arg5)        \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+5];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "stw  2,-8(11)\n\t"  /* save tocptr */                   \
+         "lwz  2,-4(11)\n\t"  /* use nraddr's tocptr */           \
+         "lwz  3, 4(11)\n\t"  /* arg1->r3 */                      \
+         "lwz  4, 8(11)\n\t" /* arg2->r4 */                       \
+         "lwz  5, 12(11)\n\t" /* arg3->r5 */                      \
+         "lwz  6, 16(11)\n\t" /* arg4->r6 */                      \
+         "lwz  7, 20(11)\n\t" /* arg5->r7 */                      \
+         "lwz 11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "lwz 2,-8(11)\n\t" /* restore tocptr */                  \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_6W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6)   \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+6];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      _argvec[2+6] = (unsigned long)arg6;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "stw  2,-8(11)\n\t"  /* save tocptr */                   \
+         "lwz  2,-4(11)\n\t"  /* use nraddr's tocptr */           \
+         "lwz  3, 4(11)\n\t"  /* arg1->r3 */                      \
+         "lwz  4, 8(11)\n\t"  /* arg2->r4 */                      \
+         "lwz  5, 12(11)\n\t" /* arg3->r5 */                      \
+         "lwz  6, 16(11)\n\t" /* arg4->r6 */                      \
+         "lwz  7, 20(11)\n\t" /* arg5->r7 */                      \
+         "lwz  8, 24(11)\n\t" /* arg6->r8 */                      \
+         "lwz 11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "lwz 2,-8(11)\n\t" /* restore tocptr */                  \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_7W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,   \
+                                 arg7)                            \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+7];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      _argvec[2+6] = (unsigned long)arg6;                         \
+      _argvec[2+7] = (unsigned long)arg7;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "stw  2,-8(11)\n\t"  /* save tocptr */                   \
+         "lwz  2,-4(11)\n\t"  /* use nraddr's tocptr */           \
+         "lwz  3, 4(11)\n\t"  /* arg1->r3 */                      \
+         "lwz  4, 8(11)\n\t"  /* arg2->r4 */                      \
+         "lwz  5, 12(11)\n\t" /* arg3->r5 */                      \
+         "lwz  6, 16(11)\n\t" /* arg4->r6 */                      \
+         "lwz  7, 20(11)\n\t" /* arg5->r7 */                      \
+         "lwz  8, 24(11)\n\t" /* arg6->r8 */                      \
+         "lwz  9, 28(11)\n\t" /* arg7->r9 */                      \
+         "lwz 11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "lwz 2,-8(11)\n\t" /* restore tocptr */                  \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_8W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,   \
+                                 arg7,arg8)                       \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+8];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      _argvec[2+6] = (unsigned long)arg6;                         \
+      _argvec[2+7] = (unsigned long)arg7;                         \
+      _argvec[2+8] = (unsigned long)arg8;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "stw  2,-8(11)\n\t"  /* save tocptr */                   \
+         "lwz  2,-4(11)\n\t"  /* use nraddr's tocptr */           \
+         "lwz  3, 4(11)\n\t"  /* arg1->r3 */                      \
+         "lwz  4, 8(11)\n\t"  /* arg2->r4 */                      \
+         "lwz  5, 12(11)\n\t" /* arg3->r5 */                      \
+         "lwz  6, 16(11)\n\t" /* arg4->r6 */                      \
+         "lwz  7, 20(11)\n\t" /* arg5->r7 */                      \
+         "lwz  8, 24(11)\n\t" /* arg6->r8 */                      \
+         "lwz  9, 28(11)\n\t" /* arg7->r9 */                      \
+         "lwz 10, 32(11)\n\t" /* arg8->r10 */                     \
+         "lwz 11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "lwz 2,-8(11)\n\t" /* restore tocptr */                  \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_9W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,   \
+                                 arg7,arg8,arg9)                  \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+9];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      _argvec[2+6] = (unsigned long)arg6;                         \
+      _argvec[2+7] = (unsigned long)arg7;                         \
+      _argvec[2+8] = (unsigned long)arg8;                         \
+      _argvec[2+9] = (unsigned long)arg9;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "stw  2,-8(11)\n\t"  /* save tocptr */                   \
+         "lwz  2,-4(11)\n\t"  /* use nraddr's tocptr */           \
+         VG_EXPAND_FRAME_BY_trashes_r3(64)                        \
+         /* arg9 */                                               \
+         "lwz 3,36(11)\n\t"                                       \
+         "stw 3,56(1)\n\t"                                        \
+         /* args1-8 */                                            \
+         "lwz  3, 4(11)\n\t"  /* arg1->r3 */                      \
+         "lwz  4, 8(11)\n\t"  /* arg2->r4 */                      \
+         "lwz  5, 12(11)\n\t" /* arg3->r5 */                      \
+         "lwz  6, 16(11)\n\t" /* arg4->r6 */                      \
+         "lwz  7, 20(11)\n\t" /* arg5->r7 */                      \
+         "lwz  8, 24(11)\n\t" /* arg6->r8 */                      \
+         "lwz  9, 28(11)\n\t" /* arg7->r9 */                      \
+         "lwz 10, 32(11)\n\t" /* arg8->r10 */                     \
+         "lwz 11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "lwz 2,-8(11)\n\t" /* restore tocptr */                  \
+         VG_CONTRACT_FRAME_BY(64)                                 \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_10W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,  \
+                                  arg7,arg8,arg9,arg10)           \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+10];                       \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      _argvec[2+6] = (unsigned long)arg6;                         \
+      _argvec[2+7] = (unsigned long)arg7;                         \
+      _argvec[2+8] = (unsigned long)arg8;                         \
+      _argvec[2+9] = (unsigned long)arg9;                         \
+      _argvec[2+10] = (unsigned long)arg10;                       \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "stw  2,-8(11)\n\t"  /* save tocptr */                   \
+         "lwz  2,-4(11)\n\t"  /* use nraddr's tocptr */           \
+         VG_EXPAND_FRAME_BY_trashes_r3(64)                        \
+         /* arg10 */                                              \
+         "lwz 3,40(11)\n\t"                                       \
+         "stw 3,60(1)\n\t"                                        \
+         /* arg9 */                                               \
+         "lwz 3,36(11)\n\t"                                       \
+         "stw 3,56(1)\n\t"                                        \
+         /* args1-8 */                                            \
+         "lwz  3, 4(11)\n\t"  /* arg1->r3 */                      \
+         "lwz  4, 8(11)\n\t"  /* arg2->r4 */                      \
+         "lwz  5, 12(11)\n\t" /* arg3->r5 */                      \
+         "lwz  6, 16(11)\n\t" /* arg4->r6 */                      \
+         "lwz  7, 20(11)\n\t" /* arg5->r7 */                      \
+         "lwz  8, 24(11)\n\t" /* arg6->r8 */                      \
+         "lwz  9, 28(11)\n\t" /* arg7->r9 */                      \
+         "lwz 10, 32(11)\n\t" /* arg8->r10 */                     \
+         "lwz 11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "lwz 2,-8(11)\n\t" /* restore tocptr */                  \
+         VG_CONTRACT_FRAME_BY(64)                                 \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_11W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,  \
+                                  arg7,arg8,arg9,arg10,arg11)     \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+11];                       \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      _argvec[2+6] = (unsigned long)arg6;                         \
+      _argvec[2+7] = (unsigned long)arg7;                         \
+      _argvec[2+8] = (unsigned long)arg8;                         \
+      _argvec[2+9] = (unsigned long)arg9;                         \
+      _argvec[2+10] = (unsigned long)arg10;                       \
+      _argvec[2+11] = (unsigned long)arg11;                       \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "stw  2,-8(11)\n\t"  /* save tocptr */                   \
+         "lwz  2,-4(11)\n\t"  /* use nraddr's tocptr */           \
+         VG_EXPAND_FRAME_BY_trashes_r3(72)                        \
+         /* arg11 */                                              \
+         "lwz 3,44(11)\n\t"                                       \
+         "stw 3,64(1)\n\t"                                        \
+         /* arg10 */                                              \
+         "lwz 3,40(11)\n\t"                                       \
+         "stw 3,60(1)\n\t"                                        \
+         /* arg9 */                                               \
+         "lwz 3,36(11)\n\t"                                       \
+         "stw 3,56(1)\n\t"                                        \
+         /* args1-8 */                                            \
+         "lwz  3, 4(11)\n\t"  /* arg1->r3 */                      \
+         "lwz  4, 8(11)\n\t"  /* arg2->r4 */                      \
+         "lwz  5, 12(11)\n\t" /* arg3->r5 */                      \
+         "lwz  6, 16(11)\n\t" /* arg4->r6 */                      \
+         "lwz  7, 20(11)\n\t" /* arg5->r7 */                      \
+         "lwz  8, 24(11)\n\t" /* arg6->r8 */                      \
+         "lwz  9, 28(11)\n\t" /* arg7->r9 */                      \
+         "lwz 10, 32(11)\n\t" /* arg8->r10 */                     \
+         "lwz 11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "lwz 2,-8(11)\n\t" /* restore tocptr */                  \
+         VG_CONTRACT_FRAME_BY(72)                                 \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_12W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,  \
+                                arg7,arg8,arg9,arg10,arg11,arg12) \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+12];                       \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      _argvec[2+6] = (unsigned long)arg6;                         \
+      _argvec[2+7] = (unsigned long)arg7;                         \
+      _argvec[2+8] = (unsigned long)arg8;                         \
+      _argvec[2+9] = (unsigned long)arg9;                         \
+      _argvec[2+10] = (unsigned long)arg10;                       \
+      _argvec[2+11] = (unsigned long)arg11;                       \
+      _argvec[2+12] = (unsigned long)arg12;                       \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "stw  2,-8(11)\n\t"  /* save tocptr */                   \
+         "lwz  2,-4(11)\n\t"  /* use nraddr's tocptr */           \
+         VG_EXPAND_FRAME_BY_trashes_r3(72)                        \
+         /* arg12 */                                              \
+         "lwz 3,48(11)\n\t"                                       \
+         "stw 3,68(1)\n\t"                                        \
+         /* arg11 */                                              \
+         "lwz 3,44(11)\n\t"                                       \
+         "stw 3,64(1)\n\t"                                        \
+         /* arg10 */                                              \
+         "lwz 3,40(11)\n\t"                                       \
+         "stw 3,60(1)\n\t"                                        \
+         /* arg9 */                                               \
+         "lwz 3,36(11)\n\t"                                       \
+         "stw 3,56(1)\n\t"                                        \
+         /* args1-8 */                                            \
+         "lwz  3, 4(11)\n\t"  /* arg1->r3 */                      \
+         "lwz  4, 8(11)\n\t"  /* arg2->r4 */                      \
+         "lwz  5, 12(11)\n\t" /* arg3->r5 */                      \
+         "lwz  6, 16(11)\n\t" /* arg4->r6 */                      \
+         "lwz  7, 20(11)\n\t" /* arg5->r7 */                      \
+         "lwz  8, 24(11)\n\t" /* arg6->r8 */                      \
+         "lwz  9, 28(11)\n\t" /* arg7->r9 */                      \
+         "lwz 10, 32(11)\n\t" /* arg8->r10 */                     \
+         "lwz 11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "lwz 2,-8(11)\n\t" /* restore tocptr */                  \
+         VG_CONTRACT_FRAME_BY(72)                                 \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#endif /* PLAT_ppc32_aix5 */
+
+/* ------------------------ ppc64-aix5 ------------------------- */
+
+#if defined(PLAT_ppc64_aix5)
+
+/* ARGREGS: r3 r4 r5 r6 r7 r8 r9 r10 (the rest on stack somewhere) */
+
+/* These regs are trashed by the hidden call. */
+#define __CALLER_SAVED_REGS                                       \
+   "lr", "ctr", "xer",                                            \
+   "cr0", "cr1", "cr2", "cr3", "cr4", "cr5", "cr6", "cr7",        \
+   "r0", "r2", "r3", "r4", "r5", "r6", "r7", "r8", "r9", "r10",   \
+   "r11", "r12", "r13"
+
+/* Expand the stack frame, copying enough info that unwinding
+   still works.  Trashes r3. */
+
+#define VG_EXPAND_FRAME_BY_trashes_r3(_n_fr)                      \
+         "addi 1,1,-" #_n_fr "\n\t"                               \
+         "ld   3," #_n_fr "(1)\n\t"                               \
+         "std  3,0(1)\n\t"
+
+#define VG_CONTRACT_FRAME_BY(_n_fr)                               \
+         "addi 1,1," #_n_fr "\n\t"
+
+/* These CALL_FN_ macros assume that on ppc64-aix5, sizeof(unsigned
+   long) == 8. */
+
+#define CALL_FN_W_v(lval, orig)                                   \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+0];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1] = (unsigned long)_orig.r2;                       \
+      _argvec[2] = (unsigned long)_orig.nraddr;                   \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "std  2,-16(11)\n\t" /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld 2,-16(11)\n\t" /* restore tocptr */                  \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_W(lval, orig, arg1)                             \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+1];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "std  2,-16(11)\n\t" /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld 2,-16(11)\n\t" /* restore tocptr */                  \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_WW(lval, orig, arg1,arg2)                       \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+2];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "std  2,-16(11)\n\t" /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld   4, 16(11)\n\t" /* arg2->r4 */                      \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld  2,-16(11)\n\t" /* restore tocptr */                 \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_WWW(lval, orig, arg1,arg2,arg3)                 \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+3];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "std  2,-16(11)\n\t" /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld   4, 16(11)\n\t" /* arg2->r4 */                      \
+         "ld   5, 24(11)\n\t" /* arg3->r5 */                      \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld  2,-16(11)\n\t" /* restore tocptr */                 \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_WWWW(lval, orig, arg1,arg2,arg3,arg4)           \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+4];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "std  2,-16(11)\n\t" /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld   4, 16(11)\n\t" /* arg2->r4 */                      \
+         "ld   5, 24(11)\n\t" /* arg3->r5 */                      \
+         "ld   6, 32(11)\n\t" /* arg4->r6 */                      \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld  2,-16(11)\n\t" /* restore tocptr */                 \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_5W(lval, orig, arg1,arg2,arg3,arg4,arg5)        \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+5];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "std  2,-16(11)\n\t" /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld   4, 16(11)\n\t" /* arg2->r4 */                      \
+         "ld   5, 24(11)\n\t" /* arg3->r5 */                      \
+         "ld   6, 32(11)\n\t" /* arg4->r6 */                      \
+         "ld   7, 40(11)\n\t" /* arg5->r7 */                      \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld  2,-16(11)\n\t" /* restore tocptr */                 \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_6W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6)   \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+6];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      _argvec[2+6] = (unsigned long)arg6;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "std  2,-16(11)\n\t" /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld   4, 16(11)\n\t" /* arg2->r4 */                      \
+         "ld   5, 24(11)\n\t" /* arg3->r5 */                      \
+         "ld   6, 32(11)\n\t" /* arg4->r6 */                      \
+         "ld   7, 40(11)\n\t" /* arg5->r7 */                      \
+         "ld   8, 48(11)\n\t" /* arg6->r8 */                      \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld  2,-16(11)\n\t" /* restore tocptr */                 \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_7W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,   \
+                                 arg7)                            \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+7];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      _argvec[2+6] = (unsigned long)arg6;                         \
+      _argvec[2+7] = (unsigned long)arg7;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "std  2,-16(11)\n\t" /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld   4, 16(11)\n\t" /* arg2->r4 */                      \
+         "ld   5, 24(11)\n\t" /* arg3->r5 */                      \
+         "ld   6, 32(11)\n\t" /* arg4->r6 */                      \
+         "ld   7, 40(11)\n\t" /* arg5->r7 */                      \
+         "ld   8, 48(11)\n\t" /* arg6->r8 */                      \
+         "ld   9, 56(11)\n\t" /* arg7->r9 */                      \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld  2,-16(11)\n\t" /* restore tocptr */                 \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_8W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,   \
+                                 arg7,arg8)                       \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+8];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      _argvec[2+6] = (unsigned long)arg6;                         \
+      _argvec[2+7] = (unsigned long)arg7;                         \
+      _argvec[2+8] = (unsigned long)arg8;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "std  2,-16(11)\n\t" /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld   4, 16(11)\n\t" /* arg2->r4 */                      \
+         "ld   5, 24(11)\n\t" /* arg3->r5 */                      \
+         "ld   6, 32(11)\n\t" /* arg4->r6 */                      \
+         "ld   7, 40(11)\n\t" /* arg5->r7 */                      \
+         "ld   8, 48(11)\n\t" /* arg6->r8 */                      \
+         "ld   9, 56(11)\n\t" /* arg7->r9 */                      \
+         "ld  10, 64(11)\n\t" /* arg8->r10 */                     \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld  2,-16(11)\n\t" /* restore tocptr */                 \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_9W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,   \
+                                 arg7,arg8,arg9)                  \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+9];                        \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      _argvec[2+6] = (unsigned long)arg6;                         \
+      _argvec[2+7] = (unsigned long)arg7;                         \
+      _argvec[2+8] = (unsigned long)arg8;                         \
+      _argvec[2+9] = (unsigned long)arg9;                         \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "std  2,-16(11)\n\t" /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         VG_EXPAND_FRAME_BY_trashes_r3(128)                       \
+         /* arg9 */                                               \
+         "ld  3,72(11)\n\t"                                       \
+         "std 3,112(1)\n\t"                                       \
+         /* args1-8 */                                            \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld   4, 16(11)\n\t" /* arg2->r4 */                      \
+         "ld   5, 24(11)\n\t" /* arg3->r5 */                      \
+         "ld   6, 32(11)\n\t" /* arg4->r6 */                      \
+         "ld   7, 40(11)\n\t" /* arg5->r7 */                      \
+         "ld   8, 48(11)\n\t" /* arg6->r8 */                      \
+         "ld   9, 56(11)\n\t" /* arg7->r9 */                      \
+         "ld  10, 64(11)\n\t" /* arg8->r10 */                     \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld  2,-16(11)\n\t" /* restore tocptr */                 \
+         VG_CONTRACT_FRAME_BY(128)                                \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_10W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,  \
+                                  arg7,arg8,arg9,arg10)           \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+10];                       \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      _argvec[2+6] = (unsigned long)arg6;                         \
+      _argvec[2+7] = (unsigned long)arg7;                         \
+      _argvec[2+8] = (unsigned long)arg8;                         \
+      _argvec[2+9] = (unsigned long)arg9;                         \
+      _argvec[2+10] = (unsigned long)arg10;                       \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "std  2,-16(11)\n\t" /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         VG_EXPAND_FRAME_BY_trashes_r3(128)                       \
+         /* arg10 */                                              \
+         "ld  3,80(11)\n\t"                                       \
+         "std 3,120(1)\n\t"                                       \
+         /* arg9 */                                               \
+         "ld  3,72(11)\n\t"                                       \
+         "std 3,112(1)\n\t"                                       \
+         /* args1-8 */                                            \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld   4, 16(11)\n\t" /* arg2->r4 */                      \
+         "ld   5, 24(11)\n\t" /* arg3->r5 */                      \
+         "ld   6, 32(11)\n\t" /* arg4->r6 */                      \
+         "ld   7, 40(11)\n\t" /* arg5->r7 */                      \
+         "ld   8, 48(11)\n\t" /* arg6->r8 */                      \
+         "ld   9, 56(11)\n\t" /* arg7->r9 */                      \
+         "ld  10, 64(11)\n\t" /* arg8->r10 */                     \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld  2,-16(11)\n\t" /* restore tocptr */                 \
+         VG_CONTRACT_FRAME_BY(128)                                \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_11W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,  \
+                                  arg7,arg8,arg9,arg10,arg11)     \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+11];                       \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      _argvec[2+6] = (unsigned long)arg6;                         \
+      _argvec[2+7] = (unsigned long)arg7;                         \
+      _argvec[2+8] = (unsigned long)arg8;                         \
+      _argvec[2+9] = (unsigned long)arg9;                         \
+      _argvec[2+10] = (unsigned long)arg10;                       \
+      _argvec[2+11] = (unsigned long)arg11;                       \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "std  2,-16(11)\n\t" /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         VG_EXPAND_FRAME_BY_trashes_r3(144)                       \
+         /* arg11 */                                              \
+         "ld  3,88(11)\n\t"                                       \
+         "std 3,128(1)\n\t"                                       \
+         /* arg10 */                                              \
+         "ld  3,80(11)\n\t"                                       \
+         "std 3,120(1)\n\t"                                       \
+         /* arg9 */                                               \
+         "ld  3,72(11)\n\t"                                       \
+         "std 3,112(1)\n\t"                                       \
+         /* args1-8 */                                            \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld   4, 16(11)\n\t" /* arg2->r4 */                      \
+         "ld   5, 24(11)\n\t" /* arg3->r5 */                      \
+         "ld   6, 32(11)\n\t" /* arg4->r6 */                      \
+         "ld   7, 40(11)\n\t" /* arg5->r7 */                      \
+         "ld   8, 48(11)\n\t" /* arg6->r8 */                      \
+         "ld   9, 56(11)\n\t" /* arg7->r9 */                      \
+         "ld  10, 64(11)\n\t" /* arg8->r10 */                     \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld  2,-16(11)\n\t" /* restore tocptr */                 \
+         VG_CONTRACT_FRAME_BY(144)                                \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#define CALL_FN_W_12W(lval, orig, arg1,arg2,arg3,arg4,arg5,arg6,  \
+                                arg7,arg8,arg9,arg10,arg11,arg12) \
+   do {                                                           \
+      volatile OrigFn        _orig = (orig);                      \
+      volatile unsigned long _argvec[3+12];                       \
+      volatile unsigned long _res;                                \
+      /* _argvec[0] holds current r2 across the call */           \
+      _argvec[1]   = (unsigned long)_orig.r2;                     \
+      _argvec[2]   = (unsigned long)_orig.nraddr;                 \
+      _argvec[2+1] = (unsigned long)arg1;                         \
+      _argvec[2+2] = (unsigned long)arg2;                         \
+      _argvec[2+3] = (unsigned long)arg3;                         \
+      _argvec[2+4] = (unsigned long)arg4;                         \
+      _argvec[2+5] = (unsigned long)arg5;                         \
+      _argvec[2+6] = (unsigned long)arg6;                         \
+      _argvec[2+7] = (unsigned long)arg7;                         \
+      _argvec[2+8] = (unsigned long)arg8;                         \
+      _argvec[2+9] = (unsigned long)arg9;                         \
+      _argvec[2+10] = (unsigned long)arg10;                       \
+      _argvec[2+11] = (unsigned long)arg11;                       \
+      _argvec[2+12] = (unsigned long)arg12;                       \
+      __asm__ volatile(                                           \
+         "mr 11,%1\n\t"                                           \
+         VG_EXPAND_FRAME_BY_trashes_r3(512)                       \
+         "std  2,-16(11)\n\t" /* save tocptr */                   \
+         "ld   2,-8(11)\n\t"  /* use nraddr's tocptr */           \
+         VG_EXPAND_FRAME_BY_trashes_r3(144)                       \
+         /* arg12 */                                              \
+         "ld  3,96(11)\n\t"                                       \
+         "std 3,136(1)\n\t"                                       \
+         /* arg11 */                                              \
+         "ld  3,88(11)\n\t"                                       \
+         "std 3,128(1)\n\t"                                       \
+         /* arg10 */                                              \
+         "ld  3,80(11)\n\t"                                       \
+         "std 3,120(1)\n\t"                                       \
+         /* arg9 */                                               \
+         "ld  3,72(11)\n\t"                                       \
+         "std 3,112(1)\n\t"                                       \
+         /* args1-8 */                                            \
+         "ld   3, 8(11)\n\t"  /* arg1->r3 */                      \
+         "ld   4, 16(11)\n\t" /* arg2->r4 */                      \
+         "ld   5, 24(11)\n\t" /* arg3->r5 */                      \
+         "ld   6, 32(11)\n\t" /* arg4->r6 */                      \
+         "ld   7, 40(11)\n\t" /* arg5->r7 */                      \
+         "ld   8, 48(11)\n\t" /* arg6->r8 */                      \
+         "ld   9, 56(11)\n\t" /* arg7->r9 */                      \
+         "ld  10, 64(11)\n\t" /* arg8->r10 */                     \
+         "ld  11, 0(11)\n\t"  /* target->r11 */                   \
+         VALGRIND_BRANCH_AND_LINK_TO_NOREDIR_R11                  \
+         "mr 11,%1\n\t"                                           \
+         "mr %0,3\n\t"                                            \
+         "ld  2,-16(11)\n\t" /* restore tocptr */                 \
+         VG_CONTRACT_FRAME_BY(144)                                \
+         VG_CONTRACT_FRAME_BY(512)                                \
+         : /*out*/   "=r" (_res)                                  \
+         : /*in*/    "r" (&_argvec[2])                            \
+         : /*trash*/ "cc", "memory", __CALLER_SAVED_REGS          \
+      );                                                          \
+      lval = (__typeof__(lval)) _res;                             \
+   } while (0)
+
+#endif /* PLAT_ppc64_aix5 */
+
+
+/* ------------------------------------------------------------------ */
+/* ARCHITECTURE INDEPENDENT MACROS for CLIENT REQUESTS.               */
+/*                                                                    */
+/* ------------------------------------------------------------------ */
+
+/* Some request codes.  There are many more of these, but most are not
+   exposed to end-user view.  These are the public ones, all of the
+   form 0x1000 + small_number.
+
+   Core ones are in the range 0x00000000--0x0000ffff.  The non-public
+   ones start at 0x2000.
+*/
+
+/* These macros are used by tools -- they must be public, but don't
+   embed them into other programs. */
+#define VG_USERREQ_TOOL_BASE(a,b) \
+   ((unsigned int)(((a)&0xff) << 24 | ((b)&0xff) << 16))
+#define VG_IS_TOOL_USERREQ(a, b, v) \
+   (VG_USERREQ_TOOL_BASE(a,b) == ((v) & 0xffff0000))
+
+/* !! ABIWARNING !! ABIWARNING !! ABIWARNING !! ABIWARNING !! 
+   This enum comprises an ABI exported by Valgrind to programs
+   which use client requests.  DO NOT CHANGE THE ORDER OF THESE
+   ENTRIES, NOR DELETE ANY -- add new ones at the end. */
+typedef
+   enum { VG_USERREQ__RUNNING_ON_VALGRIND  = 0x1001,
+          VG_USERREQ__DISCARD_TRANSLATIONS = 0x1002,
+
+          /* These allow any function to be called from the simulated
+             CPU but run on the real CPU.  Nb: the first arg passed to
+             the function is always the ThreadId of the running
+             thread!  So CLIENT_CALL0 actually requires a 1 arg
+             function, etc. */
+          VG_USERREQ__CLIENT_CALL0 = 0x1101,
+          VG_USERREQ__CLIENT_CALL1 = 0x1102,
+          VG_USERREQ__CLIENT_CALL2 = 0x1103,
+          VG_USERREQ__CLIENT_CALL3 = 0x1104,
+
+          /* Can be useful in regression testing suites -- eg. can
+             send Valgrind's output to /dev/null and still count
+             errors. */
+          VG_USERREQ__COUNT_ERRORS = 0x1201,
+
+          /* These are useful and can be interpreted by any tool that
+             tracks malloc() et al, by using vg_replace_malloc.c. */
+          VG_USERREQ__MALLOCLIKE_BLOCK = 0x1301,
+          VG_USERREQ__FREELIKE_BLOCK   = 0x1302,
+          /* Memory pool support. */
+          VG_USERREQ__CREATE_MEMPOOL   = 0x1303,
+          VG_USERREQ__DESTROY_MEMPOOL  = 0x1304,
+          VG_USERREQ__MEMPOOL_ALLOC    = 0x1305,
+          VG_USERREQ__MEMPOOL_FREE     = 0x1306,
+          VG_USERREQ__MEMPOOL_TRIM     = 0x1307,
+          VG_USERREQ__MOVE_MEMPOOL     = 0x1308,
+          VG_USERREQ__MEMPOOL_CHANGE   = 0x1309,
+          VG_USERREQ__MEMPOOL_EXISTS   = 0x130a,
+
+          /* Allow printfs to valgrind log. */
+          VG_USERREQ__PRINTF           = 0x1401,
+          VG_USERREQ__PRINTF_BACKTRACE = 0x1402,
+
+          /* Stack support. */
+          VG_USERREQ__STACK_REGISTER   = 0x1501,
+          VG_USERREQ__STACK_DEREGISTER = 0x1502,
+          VG_USERREQ__STACK_CHANGE     = 0x1503,
+          VG_USERREQ__STACK_SWITCH     = 0x1504,
+          VG_USERREQ__STACK_DEREGADDR  = 0x1505
+   } Vg_ClientRequest;
+
+#if !defined(__GNUC__)
+#  define __extension__ /* */
+#endif
+
+/* Returns the number of Valgrinds this code is running under.  That
+   is, 0 if running natively, 1 if running under Valgrind, 2 if
+   running under Valgrind which is running under another Valgrind,
+   etc. */
+#define RUNNING_ON_VALGRIND  __extension__                        \
+   ({unsigned int _qzz_res;                                       \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0 /* if not */,          \
+                               VG_USERREQ__RUNNING_ON_VALGRIND,   \
+                               0, 0, 0, 0, 0);                    \
+    _qzz_res;                                                     \
+   })
+
+
+/* Discard translation of code in the range [_qzz_addr .. _qzz_addr +
+   _qzz_len - 1].  Useful if you are debugging a JITter or some such,
+   since it provides a way to make sure valgrind will retranslate the
+   invalidated area.  Returns no value. */
+#define VALGRIND_DISCARD_TRANSLATIONS(_qzz_addr,_qzz_len)         \
+   {unsigned int _qzz_res;                                        \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0,                       \
+                               VG_USERREQ__DISCARD_TRANSLATIONS,  \
+                               _qzz_addr, _qzz_len, 0, 0, 0);     \
+   }
+
+
+/* These requests are for getting Valgrind itself to print something.
+   Possibly with a backtrace.  This is a really ugly hack. */
+
+#if defined(NVALGRIND)
+
+#  define VALGRIND_PRINTF(...)
+#  define VALGRIND_PRINTF_BACKTRACE(...)
+
+#else /* NVALGRIND */
+
+/* Modern GCC will optimize the static routine out if unused,
+   and unused attribute will shut down warnings about it.  */
+static int VALGRIND_PRINTF(const char *format, ...)
+   __attribute__((format(__printf__, 1, 2), __unused__));
+static int
+VALGRIND_PRINTF(const char *format, ...)
+{
+   unsigned long _qzz_res;
+   va_list vargs;
+   va_start(vargs, format);
+   VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0, VG_USERREQ__PRINTF,
+                              (unsigned long)format, (unsigned long)vargs, 
+                              0, 0, 0);
+   va_end(vargs);
+   return (int)_qzz_res;
+}
+
+static int VALGRIND_PRINTF_BACKTRACE(const char *format, ...)
+   __attribute__((format(__printf__, 1, 2), __unused__));
+static int
+VALGRIND_PRINTF_BACKTRACE(const char *format, ...)
+{
+   unsigned long _qzz_res;
+   va_list vargs;
+   va_start(vargs, format);
+   VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0, VG_USERREQ__PRINTF_BACKTRACE,
+                              (unsigned long)format, (unsigned long)vargs, 
+                              0, 0, 0);
+   va_end(vargs);
+   return (int)_qzz_res;
+}
+
+#endif /* NVALGRIND */
+
+
+/* These requests allow control to move from the simulated CPU to the
+   real CPU, calling an arbitary function.
+   
+   Note that the current ThreadId is inserted as the first argument.
+   So this call:
+
+     VALGRIND_NON_SIMD_CALL2(f, arg1, arg2)
+
+   requires f to have this signature:
+
+     Word f(Word tid, Word arg1, Word arg2)
+
+   where "Word" is a word-sized type.
+
+   Note that these client requests are not entirely reliable.  For example,
+   if you call a function with them that subsequently calls printf(),
+   there's a high chance Valgrind will crash.  Generally, your prospects of
+   these working are made higher if the called function does not refer to
+   any global variables, and does not refer to any libc or other functions
+   (printf et al).  Any kind of entanglement with libc or dynamic linking is
+   likely to have a bad outcome, for tricky reasons which we've grappled
+   with a lot in the past.
+*/
+#define VALGRIND_NON_SIMD_CALL0(_qyy_fn)                          \
+   __extension__                                                  \
+   ({unsigned long _qyy_res;                                      \
+    VALGRIND_DO_CLIENT_REQUEST(_qyy_res, 0 /* default return */,  \
+                               VG_USERREQ__CLIENT_CALL0,          \
+                               _qyy_fn,                           \
+                               0, 0, 0, 0);                       \
+    _qyy_res;                                                     \
+   })
+
+#define VALGRIND_NON_SIMD_CALL1(_qyy_fn, _qyy_arg1)               \
+   __extension__                                                  \
+   ({unsigned long _qyy_res;                                      \
+    VALGRIND_DO_CLIENT_REQUEST(_qyy_res, 0 /* default return */,  \
+                               VG_USERREQ__CLIENT_CALL1,          \
+                               _qyy_fn,                           \
+                               _qyy_arg1, 0, 0, 0);               \
+    _qyy_res;                                                     \
+   })
+
+#define VALGRIND_NON_SIMD_CALL2(_qyy_fn, _qyy_arg1, _qyy_arg2)    \
+   __extension__                                                  \
+   ({unsigned long _qyy_res;                                      \
+    VALGRIND_DO_CLIENT_REQUEST(_qyy_res, 0 /* default return */,  \
+                               VG_USERREQ__CLIENT_CALL2,          \
+                               _qyy_fn,                           \
+                               _qyy_arg1, _qyy_arg2, 0, 0);       \
+    _qyy_res;                                                     \
+   })
+
+#define VALGRIND_NON_SIMD_CALL3(_qyy_fn, _qyy_arg1, _qyy_arg2, _qyy_arg3) \
+   __extension__                                                  \
+   ({unsigned long _qyy_res;                                      \
+    VALGRIND_DO_CLIENT_REQUEST(_qyy_res, 0 /* default return */,  \
+                               VG_USERREQ__CLIENT_CALL3,          \
+                               _qyy_fn,                           \
+                               _qyy_arg1, _qyy_arg2,              \
+                               _qyy_arg3, 0);                     \
+    _qyy_res;                                                     \
+   })
+
+
+/* Counts the number of errors that have been recorded by a tool.  Nb:
+   the tool must record the errors with VG_(maybe_record_error)() or
+   VG_(unique_error)() for them to be counted. */
+#define VALGRIND_COUNT_ERRORS                                     \
+   __extension__                                                  \
+   ({unsigned int _qyy_res;                                       \
+    VALGRIND_DO_CLIENT_REQUEST(_qyy_res, 0 /* default return */,  \
+                               VG_USERREQ__COUNT_ERRORS,          \
+                               0, 0, 0, 0, 0);                    \
+    _qyy_res;                                                     \
+   })
+
+/* Mark a block of memory as having been allocated by a malloc()-like
+   function.  `addr' is the start of the usable block (ie. after any
+   redzone) `rzB' is redzone size if the allocator can apply redzones;
+   use '0' if not.  Adding redzones makes it more likely Valgrind will spot
+   block overruns.  `is_zeroed' indicates if the memory is zeroed, as it is
+   for calloc().  Put it immediately after the point where a block is
+   allocated. 
+   
+   If you're using Memcheck: If you're allocating memory via superblocks,
+   and then handing out small chunks of each superblock, if you don't have
+   redzones on your small blocks, it's worth marking the superblock with
+   VALGRIND_MAKE_MEM_NOACCESS when it's created, so that block overruns are
+   detected.  But if you can put redzones on, it's probably better to not do
+   this, so that messages for small overruns are described in terms of the
+   small block rather than the superblock (but if you have a big overrun
+   that skips over a redzone, you could miss an error this way).  See
+   memcheck/tests/custom_alloc.c for an example.
+
+   WARNING: if your allocator uses malloc() or 'new' to allocate
+   superblocks, rather than mmap() or brk(), this will not work properly --
+   you'll likely get assertion failures during leak detection.  This is
+   because Valgrind doesn't like seeing overlapping heap blocks.  Sorry.
+
+   Nb: block must be freed via a free()-like function specified
+   with VALGRIND_FREELIKE_BLOCK or mismatch errors will occur. */
+#define VALGRIND_MALLOCLIKE_BLOCK(addr, sizeB, rzB, is_zeroed)    \
+   {unsigned int _qzz_res;                                        \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0,                       \
+                               VG_USERREQ__MALLOCLIKE_BLOCK,      \
+                               addr, sizeB, rzB, is_zeroed, 0);   \
+   }
+
+/* Mark a block of memory as having been freed by a free()-like function.
+   `rzB' is redzone size;  it must match that given to
+   VALGRIND_MALLOCLIKE_BLOCK.  Memory not freed will be detected by the leak
+   checker.  Put it immediately after the point where the block is freed. */
+#define VALGRIND_FREELIKE_BLOCK(addr, rzB)                        \
+   {unsigned int _qzz_res;                                        \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0,                       \
+                               VG_USERREQ__FREELIKE_BLOCK,        \
+                               addr, rzB, 0, 0, 0);               \
+   }
+
+/* Create a memory pool. */
+#define VALGRIND_CREATE_MEMPOOL(pool, rzB, is_zeroed)             \
+   {unsigned int _qzz_res;                                        \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0,                       \
+                               VG_USERREQ__CREATE_MEMPOOL,        \
+                               pool, rzB, is_zeroed, 0, 0);       \
+   }
+
+/* Destroy a memory pool. */
+#define VALGRIND_DESTROY_MEMPOOL(pool)                            \
+   {unsigned int _qzz_res;                                        \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0,                       \
+                               VG_USERREQ__DESTROY_MEMPOOL,       \
+                               pool, 0, 0, 0, 0);                 \
+   }
+
+/* Associate a piece of memory with a memory pool. */
+#define VALGRIND_MEMPOOL_ALLOC(pool, addr, size)                  \
+   {unsigned int _qzz_res;                                        \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0,                       \
+                               VG_USERREQ__MEMPOOL_ALLOC,         \
+                               pool, addr, size, 0, 0);           \
+   }
+
+/* Disassociate a piece of memory from a memory pool. */
+#define VALGRIND_MEMPOOL_FREE(pool, addr)                         \
+   {unsigned int _qzz_res;                                        \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0,                       \
+                               VG_USERREQ__MEMPOOL_FREE,          \
+                               pool, addr, 0, 0, 0);              \
+   }
+
+/* Disassociate any pieces outside a particular range. */
+#define VALGRIND_MEMPOOL_TRIM(pool, addr, size)                   \
+   {unsigned int _qzz_res;                                        \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0,                       \
+                               VG_USERREQ__MEMPOOL_TRIM,          \
+                               pool, addr, size, 0, 0);           \
+   }
+
+/* Resize and/or move a piece associated with a memory pool. */
+#define VALGRIND_MOVE_MEMPOOL(poolA, poolB)                       \
+   {unsigned int _qzz_res;                                        \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0,                       \
+                               VG_USERREQ__MOVE_MEMPOOL,          \
+                               poolA, poolB, 0, 0, 0);            \
+   }
+
+/* Resize and/or move a piece associated with a memory pool. */
+#define VALGRIND_MEMPOOL_CHANGE(pool, addrA, addrB, size)         \
+   {unsigned int _qzz_res;                                        \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0,                       \
+                               VG_USERREQ__MEMPOOL_CHANGE,        \
+                               pool, addrA, addrB, size, 0);      \
+   }
+
+/* Return 1 if a mempool exists, else 0. */
+#define VALGRIND_MEMPOOL_EXISTS(pool)                             \
+   ({unsigned int _qzz_res;                                       \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0,                       \
+                               VG_USERREQ__MEMPOOL_EXISTS,        \
+                               pool, 0, 0, 0, 0);                 \
+    _qzz_res;                                                     \
+   })
+
+/* Mark a piece of memory as being a stack. Returns a stack id. */
+#define VALGRIND_STACK_REGISTER(start, end)                       \
+   ({unsigned int _qzz_res;                                       \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0,                       \
+                               VG_USERREQ__STACK_REGISTER,        \
+                               start, end, 0, 0, 0);              \
+    _qzz_res;                                                     \
+   })
+
+/* Unmark the piece of memory associated with a stack id as being a
+   stack. */
+#define VALGRIND_STACK_DEREGISTER(id)                             \
+   {unsigned int _qzz_res;                                        \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0,                       \
+                               VG_USERREQ__STACK_DEREGISTER,      \
+                               id, 0, 0, 0, 0);                   \
+   }
+
+#define VALGRIND_STACK_DEREGADDR(addr)                            \
+   {unsigned int _qzz_res;                                        \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0,                       \
+                               VG_USERREQ__STACK_DEREGADDR,       \
+                               addr, 0, 0, 0, 0);                 \
+   }
+
+/* Change the start and end address of the stack id. */
+#define VALGRIND_STACK_CHANGE(id, start, end)                     \
+   {unsigned int _qzz_res;                                        \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0,                       \
+                               VG_USERREQ__STACK_CHANGE,          \
+                               id, start, end, 0, 0);             \
+   }
+
+/* Notify that stack has changed. (For longjmp.) */
+#define VALGRIND_STACK_SWITCH(old_esp, new_esp)                   \
+   {unsigned int _qzz_res;                                        \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0,                       \
+                               VG_USERREQ__STACK_SWITCH,          \
+                               old_esp, new_esp, 0, 0, 0);        \
+   }
+
+
+#undef PLAT_x86_linux
+#undef PLAT_amd64_linux
+#undef PLAT_ppc32_linux
+#undef PLAT_ppc64_linux
+#undef PLAT_ppc32_aix5
+#undef PLAT_ppc64_aix5
+
+#define CLONE_CHILD_LETGO 0x80000000  /* do not track child; 2007-12-07 jreiser */
+
+#endif   /* __VALGRIND_H */
--- linux-2.6.22.5-old/arch/um/include/memcheck.h	1969-12-31 16:00:00.000000000 -0800
+++ linux-2.6.22.5/arch/um/include/memcheck.h	2007-12-18 11:44:26.000000000 -0800
@@ -0,0 +1,295 @@
+
+/*
+   ----------------------------------------------------------------
+
+   Notice that the following BSD-style license applies to this one
+   file (memcheck.h) only.  The rest of Valgrind is licensed under the
+   terms of the GNU General Public License, version 2, unless
+   otherwise indicated.  See the COPYING file in the source
+   distribution for details.
+
+   ----------------------------------------------------------------
+
+   This file is part of MemCheck, a heavyweight Valgrind tool for
+   detecting memory errors.
+
+   Copyright (C) 2000-2007 Julian Seward.  All rights reserved.
+
+   Redistribution and use in source and binary forms, with or without
+   modification, are permitted provided that the following conditions
+   are met:
+
+   1. Redistributions of source code must retain the above copyright
+      notice, this list of conditions and the following disclaimer.
+
+   2. The origin of this software must not be misrepresented; you must 
+      not claim that you wrote the original software.  If you use this 
+      software in a product, an acknowledgment in the product 
+      documentation would be appreciated but is not required.
+
+   3. Altered source versions must be plainly marked as such, and must
+      not be misrepresented as being the original software.
+
+   4. The name of the author may not be used to endorse or promote 
+      products derived from this software without specific prior written 
+      permission.
+
+   THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS
+   OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+   WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+   ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+   DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+   DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE
+   GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+   INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+   WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+   NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+   SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+   ----------------------------------------------------------------
+
+   Notice that the above BSD-style license applies to this one file
+   (memcheck.h) only.  The entire rest of Valgrind is licensed under
+   the terms of the GNU General Public License, version 2.  See the
+   COPYING file in the source distribution for details.
+
+   ---------------------------------------------------------------- 
+*/
+
+
+#ifndef __MEMCHECK_H
+#define __MEMCHECK_H
+
+
+/* This file is for inclusion into client (your!) code.
+
+   You can use these macros to manipulate and query memory permissions
+   inside your own programs.
+
+   See comment near the top of valgrind.h on how to use them.
+*/
+
+#include "valgrind.h"
+
+/* !! ABIWARNING !! ABIWARNING !! ABIWARNING !! ABIWARNING !! 
+   This enum comprises an ABI exported by Valgrind to programs
+   which use client requests.  DO NOT CHANGE THE ORDER OF THESE
+   ENTRIES, NOR DELETE ANY -- add new ones at the end. */
+typedef
+   enum { 
+      VG_USERREQ__MAKE_MEM_NOACCESS = VG_USERREQ_TOOL_BASE('M','C'),
+      VG_USERREQ__MAKE_MEM_UNDEFINED,
+      VG_USERREQ__MAKE_MEM_DEFINED,
+      VG_USERREQ__DISCARD,
+      VG_USERREQ__CHECK_MEM_IS_ADDRESSABLE,
+      VG_USERREQ__CHECK_MEM_IS_DEFINED,
+      VG_USERREQ__DO_LEAK_CHECK,
+      VG_USERREQ__COUNT_LEAKS,
+
+      VG_USERREQ__GET_VBITS,
+      VG_USERREQ__SET_VBITS,
+
+      VG_USERREQ__CREATE_BLOCK,
+
+      VG_USERREQ__MAKE_MEM_DEFINED_IF_ADDRESSABLE,
+
+      VG_USERREQ__SET_BOGEY,
+
+      /* This is just for memcheck's internal use - don't use it */
+      _VG_USERREQ__MEMCHECK_RECORD_OVERLAP_ERROR 
+         = VG_USERREQ_TOOL_BASE('M','C') + 256
+   } Vg_MemCheckClientRequest;
+
+
+
+/* Client-code macros to manipulate the state of memory. */
+
+/* Mark memory at _qzz_addr as unaddressable for _qzz_len bytes. */
+#define VALGRIND_MAKE_MEM_NOACCESS(_qzz_addr,_qzz_len)           \
+   (__extension__({unsigned int _qzz_res;                        \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0 /* default return */, \
+                            VG_USERREQ__MAKE_MEM_NOACCESS,       \
+                            _qzz_addr, _qzz_len, 0, 0, 0);       \
+    _qzz_res;                                                    \
+   }))
+      
+/* Similarly, mark memory at _qzz_addr as addressable but undefined
+   for _qzz_len bytes. */
+#define VALGRIND_MAKE_MEM_UNDEFINED(_qzz_addr,_qzz_len)          \
+   (__extension__({unsigned int _qzz_res;                        \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0 /* default return */, \
+                            VG_USERREQ__MAKE_MEM_UNDEFINED,      \
+                            _qzz_addr, _qzz_len, 0, 0, 0);       \
+    _qzz_res;                                                    \
+   }))
+
+/* Similarly, mark memory at _qzz_addr as addressable and defined
+   for _qzz_len bytes. */
+#define VALGRIND_MAKE_MEM_DEFINED(_qzz_addr,_qzz_len)            \
+   (__extension__({unsigned int _qzz_res;                        \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0 /* default return */, \
+                            VG_USERREQ__MAKE_MEM_DEFINED,        \
+                            _qzz_addr, _qzz_len, 0, 0, 0);       \
+    _qzz_res;                                                    \
+   }))
+
+/* Similar to VALGRIND_MAKE_MEM_DEFINED except that addressability is
+   not altered: bytes which are addressable are marked as defined,
+   but those which are not addressable are left unchanged. */
+#define VALGRIND_MAKE_MEM_DEFINED_IF_ADDRESSABLE(_qzz_addr,_qzz_len) \
+   (__extension__({unsigned int _qzz_res;                        \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0 /* default return */, \
+                            VG_USERREQ__MAKE_MEM_DEFINED_IF_ADDRESSABLE, \
+                            _qzz_addr, _qzz_len, 0, 0, 0);       \
+    _qzz_res;                                                    \
+   }))
+
+#define VALGRIND_SET_BOGEY(_qzz_addr) \
+   (__extension__({unsigned int _qzz_res;                        \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0 /* default return */, \
+                            VG_USERREQ__SET_BOGEY, \
+                            _qzz_addr, 0, 0, 0, 0);       \
+    _qzz_res;                                                    \
+   }))
+
+/* Create a block-description handle.  The description is an ascii
+   string which is included in any messages pertaining to addresses
+   within the specified memory range.  Has no other effect on the
+   properties of the memory range. */
+#define VALGRIND_CREATE_BLOCK(_qzz_addr,_qzz_len, _qzz_desc)	 \
+	(__extension__({unsigned int _qzz_res;			 \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0 /* default return */, \
+                            VG_USERREQ__CREATE_BLOCK,            \
+                            _qzz_addr, _qzz_len, _qzz_desc,      \
+                            0, 0);                               \
+    _qzz_res;							 \
+   }))
+
+/* Discard a block-description-handle. Returns 1 for an
+   invalid handle, 0 for a valid handle. */
+#define VALGRIND_DISCARD(_qzz_blkindex)                          \
+   (__extension__ ({unsigned int _qzz_res;                       \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0 /* default return */, \
+                            VG_USERREQ__DISCARD,                 \
+                            0, _qzz_blkindex, 0, 0, 0);          \
+    _qzz_res;                                                    \
+   }))
+
+
+/* Client-code macros to check the state of memory. */
+
+/* Check that memory at _qzz_addr is addressable for _qzz_len bytes.
+   If suitable addressibility is not established, Valgrind prints an
+   error message and returns the address of the first offending byte.
+   Otherwise it returns zero. */
+#define VALGRIND_CHECK_MEM_IS_ADDRESSABLE(_qzz_addr,_qzz_len)    \
+   (__extension__({unsigned int _qzz_res;                        \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0,                      \
+                            VG_USERREQ__CHECK_MEM_IS_ADDRESSABLE,\
+                            _qzz_addr, _qzz_len, 0, 0, 0);       \
+    _qzz_res;                                                    \
+   }))
+
+/* Check that memory at _qzz_addr is addressable and defined for
+   _qzz_len bytes.  If suitable addressibility and definedness are not
+   established, Valgrind prints an error message and returns the
+   address of the first offending byte.  Otherwise it returns zero. */
+#define VALGRIND_CHECK_MEM_IS_DEFINED(_qzz_addr,_qzz_len)        \
+   (__extension__({unsigned int _qzz_res;                        \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0,                      \
+                            VG_USERREQ__CHECK_MEM_IS_DEFINED,    \
+                            _qzz_addr, _qzz_len, 0, 0, 0);       \
+    _qzz_res;                                                    \
+   }))
+
+/* Use this macro to force the definedness and addressibility of an
+   lvalue to be checked.  If suitable addressibility and definedness
+   are not established, Valgrind prints an error message and returns
+   the address of the first offending byte.  Otherwise it returns
+   zero. */
+#define VALGRIND_CHECK_VALUE_IS_DEFINED(__lvalue)                \
+   VALGRIND_CHECK_MEM_IS_DEFINED(                                \
+      (volatile unsigned char *)&(__lvalue),                     \
+                      (unsigned int)(sizeof (__lvalue)))
+
+
+/* Do a memory leak check mid-execution.  */
+#define VALGRIND_DO_LEAK_CHECK                                   \
+   {unsigned int _qzz_res;                                       \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0,                      \
+                            VG_USERREQ__DO_LEAK_CHECK,           \
+                            0, 0, 0, 0, 0);                      \
+   }
+
+/* Just display summaries of leaked memory, rather than all the
+   details */
+#define VALGRIND_DO_QUICK_LEAK_CHECK				 \
+   {unsigned int _qzz_res;                                       \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0,                      \
+                            VG_USERREQ__DO_LEAK_CHECK,           \
+                            1, 0, 0, 0, 0);                      \
+   }
+
+/* Return number of leaked, dubious, reachable and suppressed bytes found by
+   all previous leak checks.  They must be lvalues.  */
+#define VALGRIND_COUNT_LEAKS(leaked, dubious, reachable, suppressed)     \
+   /* For safety on 64-bit platforms we assign the results to private
+      unsigned long variables, then assign these to the lvalues the user
+      specified, which works no matter what type 'leaked', 'dubious', etc
+      are.  We also initialise '_qzz_leaked', etc because
+      VG_USERREQ__COUNT_LEAKS doesn't mark the values returned as
+      initialised. */                                                    \
+   {unsigned int  _qzz_res;                                              \
+    unsigned long _qzz_leaked    = 0, _qzz_dubious    = 0;               \
+    unsigned long _qzz_reachable = 0, _qzz_suppressed = 0;               \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0,                              \
+                               VG_USERREQ__COUNT_LEAKS,                  \
+                               &_qzz_leaked, &_qzz_dubious,              \
+                               &_qzz_reachable, &_qzz_suppressed, 0);    \
+    leaked     = _qzz_leaked;                                            \
+    dubious    = _qzz_dubious;                                           \
+    reachable  = _qzz_reachable;                                         \
+    suppressed = _qzz_suppressed;                                        \
+   }
+
+
+/* Get the validity data for addresses [zza..zza+zznbytes-1] and copy it
+   into the provided zzvbits array.  Return values:
+      0   if not running on valgrind
+      1   success
+      2   [previously indicated unaligned arrays;  these are now allowed]
+      3   if any parts of zzsrc/zzvbits are not addressable.
+   The metadata is not copied in cases 0, 2 or 3 so it should be
+   impossible to segfault your system by using this call.
+*/
+#define VALGRIND_GET_VBITS(zza,zzvbits,zznbytes)                 \
+   (__extension__({unsigned int _qzz_res;                        \
+    char* czza     = (char*)zza;                                 \
+    char* czzvbits = (char*)zzvbits;                             \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0,                      \
+                            VG_USERREQ__GET_VBITS,               \
+                            czza, czzvbits, zznbytes, 0, 0 );    \
+    _qzz_res;                                                    \
+   }))
+
+/* Set the validity data for addresses [zza..zza+zznbytes-1], copying it
+   from the provided zzvbits array.  Return values:
+      0   if not running on valgrind
+      1   success
+      2   [previously indicated unaligned arrays;  these are now allowed]
+      3   if any parts of zza/zzvbits are not addressable.
+   The metadata is not copied in cases 0, 2 or 3 so it should be
+   impossible to segfault your system by using this call.
+*/
+#define VALGRIND_SET_VBITS(zza,zzvbits,zznbytes)                 \
+   (__extension__({unsigned int _qzz_res;                        \
+    char* czza     = (char*)zza;                                 \
+    char* czzvbits = (char*)zzvbits;                             \
+    VALGRIND_DO_CLIENT_REQUEST(_qzz_res, 0,                      \
+                            VG_USERREQ__SET_VBITS,               \
+                            czza, czzvbits, zznbytes, 0, 0 );    \
+    _qzz_res;                                                    \
+   }))
+
+#endif
+
--- linux-2.6.22.5-old/arch/um/sys-i386/clone-uml.S	1969-12-31 16:00:00.000000000 -0800
+++ linux-2.6.22.5/arch/um/sys-i386/clone-uml.S	2007-12-10 10:03:42.000000000 -0800
@@ -0,0 +1,550 @@
+/* Copyright (C) 1996-2000,02,03,04,2005 Free Software Foundation, Inc.
+   This file is part of the GNU C Library.
+   Contributed by Richard Henderson (rth@tamu.edu)
+
+   The GNU C Library is free software; you can redistribute it and/or
+   modify it under the terms of the GNU Lesser General Public
+   License as published by the Free Software Foundation; either
+   version 2.1 of the License, or (at your option) any later version.
+
+   The GNU C Library is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   Lesser General Public License for more details.
+
+   You should have received a copy of the GNU Lesser General Public
+   License along with the GNU C Library; if not, write to the Free
+   Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA
+   02111-1307 USA.  */
+
+/* 2007-12-10 jreiser  Specialize for UML: clone only; do not cache getpid. */
+
+/* clone() is even more special than fork() as it mucks with stacks
+   and invokes a function in the right context after its all over.  */
+
+#define NO_UNDERSCORES
+//-----
+#ifndef C_LABEL
+
+/* Define a macro we can use to construct the asm name for a C symbol.  */
+#ifdef	NO_UNDERSCORES
+#ifdef	__STDC__
+#define C_LABEL(name)		name##:
+#else
+#define C_LABEL(name)		name/**/:
+#endif
+#else
+#ifdef	__STDC__
+#define C_LABEL(name)		_##name##:
+#else
+#define C_LABEL(name)		_/**/name/**/:
+#endif
+#endif
+
+#endif
+
+#ifdef __ASSEMBLER__
+/* Mark the end of function named SYM.  This is used on some platforms
+   to generate correct debugging information.  */
+#ifndef END
+#define END(sym)
+#endif
+
+#ifndef JUMPTARGET
+#define JUMPTARGET(sym)		sym
+#endif
+
+/* Makros to generate eh_frame unwind information.  */
+# ifdef HAVE_ASM_CFI_DIRECTIVES
+#  define cfi_startproc			.cfi_startproc
+#  define cfi_endproc			.cfi_endproc
+#  define cfi_def_cfa(reg, off)		.cfi_def_cfa reg, off
+#  define cfi_def_cfa_register(reg)	.cfi_def_cfa_register reg
+#  define cfi_def_cfa_offset(off)	.cfi_def_cfa_offset off
+#  define cfi_adjust_cfa_offset(off)	.cfi_adjust_cfa_offset off
+#  define cfi_offset(reg, off)		.cfi_offset reg, off
+#  define cfi_rel_offset(reg, off)	.cfi_rel_offset reg, off
+#  define cfi_register(r1, r2)		.cfi_register r1, r2
+#  define cfi_return_column(reg)	.cfi_return_column reg
+#  define cfi_restore(reg)		.cfi_restore reg
+#  define cfi_same_value(reg)		.cfi_same_value reg
+#  define cfi_undefined(reg)		.cfi_undefined reg
+#  define cfi_remember_state		.cfi_remember_state
+#  define cfi_restore_state		.cfi_restore_state
+#  define cfi_window_save		.cfi_window_save
+# else
+#  define cfi_startproc
+#  define cfi_endproc
+#  define cfi_def_cfa(reg, off)
+#  define cfi_def_cfa_register(reg)
+#  define cfi_def_cfa_offset(off)
+#  define cfi_adjust_cfa_offset(off)
+#  define cfi_offset(reg, off)
+#  define cfi_rel_offset(reg, off)
+#  define cfi_register(r1, r2)
+#  define cfi_return_column(reg)
+#  define cfi_restore(reg)
+#  define cfi_same_value(reg)
+#  define cfi_undefined(reg)
+#  define cfi_remember_state
+#  define cfi_restore_state
+#  define cfi_window_save
+# endif
+
+#else /* ! ASSEMBLER */
+# ifdef HAVE_ASM_CFI_DIRECTIVES
+#  define CFI_STRINGIFY(Name) CFI_STRINGIFY2 (Name)
+#  define CFI_STRINGIFY2(Name) #Name
+#  define CFI_STARTPROC	".cfi_startproc"
+#  define CFI_ENDPROC	".cfi_endproc"
+#  define CFI_DEF_CFA(reg, off)	\
+   ".cfi_def_cfa " CFI_STRINGIFY(reg) "," CFI_STRINGIFY(off)
+#  define CFI_DEF_CFA_REGISTER(reg) \
+   ".cfi_def_cfa_register " CFI_STRINGIFY(reg)
+#  define CFI_DEF_CFA_OFFSET(off) \
+   ".cfi_def_cfa_offset " CFI_STRINGIFY(off)
+#  define CFI_ADJUST_CFA_OFFSET(off) \
+   ".cfi_adjust_cfa_offset " CFI_STRINGIFY(off)
+#  define CFI_OFFSET(reg, off) \
+   ".cfi_offset " CFI_STRINGIFY(reg) "," CFI_STRINGIFY(off)
+#  define CFI_REL_OFFSET(reg, off) \
+   ".cfi_rel_offset " CFI_STRINGIFY(reg) "," CFI_STRINGIFY(off)
+#  define CFI_REGISTER(r1, r2) \
+   ".cfi_register " CFI_STRINGIFY(r1) "," CFI_STRINGIFY(r2)
+#  define CFI_RETURN_COLUMN(reg) \
+   ".cfi_return_column " CFI_STRINGIFY(reg)
+#  define CFI_RESTORE(reg) \
+   ".cfi_restore " CFI_STRINGIFY(reg)
+#  define CFI_UNDEFINED(reg) \
+   ".cfi_undefined " CFI_STRINGIFY(reg)
+#  define CFI_REMEMBER_STATE \
+   ".cfi_remember_state"
+#  define CFI_RESTORE_STATE \
+   ".cfi_restore_state"
+#  define CFI_WINDOW_SAVE \
+   ".cfi_window_save"
+# else
+#  define CFI_STARTPROC
+#  define CFI_ENDPROC
+#  define CFI_DEF_CFA(reg, off)
+#  define CFI_DEF_CFA_REGISTER(reg)
+#  define CFI_DEF_CFA_OFFSET(off)
+#  define CFI_ADJUST_CFA_OFFSET(off)
+#  define CFI_OFFSET(reg, off)
+#  define CFI_REL_OFFSET(reg, off)
+#  define CFI_REGISTER(r1, r2)
+#  define CFI_RETURN_COLUMN(reg)
+#  define CFI_RESTORE(reg)
+#  define CFI_UNDEFINED(reg)
+#  define CFI_REMEMBER_STATE
+#  define CFI_RESTORE_STATE
+#  define CFI_WINDOW_SAVE
+# endif
+
+#endif /* __ASSEMBLER__ */
+//-----
+
+#define HAVE_ELF 1
+#define	ASM_GLOBAL_DIRECTIVE .globl
+#  define C_SYMBOL_NAME(name) name
+#define CALL_MCOUNT /*empty*/
+#define SYS_ify(syscall_name)	__NR_##syscall_name
+#define ENTER_KERNEL int $0x80
+
+//-----sysdeps/unix/sysv/linux/i386/sysdep.h
+/* Linux uses a negative return value to indicate syscall errors,
+   unlike most Unices, which use the condition codes' carry flag.
+
+   Since version 2.1 the return value of a system call might be
+   negative even if the call succeeded.  E.g., the `lseek' system call
+   might return a large offset.  Therefore we must not anymore test
+   for < 0, but test for a real error by making sure the value in %eax
+   is a real error number.  Linus said he will make sure the no syscall
+   returns a value in -1 .. -4095 as a valid result so we can savely
+   test with -4095.  */
+
+/* We don't want the label for the error handle to be global when we define
+   it here.  */
+#ifdef PIC
+# define SYSCALL_ERROR_LABEL 0f
+#else
+# define SYSCALL_ERROR_LABEL syscall_error
+#endif
+
+#undef	PSEUDO
+#define	PSEUDO(name, syscall_name, args)				      \
+  .text;								      \
+  ENTRY (name)								      \
+    DO_CALL (syscall_name, args);					      \
+    cmpl $-4095, %eax;							      \
+    jae SYSCALL_ERROR_LABEL;						      \
+  L(pseudo_end):
+
+#undef	PSEUDO_END
+#define	PSEUDO_END(name)						      \
+  SYSCALL_ERROR_HANDLER							      \
+  END (name)
+
+#undef	PSEUDO_NOERRNO
+#define	PSEUDO_NOERRNO(name, syscall_name, args)			      \
+  .text;								      \
+  ENTRY (name)								      \
+    DO_CALL (syscall_name, args)
+
+#undef	PSEUDO_END_NOERRNO
+#define	PSEUDO_END_NOERRNO(name)					      \
+  END (name)
+
+#define ret_NOERRNO ret
+
+/* The function has to return the error code.  */
+#undef	PSEUDO_ERRVAL
+#define	PSEUDO_ERRVAL(name, syscall_name, args) \
+  .text;								      \
+  ENTRY (name)								      \
+    DO_CALL (syscall_name, args);					      \
+    negl %eax
+
+#undef	PSEUDO_END_ERRVAL
+#define	PSEUDO_END_ERRVAL(name) \
+  END (name)
+
+#define ret_ERRVAL ret
+
+#ifndef PIC
+# define SYSCALL_ERROR_HANDLER	/* Nothing here; code in sysdep.S is used.  */
+#else
+
+# if RTLD_PRIVATE_ERRNO
+#  define SYSCALL_ERROR_HANDLER						      \
+0:SETUP_PIC_REG(cx);							      \
+  addl $_GLOBAL_OFFSET_TABLE_, %ecx;					      \
+  xorl %edx, %edx;							      \
+  subl %eax, %edx;							      \
+  movl %edx, rtld_errno@GOTOFF(%ecx);					      \
+  orl $-1, %eax;							      \
+  jmp L(pseudo_end);
+
+# elif defined _LIBC_REENTRANT
+
+#  if USE___THREAD
+#   ifndef NOT_IN_libc
+#    define SYSCALL_ERROR_ERRNO __libc_errno
+#   else
+#    define SYSCALL_ERROR_ERRNO errno
+#   endif
+#   define SYSCALL_ERROR_HANDLER					      \
+0:SETUP_PIC_REG (cx);							      \
+  addl $_GLOBAL_OFFSET_TABLE_, %ecx;					      \
+  movl SYSCALL_ERROR_ERRNO@GOTNTPOFF(%ecx), %ecx;			      \
+  xorl %edx, %edx;							      \
+  subl %eax, %edx;							      \
+  SYSCALL_ERROR_HANDLER_TLS_STORE (%edx, %ecx);				      \
+  orl $-1, %eax;							      \
+  jmp L(pseudo_end);
+#   ifndef NO_TLS_DIRECT_SEG_REFS
+#    define SYSCALL_ERROR_HANDLER_TLS_STORE(src, destoff)		      \
+  movl src, %gs:(destoff)
+#   else
+#    define SYSCALL_ERROR_HANDLER_TLS_STORE(src, destoff)		      \
+  addl %gs:0, destoff;							      \
+  movl src, (destoff)
+#   endif
+#  else
+#   define SYSCALL_ERROR_HANDLER					      \
+0:pushl %ebx;								      \
+  cfi_adjust_cfa_offset (4);						      \
+  cfi_rel_offset (ebx, 0);						      \
+  SETUP_PIC_REG (bx);							      \
+  addl $_GLOBAL_OFFSET_TABLE_, %ebx;					      \
+  xorl %edx, %edx;							      \
+  subl %eax, %edx;							      \
+  pushl %edx;								      \
+  cfi_adjust_cfa_offset (4);						      \
+  PUSH_ERRNO_LOCATION_RETURN;						      \
+  call BP_SYM (__errno_location)@PLT;					      \
+  POP_ERRNO_LOCATION_RETURN;						      \
+  popl %ecx;								      \
+  cfi_adjust_cfa_offset (-4);						      \
+  popl %ebx;								      \
+  cfi_adjust_cfa_offset (-4);						      \
+  cfi_restore (ebx);							      \
+  movl %ecx, (%eax);							      \
+  orl $-1, %eax;							      \
+  jmp L(pseudo_end);
+/* A quick note: it is assumed that the call to `__errno_location' does
+   not modify the stack!  */
+#  endif
+# else
+/* Store (- %eax) into errno through the GOT.  */
+#  define SYSCALL_ERROR_HANDLER						      \
+0:SETUP_PIC_REG(cx);							      \
+  addl $_GLOBAL_OFFSET_TABLE_, %ecx;					      \
+  xorl %edx, %edx;							      \
+  subl %eax, %edx;							      \
+  movl errno@GOT(%ecx), %ecx;						      \
+  movl %edx, (%ecx);							      \
+  orl $-1, %eax;							      \
+  jmp L(pseudo_end);
+# endif	/* _LIBC_REENTRANT */
+#endif	/* PIC */
+
+//-----
+
+#  define weak_alias(name, aliasname) _weak_alias (name, aliasname)
+#  define _weak_alias(name, aliasname) \
+  extern __typeof (name) aliasname __attribute__ ((weak, alias (#name)));
+
+//-----#include <sysdep.h>
+#ifdef HAVE_ELF
+
+/* ELF uses byte-counts for .align, most others use log2 of count of bytes.  */
+#define ALIGNARG(log2) 1<<log2
+/* For ELF we need the `.type' directive to make shared libs work right.  */
+#define ASM_TYPE_DIRECTIVE(name,typearg) .type name,typearg;
+#define ASM_SIZE_DIRECTIVE(name) .size name,.-name;
+
+/* In ELF C symbols are asm symbols.  */
+#undef	NO_UNDERSCORES
+#define NO_UNDERSCORES
+
+#else
+
+#define ALIGNARG(log2) log2
+#define ASM_TYPE_DIRECTIVE(name,type)	/* Nothing is specified.  */
+#define ASM_SIZE_DIRECTIVE(name)	/* Nothing is specified.  */
+
+#endif
+
+
+/* Define an entry point visible from C.
+
+   There is currently a bug in gdb which prevents us from specifying
+   incomplete stabs information.  Fake some entries here which specify
+   the current source file.  */
+#define	ENTRY(name)							      \
+  STABS_CURRENT_FILE1("")						      \
+  STABS_CURRENT_FILE(name)						      \
+  ASM_GLOBAL_DIRECTIVE C_SYMBOL_NAME(name);				      \
+  ASM_TYPE_DIRECTIVE (C_SYMBOL_NAME(name),@function)			      \
+  .align ALIGNARG(4);							      \
+  STABS_FUN(name)							      \
+  C_LABEL(name)								      \
+  cfi_startproc;							      \
+  CALL_MCOUNT
+
+#undef	END
+#define END(name)							      \
+  cfi_endproc;								      \
+  ASM_SIZE_DIRECTIVE(name)						      \
+  STABS_FUN_END(name)
+
+#ifdef HAVE_CPP_ASM_DEBUGINFO
+/* Disable that goop, because we just pass -g through to the assembler
+   and it generates proper line number information directly.  */
+# define STABS_CURRENT_FILE1(name)
+# define STABS_CURRENT_FILE(name)
+# define STABS_FUN(name)
+# define STABS_FUN_END(name)
+#else
+/* Remove the following two lines once the gdb bug is fixed.  */
+#define STABS_CURRENT_FILE(name)					      \
+  STABS_CURRENT_FILE1 (#name)
+#define STABS_CURRENT_FILE1(name)					      \
+  1: .stabs name,100,0,0,1b;
+/* Emit stabs definition lines.  We use F(0,1) and define t(0,1) as `int',
+   the same way gcc does it.  */
+#define STABS_FUN(name) STABS_FUN2(name, name##:F(0,1))
+#define STABS_FUN2(name, namestr)					      \
+  .stabs "int:t(0,1)=r(0,1);-2147483648;2147483647;",128,0,0,0;		      \
+  .stabs #namestr,36,0,0,name;
+#define STABS_FUN_END(name)						      \
+  1: .stabs "",36,0,0,1b-name;
+#endif
+//-----
+
+#define _ERRNO_H	1
+//#include <bits/errno.h>
+
+//-----#include <asm-syntax.h>
+#undef ALIGN
+#if defined NOLOG_ALIGN || defined HAVE_ELF
+# define ALIGN(log) .align 1<<log
+#else
+# define ALIGN(log) .align log
+#endif
+
+#undef L
+#ifdef __ELF__
+# ifdef __STDC__
+#  define L(body) .L##body
+# else
+#  define L(body) .L/**/body
+# endif
+#else
+# ifdef __STDC__
+#  define L(body) L##body
+# else
+#  define L(body) L/**/body
+# endif
+#endif
+//-----
+
+//-----#include <bp-sym.h>
+#define BP_SYM(name) _BP_SYM (name)
+# define _BP_SYM(name) name
+//-----
+
+//-----#include <bp-asm.h>
+/* Unbounded pointers occupy one word.  */
+#   define PTR_SIZE 4
+/* Unbounded pointer return values are passed back in the register %eax.  */
+#   define RTN_SIZE 0
+/* Use simple return instruction for unbounded pointer values.  */
+#   define RET_PTR ret
+/* Don't maintain frame pointer chain for leaf assembler functions.  */
+#   define ENTER
+#   define LEAVE
+/* Stack space overhead of procedure-call linkage: return address only.  */
+#   define LINKAGE 4
+/* Stack offset of return address after calling ENTER.  */
+#   define PCOFF 0
+//-----
+
+#define EINVAL 22
+#define __NR_exit 1
+
+/* int clone(int (*fn)(void *arg), void *child_stack, int flags, void *arg,
+	     pid_t *ptid, struct user_desc *tls, pid_t *ctid); */
+
+#define PARMS	LINKAGE		/* no space for saved regs */
+#define FUNC	PARMS
+#define STACK	FUNC+4
+#define FLAGS	STACK+PTR_SIZE
+#define ARG	FLAGS+4
+#define PTID	ARG+PTR_SIZE
+#define TLS	PTID+PTR_SIZE
+#define CTID	TLS+PTR_SIZE
+
+#define __NR_clone 120
+#define SYS_clone 120
+
+#define CLONE_VM	0x00000100
+#define CLONE_THREAD	0x00010000
+
+        .text
+ENTRY (BP_SYM (clone))
+	/* Sanity check arguments.  */
+	movl	$-EINVAL,%eax
+	movl	FUNC(%esp),%ecx		/* no NULL function pointers */
+#ifdef PIC
+	jecxz	SYSCALL_ERROR_LABEL
+#else
+	testl	%ecx,%ecx
+	jz	SYSCALL_ERROR_LABEL
+#endif
+	movl	STACK(%esp),%ecx	/* no NULL stack pointers */
+#ifdef PIC
+	jecxz	SYSCALL_ERROR_LABEL
+#else
+	testl	%ecx,%ecx
+	jz	SYSCALL_ERROR_LABEL
+#endif
+
+	/* Insert the argument onto the new stack.  Make sure the new
+	   thread is started with an alignment of (mod 16).  */
+	andl	$0xfffffff0, %ecx
+	subl	$28,%ecx
+	movl	ARG(%esp),%eax		/* no negative argument counts */
+	movl	%eax,12(%ecx)
+
+	/* Save the function pointer as the zeroth argument.
+	   It will be popped off in the child in the ebx frobbing below.  */
+	movl	FUNC(%esp),%eax
+	movl	%eax,8(%ecx)
+	/* Don't leak any information.  */
+	movl	$0,4(%ecx)
+//#ifndef RESET_PID
+	movl	$0,(%ecx)
+//#endif
+
+	/* Do the system call */
+	pushl	%ebx
+	cfi_adjust_cfa_offset (4)
+	pushl	%esi
+	cfi_adjust_cfa_offset (4)
+	pushl	%edi
+	cfi_adjust_cfa_offset (4)
+
+	movl	TLS+12(%esp),%esi
+	cfi_rel_offset (esi, 4)
+	movl	PTID+12(%esp),%edx
+	movl	FLAGS+12(%esp),%ebx
+	cfi_rel_offset (ebx, 8)
+	movl	CTID+12(%esp),%edi
+	cfi_rel_offset (edi, 0)
+	movl	$SYS_ify(clone),%eax
+
+//#ifdef RESET_PID
+//	/* Remember the flag value.  */
+//	movl	%ebx, (%ecx)
+//#endif
+
+	/* End FDE now, because in the child the unwind info will be
+	   wrong.  */
+	cfi_endproc
+
+	int	$0x80
+	popl	%edi
+	popl	%esi
+	popl	%ebx
+
+	test	%eax,%eax
+	jl	SYSCALL_ERROR_LABEL
+	jz	L(thread_start)
+
+L(pseudo_end):
+	ret
+
+L(thread_start):
+	/* Note: %esi is zero.  */
+	movl	%esi,%ebp	/* terminate the stack frame */
+//#ifdef RESET_PID
+//	testl	$CLONE_THREAD, %edi
+//	je	L(newpid)
+//L(haspid):
+//#endif
+	call	*%ebx
+#ifdef PIC
+	call	L(here)
+L(here):
+	popl	%ebx
+	addl	$_GLOBAL_OFFSET_TABLE_+[.-L(here)], %ebx
+#endif
+	movl	%eax, %ebx
+	movl	$SYS_ify(exit), %eax
+	ENTER_KERNEL
+
+//#ifdef RESET_PID
+//	.subsection 2
+//L(newpid):
+//	testl	$CLONE_VM, %edi
+//	movl	$-1, %eax
+//	jne	L(nomoregetpid)
+//	movl	$SYS_ify(getpid), %eax
+//	ENTER_KERNEL
+//L(nomoregetpid):
+//	movl	%eax, %gs:PID
+//	movl	%eax, %gs:TID
+//	jmp	L(haspid)
+//	.previous
+//#endif
+
+	cfi_startproc
+syscall_error:
+	orl $~0,%eax
+0:
+	jmp 0b  // XXX 2007-12-10 jreiser
+
+
+PSEUDO_END (BP_SYM (clone))
diff -ur linux-2.6.22.5-old/arch/arm/plat-s3c24xx/dma.c linux-2.6.22.5/arch/arm/plat-s3c24xx/dma.c
--- linux-2.6.22.5-old/arch/arm/plat-s3c24xx/dma.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/arm/plat-s3c24xx/dma.c	2007-12-16 13:24:56.000000000 -0800
@@ -465,7 +465,7 @@
 	pr_debug("%s: id=%p, data=%08x, size=%d\n",
 		 __FUNCTION__, id, (unsigned int)data, size);
 
-	buf = kmem_cache_alloc(dma_kmem, GFP_ATOMIC);
+	buf = kmem_cache_alloc(dma_kmem, GFP_ATOMIC, sizeof(*buf));
 	if (buf == NULL) {
 		pr_debug("%s: out of memory (%ld alloc)\n",
 			 __FUNCTION__, (long)sizeof(*buf));
diff -ur linux-2.6.22.5-old/arch/arm26/mm/memc.c linux-2.6.22.5/arch/arm26/mm/memc.c
--- linux-2.6.22.5-old/arch/arm26/mm/memc.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/arm26/mm/memc.c	2007-12-16 13:24:56.000000000 -0800
@@ -36,7 +36,7 @@
  */
 static inline pgd_t *alloc_pgd_table(void)
 {
-	void *pg2k = kmem_cache_alloc(pgd_cache, GFP_KERNEL);
+	void *pg2k = kmem_cache_alloc(pgd_cache, GFP_KERNEL, sizeof(**pg2k));
 
 	if (pg2k)
 		pg2k += MEMC_TABLE_SIZE;
diff -ur linux-2.6.22.5-old/arch/i386/mm/highmem.c linux-2.6.22.5/arch/i386/mm/highmem.c
--- linux-2.6.22.5-old/arch/i386/mm/highmem.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/i386/mm/highmem.c	2007-12-11 13:34:01.000000000 -0800
@@ -37,13 +37,17 @@
 	idx = type + KM_TYPE_NR*smp_processor_id();
 	BUG_ON(!pte_none(*(kmap_pte-idx)));
 
-	if (!PageHighMem(page))
-		return page_address(page);
+	if (!PageHighMem(page)) {
+		vaddr = page_address(page);
+		VALGRIND_MALLOCLIKE_BLOCK(vaddr, PAGE_SIZE, 0, 0);
+		return vaddr;
+	}
 
 	vaddr = __fix_to_virt(FIX_KMAP_BEGIN + idx);
 	set_pte(kmap_pte-idx, mk_pte(page, prot));
 	arch_flush_lazy_mmu_mode();
 
+	VALGRIND_MALLOCLIKE_BLOCK(vaddr, PAGE_SIZE, 0, 0);
 	return (void*) vaddr;
 }
 
diff -ur linux-2.6.22.5-old/arch/i386/mm/pgtable.c linux-2.6.22.5/arch/i386/mm/pgtable.c
--- linux-2.6.22.5-old/arch/i386/mm/pgtable.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/i386/mm/pgtable.c	2007-12-16 13:24:56.000000000 -0800
@@ -307,7 +307,7 @@
 			       (void *)pgd_page_vaddr(swapper_pg_dir[idx]),
 			       sizeof(pmd_t) * PTRS_PER_PMD);
 	} else
-		pmd = kmem_cache_alloc(pmd_cache, GFP_KERNEL);
+		pmd = kmem_cache_alloc(pmd_cache, GFP_KERNEL, sizeof(*pmd));
 
 	return pmd;
 }
diff -ur linux-2.6.22.5-old/arch/ia64/ia32/sys_ia32.c linux-2.6.22.5/arch/ia64/ia32/sys_ia32.c
--- linux-2.6.22.5-old/arch/ia64/ia32/sys_ia32.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/ia64/ia32/sys_ia32.c	2007-12-16 13:24:56.000000000 -0800
@@ -451,7 +451,7 @@
 	}
 
 	/* new a partial_page */
-	pp = kmem_cache_alloc(partial_page_cachep, GFP_KERNEL);
+	pp = kmem_cache_alloc(partial_page_cachep, GFP_KERNEL, sizeof(*pp));
 	if (!pp)
 		return -ENOMEM;
 	pp->base = pstart;
@@ -533,7 +533,7 @@
 	}
 
 	/* new a partial_page */
-	pp = kmem_cache_alloc(partial_page_cachep, GFP_KERNEL);
+	pp = kmem_cache_alloc(partial_page_cachep, GFP_KERNEL, sizeof(*pp));
 	if (!pp)
 		return -ENOMEM;
 	pp->base = pstart;
@@ -721,7 +721,7 @@
 	prev = NULL;
 
 	for (pp = current->thread.ppl->pp_head; pp; pp = pp->next) {
-		tmp = kmem_cache_alloc(partial_page_cachep, GFP_KERNEL);
+		tmp = kmem_cache_alloc(partial_page_cachep, GFP_KERNEL, sizeof(*tmp));
 		if (!tmp)
 			return -ENOMEM;
 		*tmp = *pp;
diff -ur linux-2.6.22.5-old/arch/powerpc/kernel/rtas_flash.c linux-2.6.22.5/arch/powerpc/kernel/rtas_flash.c
--- linux-2.6.22.5-old/arch/powerpc/kernel/rtas_flash.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/powerpc/kernel/rtas_flash.c	2007-12-16 13:24:56.000000000 -0800
@@ -315,7 +315,7 @@
 	 * proc file
 	 */
 	if (uf->flist == NULL) {
-		uf->flist = kmem_cache_alloc(flash_block_cache, GFP_KERNEL);
+		uf->flist = kmem_cache_alloc(flash_block_cache, GFP_KERNEL, sizeof(*uf->flist));
 		if (!uf->flist)
 			return -ENOMEM;
 	}
@@ -326,7 +326,7 @@
 	next_free = fl->num_blocks;
 	if (next_free == FLASH_BLOCKS_PER_NODE) {
 		/* Need to allocate another block_list */
-		fl->next = kmem_cache_alloc(flash_block_cache, GFP_KERNEL);
+		fl->next = kmem_cache_alloc(flash_block_cache, GFP_KERNEL, sizeof(*fl->next));
 		if (!fl->next)
 			return -ENOMEM;
 		fl = fl->next;
@@ -335,7 +335,7 @@
 
 	if (count > RTAS_BLK_SIZE)
 		count = RTAS_BLK_SIZE;
-	p = kmem_cache_alloc(flash_block_cache, GFP_KERNEL);
+	p = kmem_cache_alloc(flash_block_cache, GFP_KERNEL, sizeof(*p));
 	if (!p)
 		return -ENOMEM;
 	
diff -ur linux-2.6.22.5-old/arch/powerpc/platforms/cell/spufs/inode.c linux-2.6.22.5/arch/powerpc/platforms/cell/spufs/inode.c
--- linux-2.6.22.5-old/arch/powerpc/platforms/cell/spufs/inode.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/powerpc/platforms/cell/spufs/inode.c	2007-12-16 13:24:56.000000000 -0800
@@ -49,7 +49,7 @@
 {
 	struct spufs_inode_info *ei;
 
-	ei = kmem_cache_alloc(spufs_inode_cache, GFP_KERNEL);
+	ei = kmem_cache_alloc(spufs_inode_cache, GFP_KERNEL, sizeof(*ei));
 	if (!ei)
 		return NULL;
 
diff -ur linux-2.6.22.5-old/arch/sh/kernel/cpu/sh4/sq.c linux-2.6.22.5/arch/sh/kernel/cpu/sh4/sq.c
--- linux-2.6.22.5-old/arch/sh/kernel/cpu/sh4/sq.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/sh/kernel/cpu/sh4/sq.c	2007-12-16 13:24:56.000000000 -0800
@@ -160,7 +160,7 @@
 	phys &= PAGE_MASK;
 	size = PAGE_ALIGN(end + 1) - phys;
 
-	map = kmem_cache_alloc(sq_cache, GFP_KERNEL);
+	map = kmem_cache_alloc(sq_cache, GFP_KERNEL, sizeof(*map));
 	if (unlikely(!map))
 		return -ENOMEM;
 
diff -ur linux-2.6.22.5-old/arch/sh/mm/pmb.c linux-2.6.22.5/arch/sh/mm/pmb.c
--- linux-2.6.22.5-old/arch/sh/mm/pmb.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/sh/mm/pmb.c	2007-12-16 13:24:56.000000000 -0800
@@ -99,7 +99,7 @@
 {
 	struct pmb_entry *pmbe;
 
-	pmbe = kmem_cache_alloc(pmb_cache, GFP_KERNEL);
+	pmbe = kmem_cache_alloc(pmb_cache, GFP_KERNEL, sizeof(*pmbe));
 	if (!pmbe)
 		return ERR_PTR(-ENOMEM);
 
diff -ur linux-2.6.22.5-old/arch/sparc64/mm/tsb.c linux-2.6.22.5/arch/sparc64/mm/tsb.c
--- linux-2.6.22.5-old/arch/sparc64/mm/tsb.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/sparc64/mm/tsb.c	2007-12-16 13:24:56.000000000 -0800
@@ -320,7 +320,7 @@
 	if (new_size > (PAGE_SIZE * 2))
 		gfp_flags = __GFP_NOWARN | __GFP_NORETRY;
 
-	new_tsb = kmem_cache_alloc(tsb_caches[new_cache_index], gfp_flags);
+	new_tsb = kmem_cache_alloc(tsb_caches[new_cache_index], gfp_flags, sizeof(*new_tsb));
 	if (unlikely(!new_tsb)) {
 		/* Not being able to fork due to a high-order TSB
 		 * allocation failure is very bad behavior.  Just back
diff -ur linux-2.6.22.5-old/arch/um/drivers/ubd_kern.c linux-2.6.22.5/arch/um/drivers/ubd_kern.c
--- linux-2.6.22.5-old/arch/um/drivers/ubd_kern.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/um/drivers/ubd_kern.c	2007-12-04 14:13:12.000000000 -0800
@@ -1067,6 +1067,12 @@
 	io_req->length = len;
 	io_req->error = 0;
 	io_req->sector_mask = 0;
+/* At startup, the maximum .length is 64K, and blk_queue_max_sectors()
+ * has not been called yet.  So do_io() could require 64K/(1<<9) = 128 bits:
+ * 32 in sector_mask, 64 in cow_offset, 32 in bitmap_words[0].
+ * 2007-12-04 jreiser (valgrind/memcheck)
+ */
+	io_req->bitmap_words[0] = 0;
 
 	io_req->op = (rq_data_dir(req) == READ) ? UBD_READ : UBD_WRITE;
 	io_req->offsets[0] = 0;
diff -ur linux-2.6.22.5-old/arch/um/kernel/mem.c linux-2.6.22.5/arch/um/kernel/mem.c
--- linux-2.6.22.5-old/arch/um/kernel/mem.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/um/kernel/mem.c	2007-12-12 11:03:17.000000000 -0800
@@ -340,6 +340,7 @@
 	pgd_t *pgd = (pgd_t *)__get_free_page(GFP_KERNEL);
 
 	if (pgd) {
+		VALGRIND_MAKE_MEM_DEFINED(pgd, PTRS_PER_PGD * sizeof(pgd_t));
 		memset(pgd, 0, USER_PTRS_PER_PGD * sizeof(pgd_t));
 		memcpy(pgd + USER_PTRS_PER_PGD, 
 		       swapper_pg_dir + USER_PTRS_PER_PGD, 
diff -ur linux-2.6.22.5-old/arch/um/kernel/process.c linux-2.6.22.5/arch/um/kernel/process.c
--- linux-2.6.22.5-old/arch/um/kernel/process.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/um/kernel/process.c	2007-12-18 15:31:43.000000000 -0800
@@ -48,6 +48,8 @@
 #include "choose-mode.h"
 #include "um_malloc.h"
 
+#include "valgrind.h"
+
 /* This is a per-cpu array.  A processor only modifies its entry and it only
  * cares about its entry, so it's OK if another processor is modifying its
  * entry.
@@ -75,6 +77,8 @@
 	free_pages(stack, order);
 }
 
+#include "asm/asm-offsets.h"
+
 unsigned long alloc_stack(int order, int atomic)
 {
 	unsigned long page;
@@ -85,10 +89,31 @@
 	page = __get_free_pages(flags, order);
 	if(page == 0)
 		return 0;
+//printf("alloc_stack\n");
+//subsumed	VALGRIND_MALLOCLIKE_BLOCK(page, UM_THREAD_SIZE, 0, 0);
 	stack_protections(page);
 	return page;
 }
 
+struct thread_info *alloc_thread_info(struct task_struct *tsk)
+{
+	struct thread_info *const ti = (struct thread_info *)
+		kmalloc(THREAD_SIZE, GFP_KERNEL);
+//	if (ti)
+//		VALGRIND_STACK_REGISTER(ti, 1+ ti);
+//
+	return ti;
+}
+
+#define SIZEOF_THREAD_INFO (8*sizeof(void *))
+
+void free_thread_info(struct thread_info *ti)
+{
+//printf("free_thread_info ti=%p  task=%p  stack=%p\n", ti, ti->task, ti->task->stack);
+	VALGRIND_STACK_DEREGADDR(SIZEOF_THREAD_INFO + ti->task->stack);
+	kfree(ti);
+}
+
 int kernel_thread(int (*fn)(void *), void * arg, unsigned long flags)
 {
 	int pid;
diff -ur linux-2.6.22.5-old/arch/um/kernel/skas/mmu.c linux-2.6.22.5/arch/um/kernel/skas/mmu.c
--- linux-2.6.22.5-old/arch/um/kernel/skas/mmu.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/um/kernel/skas/mmu.c	2007-12-18 15:22:34.000000000 -0800
@@ -115,10 +115,13 @@
 		to_mm->id.u.mm_fd = ret;
 	}
 	else {
-		if(from_mm)
+		if(from_mm) {
 			to_mm->id.u.pid = copy_context_skas0(stack,
 							     from_mm->id.u.pid);
-		else to_mm->id.u.pid = start_userspace(stack);
+		}
+		else {
+			to_mm->id.u.pid = start_userspace(stack);
+		}
 	}
 
 	ret = init_new_ldt(to_mm, from_mm);
@@ -137,6 +140,8 @@
 	return ret;
 }
 
+#define SIZEOF_THREAD_INFO (8*sizeof(void *))
+
 void destroy_context_skas(struct mm_struct *mm)
 {
 	struct mmu_context_skas *mmu = &mm->context.skas;
@@ -147,6 +152,7 @@
 		os_kill_ptraced_process(mmu->id.u.pid, 1);
 
 	if(!proc_mm || !ptrace_faultinfo){
+		VALGRIND_STACK_DEREGADDR(SIZEOF_THREAD_INFO + mmu->id.stack);
 		free_page(mmu->id.stack);
 		pte_lock_deinit(virt_to_page(mmu->last_page_table));
 		pte_free_kernel((pte_t *) mmu->last_page_table);
diff -ur linux-2.6.22.5-old/arch/um/kernel/skas/process.c linux-2.6.22.5/arch/um/kernel/skas/process.c
--- linux-2.6.22.5-old/arch/um/kernel/skas/process.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/um/kernel/skas/process.c	2007-12-12 13:24:00.000000000 -0800
@@ -21,6 +21,8 @@
 #include "mode.h"
 #include "registers.h"
 
+#include "valgrind.h"
+
 void switch_to_skas(void *prev, void *next)
 {
 	struct task_struct *from, *to;
diff -ur linux-2.6.22.5-old/arch/um/kernel/skas/uaccess.c linux-2.6.22.5/arch/um/kernel/skas/uaccess.c
--- linux-2.6.22.5-old/arch/um/kernel/skas/uaccess.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/um/kernel/skas/uaccess.c	2007-12-16 13:38:18.000000000 -0800
@@ -15,6 +15,7 @@
 #include "asm/uaccess.h"
 #include "kern_util.h"
 #include "os.h"
+#include "memcheck.h"
 
 extern void *um_virt_to_phys(struct task_struct *task, unsigned long addr,
 			     pte_t *pte_out);
@@ -139,16 +140,35 @@
 	return(0);
 }
 
+static struct CFU_history {
+   void *ra;
+   void *to;
+   void *from;
+   int n;
+} cfu_history[1024];
+static unsigned cfu_ndx = 0;
+
 int copy_from_user_skas(void *to, const void __user *from, int n)
 {
+cfu_history[cfu_ndx].ra = __builtin_return_address(0);
+cfu_history[cfu_ndx].to = to;
+cfu_history[cfu_ndx].from = from;
+cfu_history[cfu_ndx].n = n;
+cfu_ndx = (1+ cfu_ndx) &~ -1024;
 	if(segment_eq(get_fs(), KERNEL_DS)){
 		memcpy(to, (__force void*)from, n);
 		return(0);
 	}
 
-	return(access_ok(VERIFY_READ, from, n) ?
-	       buffer_op((unsigned long) from, n, 0, copy_chunk_from_user, &to):
-	       n);
+	if (access_ok(VERIFY_READ, from, n)) {
+		void *const to0 = to;
+		int uw = buffer_op((unsigned long) from, n, 0, copy_chunk_from_user, &to);
+		VALGRIND_MAKE_MEM_DEFINED(to0, n - uw);
+		return uw;
+	}
+	else {
+	       return n;
+	}
 }
 
 static int copy_chunk_to_user(unsigned long to, int len, void *arg)
@@ -177,6 +197,7 @@
 	char **to_ptr = arg, *to = *to_ptr;
 	int n;
 
+	VALGRIND_MAKE_MEM_DEFINED(from, len);  // XXX 2007-12-11 jreiser  UGH!
 	strncpy(to, (void *) from, len);
 	n = strnlen(to, len);
 	*to_ptr += n;
diff -ur linux-2.6.22.5-old/arch/um/kernel/um_arch.c linux-2.6.22.5/arch/um/kernel/um_arch.c
--- linux-2.6.22.5-old/arch/um/kernel/um_arch.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/um/kernel/um_arch.c	2007-12-12 13:21:26.000000000 -0800
@@ -42,6 +42,8 @@
 #include "skas.h"
 #endif
 
+#include "valgrind.h"
+
 #define DEFAULT_COMMAND_LINE "root=98:0"
 
 /* Changed in add_arg and setup_arch, which run before SMP is started */
@@ -346,6 +348,7 @@
 	unsigned int i, add;
 	char * mode;
 
+	/*VALGRIND_PRINTF("linux_main %d 0x%lx\n", argc, argv);*/
 	for (i = 1; i < argc; i++){
 		if((i == 1) && (argv[i][0] == ' ')) continue;
 		add = 1;
@@ -385,7 +388,6 @@
 
 	host_task_size = CHOOSE_MODE_PROC(set_task_sizes_tt,
 					  set_task_sizes_skas, &task_size);
-
 	/*
 	 * Setting up handlers to 'sig_info' struct
 	 */
diff -ur linux-2.6.22.5-old/arch/um/os-Linux/aio.c linux-2.6.22.5/arch/um/os-Linux/aio.c
--- linux-2.6.22.5-old/arch/um/os-Linux/aio.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/um/os-Linux/aio.c	2007-08-27 17:07:25.000000000 -0700
@@ -76,8 +76,7 @@
 				.aio_nbytes	= len,
 				.aio_offset	= offset,
 				.aio_reserved1	= 0,
-				.aio_reserved2	= 0,
-				.aio_reserved3	= 0 });
+				.aio_reserved2	= 0});
 
 	switch(type){
 	case AIO_READ:
diff -ur linux-2.6.22.5-old/arch/um/os-Linux/helper.c linux-2.6.22.5/arch/um/os-Linux/helper.c
--- linux-2.6.22.5-old/arch/um/os-Linux/helper.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/um/os-Linux/helper.c	2007-12-03 16:56:18.000000000 -0800
@@ -129,7 +129,7 @@
 		return -ENOMEM;
 
 	sp = stack + (UM_KERN_PAGE_SIZE << stack_order) - sizeof(void *);
-	pid = clone(proc, (void *) sp, flags | SIGCHLD, arg);
+	pid = clone(proc, (void *) sp, flags | SIGCHLD, arg, 0,0,0);
 	if (pid < 0) {
 		err = -errno;
 		printk("run_helper_thread : clone failed, errno = %d\n",
diff -ur linux-2.6.22.5-old/arch/um/os-Linux/mem.c linux-2.6.22.5/arch/um/os-Linux/mem.c
--- linux-2.6.22.5-old/arch/um/os-Linux/mem.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/um/os-Linux/mem.c	2007-12-05 09:00:17.000000000 -0800
@@ -211,7 +211,7 @@
 	int fd, err;
 	char zero;
 
-	fd = make_tempfile(TEMPNAME_TEMPLATE, NULL, 1);
+	fd = make_tempfile(TEMPNAME_TEMPLATE, NULL, 0/*jreiser*/);
 	if(fd < 0) {
 		exit(1);
 	}
diff -ur linux-2.6.22.5-old/arch/um/os-Linux/sigio.c linux-2.6.22.5/arch/um/os-Linux/sigio.c
--- linux-2.6.22.5-old/arch/um/os-Linux/sigio.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/um/os-Linux/sigio.c	2007-12-13 14:11:12.000000000 -0800
@@ -125,7 +125,7 @@
 {
 	unsigned long flags;
 	int n;
-	char c;
+	char c = 0xE6;  /* 2007-12-13 (valgrind/memcheck) Initialize. */
 
 	flags = set_signals(0);
 	n = write(sigio_private[0], &c, sizeof(c));
diff -ur linux-2.6.22.5-old/arch/um/os-Linux/skas/process.c linux-2.6.22.5/arch/um/os-Linux/skas/process.c
--- linux-2.6.22.5-old/arch/um/os-Linux/skas/process.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/um/os-Linux/skas/process.c	2007-12-12 21:35:55.000000000 -0800
@@ -36,6 +36,10 @@
 #include "kern_constants.h"
 #include "as-layout.h"
 
+#include "valgrind.h"
+#include "memcheck.h"
+#define SIZEOF_THREAD_INFO (8*sizeof(void *))
+
 int is_skas_winch(int pid, int fd, void *data)
 {
 	if(pid != os_getpgrp())
@@ -45,17 +49,26 @@
 	return(1);
 }
 
-static int ptrace_dump_regs(int pid)
+int ptrace_dump_regs(int pid, char const *msg)
 {
         unsigned long regs[MAX_REG_NR];
         int i;
 
+printf("ptrace_dump_regs %s\n", msg);
         if(ptrace(PTRACE_GETREGS, pid, 0, regs) < 0)
                 return -errno;
         else {
-                printk("Stub registers -\n");
+		unsigned *pc = (unsigned *)regs[12];
+		unsigned *sp = (unsigned *)regs[15];
+		unsigned long data = ptrace(PTRACE_PEEKTEXT, pid, pc, 0);
+                printk("Stub registers   pid=%d\n", pid);
                 for(i = 0; i < ARRAY_SIZE(regs); i++)
-                        printk("\t%d - %lx\n", i, regs[i]);
+			printk("\t%d - %lx\n", i, regs[i]);
+                printk("%p - %lx\n", (void *)pc, data);
+		for(i = 0; i < 64; i++) {
+			data = ptrace(PTRACE_PEEKDATA, pid, i+sp, 0);
+			printk("\t%p - %lx\n", (void *)(i+sp), data);
+		}
         }
 
         return 0;
@@ -70,17 +83,32 @@
 /* Signals that the stub will finish with - anything else is an error */
 #define STUB_DONE_MASK ((1 << SIGUSR1) | (1 << SIGTRAP))
 
+#include "valgrind.h"
+
+static void printpc(int pid)
+{
+  unsigned long regs[MAX_REG_NR];
+  ptrace(PTRACE_GETREGS, pid, 0, regs);
+  unsigned *pc = (unsigned *)regs[12];
+  unsigned long data = ptrace(PTRACE_PEEKTEXT, pid, pc, 0);
+  printf("%p / %lx\n", (void *)pc, data);
+}
+
 void wait_stub_done(int pid)
 {
 	int n, status, err;
 
+	status = 0;  // XXX 2007-23-12 jreiser
 	while(1){
 		CATCH_EINTR(n = waitpid(pid, &status, WUNTRACED));
-		if((n < 0) || !WIFSTOPPED(status))
+		if((n < 0) || !WIFSTOPPED(status)) {
+			printf("wait_stub_done A status=0x%x\n", status);
 			goto bad_wait;
+		}
 
-		if(((1 << WSTOPSIG(status)) & STUB_SIG_MASK) == 0)
+		if(((1 << WSTOPSIG(status)) & STUB_SIG_MASK) == 0) {
 			break;
+		}
 
 		err = ptrace(PTRACE_CONT, pid, 0, 0);
 		if(err)
@@ -92,9 +120,10 @@
 		return;
 
 bad_wait:
-	err = ptrace_dump_regs(pid);
+	err = ptrace_dump_regs(pid, "wait_stub_done");
 	if(err)
 		printk("Failed to get registers from stub, errno = %d\n", -err);
+//if (pid) for(;;) ;
 	panic("wait_stub_done : failed to wait for SIGUSR1/SIGTRAP, pid = %d, "
 	      "n = %d, errno = %d, status = 0x%x\n", pid, n, errno, status);
 }
@@ -104,7 +133,6 @@
 void get_skas_faultinfo(int pid, struct faultinfo * fi)
 {
 	int err;
-
 	if(ptrace_faultinfo){
 		err = ptrace(PTRACE_FAULTINFO, pid, 0, fi);
 		if(err)
@@ -137,6 +165,8 @@
 	segv(regs->skas.faultinfo, 0, 1, NULL);
 }
 
+unsigned vg_status;
+
 /*To use the same value of using_sysemu as the caller, ask it that value (in local_using_sysemu)*/
 static void handle_trap(int pid, union uml_pt_regs *regs, int local_using_sysemu)
 {
@@ -159,9 +189,10 @@
 			      "errno = %d\n", errno);
 
 		CATCH_EINTR(err = waitpid(pid, &status, WUNTRACED));
+VALGRIND_GET_VBITS(&status, &vg_status, sizeof(status));
 		if((err < 0) || !WIFSTOPPED(status) ||
 		   (WSTOPSIG(status) != SIGTRAP + 0x80)){
-                        err = ptrace_dump_regs(pid);
+                        err = ptrace_dump_regs(pid, "handle_trap");
                         if(err)
                                 printk("Failed to get registers from process, "
                                        "errno = %d\n", -err);
@@ -180,20 +211,23 @@
 	void *addr;
 	int err;
 
+//VALGRIND_PRINTF("userspace_tramp stack=%p\n", stack);
 	ptrace(PTRACE_TRACEME, 0, 0, 0);
-
+//VALGRIND_PRINTF("userspace_tramp A");
 	init_new_thread_signals();
 	err = set_interval(1);
 	if(err)
 		panic("userspace_tramp - setting timer failed, errno = %d\n",
 		      err);
 
+//VALGRIND_PRINTF("userspace_tramp B");
 	if(!proc_mm){
 		/* This has a pte, but it can't be mapped in with the usual
 		 * tlb_flush mechanism because this is part of that mechanism
 		 */
 		int fd;
 		__u64 offset;
+//VALGRIND_PRINTF("userspace_tramp C");
 		fd = phys_mapping(to_phys(&__syscall_stub_start), &offset);
 		addr = mmap64((void *) UML_CONFIG_STUB_CODE, UM_KERN_PAGE_SIZE,
 			      PROT_EXEC, MAP_FIXED | MAP_PRIVATE, fd, offset);
@@ -203,6 +237,7 @@
 			exit(1);
 		}
 
+//VALGRIND_PRINTF("userspace_tramp D");
 		if(stack != NULL){
 			fd = phys_mapping(to_phys(stack), &offset);
 			addr = mmap((void *) UML_CONFIG_STUB_DATA,
@@ -215,6 +250,7 @@
 			}
 		}
 	}
+//VALGRIND_PRINTF("userspace_tramp E");
 	if(!ptrace_faultinfo && (stack != NULL)){
 		struct sigaction sa;
 
@@ -222,6 +258,7 @@
 				  (unsigned long) stub_segv_handler -
 				  (unsigned long) &__syscall_stub_start;
 
+//VALGRIND_PRINTF("userspace_tramp F");
 		set_sigstack((void *) UML_CONFIG_STUB_DATA, UM_KERN_PAGE_SIZE);
 		sigemptyset(&sa.sa_mask);
 		sigaddset(&sa.sa_mask, SIGIO);
@@ -237,10 +274,14 @@
 			      "failed - errno = %d\n", errno);
 	}
 
+//VALGRIND_PRINTF("userspace_tramp G");
 	os_stop_process(os_getpid());
+//VALGRIND_PRINTF("userspace_tramp H");
 	return(0);
 }
 
+#include "valgrind.h"
+
 /* Each element set once, and only accessed by a single processor anyway */
 #undef NR_CPUS
 #define NR_CPUS 1
@@ -258,8 +299,11 @@
 	if(stack == MAP_FAILED)
 		panic("start_userspace : mmap failed, errno = %d", errno);
 	sp = (unsigned long) stack + UM_KERN_PAGE_SIZE - sizeof(void *);
+	VALGRIND_MALLOCLIKE_BLOCK(stack, SIZEOF_THREAD_INFO, 0, 0);
+	VALGRIND_STACK_REGISTER(SIZEOF_THREAD_INFO + stack,
+		UM_KERN_PAGE_SIZE + stack - sizeof(void *));
 
-	flags = CLONE_FILES | SIGCHLD;
+	flags = CLONE_FILES | SIGCHLD | CLONE_CHILD_LETGO;
 	if(proc_mm) flags |= CLONE_VM;
 	pid = clone(userspace_tramp, (void *) sp, flags, (void *) stub_stack);
 	if(pid < 0)
@@ -268,18 +312,21 @@
 	do {
 		CATCH_EINTR(n = waitpid(pid, &status, WUNTRACED));
 		if(n < 0)
-			panic("start_userspace : wait failed, errno = %d",
+			panic("start_userspace : wait failed, errno = %d ",
 			      errno);
 	} while(WIFSTOPPED(status) && (WSTOPSIG(status) == SIGVTALRM));
 
-	if(!WIFSTOPPED(status) || (WSTOPSIG(status) != SIGSTOP))
-		panic("start_userspace : expected SIGSTOP, got status = %d",
+	if(!WIFSTOPPED(status) || (WSTOPSIG(status) != SIGSTOP)) {
+		panic("start_userspace : expected SIGSTOP, got status = 0x%x ",
 		      status);
+	}
 
 	if (ptrace(PTRACE_OLDSETOPTIONS, pid, NULL, (void *)PTRACE_O_TRACESYSGOOD) < 0)
 		panic("start_userspace : PTRACE_OLDSETOPTIONS failed, errno=%d\n",
 		      errno);
 
+	VALGRIND_STACK_DEREGADDR(SIZEOF_THREAD_INFO + stack);
+	VALGRIND_FREELIKE_BLOCK(stack, SIZEOF_THREAD_INFO);
 	if(munmap(stack, UM_KERN_PAGE_SIZE) < 0)
 		panic("start_userspace : munmap failed, errno = %d\n", errno);
 
@@ -292,7 +339,7 @@
 	/* To prevent races if using_sysemu changes under us.*/
 	int local_using_sysemu;
 
-	while(1){
+	for (;;) {
 		restore_registers(pid, regs);
 
 		/* Now we set local_using_sysemu to be used for one loop */
@@ -324,7 +371,9 @@
 					get_skas_faultinfo(pid, &regs->skas.faultinfo);
 					(*sig_info[SIGSEGV])(SIGSEGV, regs);
 				}
-				else handle_segv(pid, regs);
+				else {
+					handle_segv(pid, regs);
+				}
 				break;
 			case SIGTRAP + 0x80:
 			        handle_trap(pid, regs, local_using_sysemu);
@@ -376,6 +425,8 @@
 
 __initcall(init_thread_regs);
 
+#include "valgrind.h"
+
 int copy_context_skas0(unsigned long new_stack, int pid)
 {
 	int err;
@@ -385,6 +436,8 @@
 	__u64 new_offset;
 	int new_fd = phys_mapping(to_phys((void *)new_stack), &new_offset);
 
+//VALGRIND_PRINTF_BACKTRACE("copy_context_skas0 new_stack=%p  pid=%d\n",
+//   (void *)new_stack, pid);
 	/* prepare offset and fd of child's stack as argument for parent's
 	 * and child's mmap2 calls
 	 */
@@ -495,6 +548,13 @@
 	(*buf)[0].JB_IP = (unsigned long) handler;
 	(*buf)[0].JB_SP = (unsigned long) stack + UM_THREAD_SIZE -
 		sizeof(void *);
+	/*VALGRIND_MALLOCLIKE_BLOCK(stack, SIZEOF_THREAD_INFO, 0, 0);
+ 	* .thread_info is already valid
+ 	*/
+	VALGRIND_STACK_REGISTER(SIZEOF_THREAD_INFO + stack,
+		UM_THREAD_SIZE + stack - sizeof(void *));
+	if ((4*4096)==UM_THREAD_SIZE)
+		mprotect(stack+4096, 2*4096, PROT_NONE);
 }
 
 #define INIT_JMP_NEW_THREAD 0
@@ -523,6 +583,7 @@
 		    SA_ONSTACK | SA_RESTART, SIGUSR1, SIGIO, SIGALRM,
 		    SIGVTALRM, -1);
 
+	printf("start_idle_thread  stack=0x%lx\n", stack);
 	/*
 	 * Can't use UML_SETJMP or UML_LONGJMP here because they save
 	 * and restore signals, with the possible side-effect of
@@ -537,6 +598,8 @@
 		(*switch_buf)[0].JB_IP = (unsigned long) new_thread_handler;
 		(*switch_buf)[0].JB_SP = (unsigned long) stack +
 			UM_THREAD_SIZE - sizeof(void *);
+		if ((4*4096)==UM_THREAD_SIZE)
+			mprotect(stack+4096, 2*4096, PROT_NONE);
 		break;
 	case INIT_JMP_CALLBACK:
 		(*cb_proc)(cb_arg);
diff -ur linux-2.6.22.5-old/arch/um/os-Linux/start_up.c linux-2.6.22.5/arch/um/os-Linux/start_up.c
--- linux-2.6.22.5-old/arch/um/os-Linux/start_up.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/um/os-Linux/start_up.c	2007-12-12 13:26:52.000000000 -0800
@@ -43,6 +43,34 @@
 #include "registers.h"
 #endif
 
+static void fatal_perror(char *str)
+{
+	perror(str);
+	exit(1);
+}
+
+static void fatal(char *fmt, ...)
+{
+	va_list list;
+
+	va_start(list, fmt);
+	vprintf(fmt, list);
+	va_end(list);
+	fflush(stdout);
+
+	exit(1);
+}
+
+static void non_fatal(char *fmt, ...)
+{
+	va_list list;
+
+	va_start(list, fmt);
+	vprintf(fmt, list);
+	va_end(list);
+	fflush(stdout);
+}
+
 static int ptrace_child(void *arg)
 {
 	int ret;
@@ -73,34 +101,6 @@
 	_exit(ret);
 }
 
-static void fatal_perror(char *str)
-{
-	perror(str);
-	exit(1);
-}
-
-static void fatal(char *fmt, ...)
-{
-	va_list list;
-
-	va_start(list, fmt);
-	vprintf(fmt, list);
-	va_end(list);
-	fflush(stdout);
-
-	exit(1);
-}
-
-static void non_fatal(char *fmt, ...)
-{
-	va_list list;
-
-	va_start(list, fmt);
-	vprintf(fmt, list);
-	va_end(list);
-	fflush(stdout);
-}
-
 static int start_ptraced_child(void **stack_out)
 {
 	void *stack;
@@ -113,7 +113,7 @@
 	if(stack == MAP_FAILED)
 		fatal_perror("check_ptrace : mmap failed");
 	sp = (unsigned long) stack + UM_KERN_PAGE_SIZE - sizeof(void *);
-	pid = clone(ptrace_child, (void *) sp, SIGCHLD, NULL);
+	pid = clone(ptrace_child, (void *) sp, SIGCHLD, NULL, 0,0,0);
 	if(pid < 0)
 		fatal_perror("start_ptraced_child : clone failed");
 	CATCH_EINTR(n = waitpid(pid, &status, WUNTRACED));
@@ -149,6 +149,7 @@
 		non_fatal("check_ptrace : child exited with exitcode %d, while "
 			  "expecting %d; status 0x%x\n", exit_with,
 			  exitcode, status);
+		ptrace_dump_regs(pid);
 		if (mustexit)
 			exit(1);
 		ret = -1;
diff -ur linux-2.6.22.5-old/arch/um/os-Linux/util.c linux-2.6.22.5/arch/um/os-Linux/util.c
--- linux-2.6.22.5-old/arch/um/os-Linux/util.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/um/os-Linux/util.c	2007-12-12 11:30:48.000000000 -0800
@@ -31,11 +31,19 @@
 #include "longjmp.h"
 #include "kern_constants.h"
 
+#include "valgrind.h"
+#define SIZEOF_THREAD_INFO (8*sizeof(void *))
+
 void stack_protections(unsigned long address)
 {
-	if(mprotect((void *) address, UM_THREAD_SIZE,
+	if(mprotect((void *) (address), UM_THREAD_SIZE,
 		    PROT_READ | PROT_WRITE | PROT_EXEC) < 0)
 		panic("protecting stack failed, errno = %d", errno);
+	if ((4*4096)==UM_THREAD_SIZE)
+		mprotect((void *)address+4096, 2*4096, PROT_NONE);
+
+	VALGRIND_STACK_REGISTER(SIZEOF_THREAD_INFO + address,
+		UM_THREAD_SIZE + (char *)address - sizeof(void *));
 }
 
 int raw(int fd)
diff -ur linux-2.6.22.5-old/arch/um/sys-i386/Makefile linux-2.6.22.5/arch/um/sys-i386/Makefile
--- linux-2.6.22.5-old/arch/um/sys-i386/Makefile	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/um/sys-i386/Makefile	2007-12-10 09:40:16.000000000 -0800
@@ -1,6 +1,7 @@
 obj-y = bug.o bugs.o checksum.o delay.o fault.o ksyms.o ldt.o ptrace.o \
 	ptrace_user.o setjmp.o signal.o sigcontext.o syscalls.o sysrq.o \
-	sys_call_table.o tls.o
+	sys_call_table.o tls.o \
+	clone-uml.o
 
 obj-$(CONFIG_MODE_SKAS) += stub.o stub_segv.o
 
diff -ur linux-2.6.22.5-old/arch/um/sys-i386/setjmp.S linux-2.6.22.5/arch/um/sys-i386/setjmp.S
--- linux-2.6.22.5-old/arch/um/sys-i386/setjmp.S	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/um/sys-i386/setjmp.S	2007-11-06 19:30:35.000000000 -0800
@@ -41,18 +41,43 @@
 	.align 4
 	.globl longjmp
 	.type longjmp, @function
+/* longjmp(&jmpbuf, retval) hints stack switch to valgrind on i386.
+ * Copyright 2007 BitWagon Software LLC.  All rights reserved.
+ * Licensed under GNU General Public License, version 2.
+ * 2007-11-06  John Reiser
+ */
+
+VG_USERREQ__STACK_SWITCH = 0x1504  # valgrind/valgrind.h
+
+	.globl longjmp
 longjmp:
+	movl %esp,%ecx
 #ifdef _REGPARM
 	xchgl %eax,%edx
 #else
-	movl 4(%esp),%edx		# jmp_ptr address
-	movl 8(%esp),%eax		# Return value
+	movl 1*4(%ecx),%edx  # jmpbuf
+	movl 2*4(%ecx),%eax  # retval
 #endif
-	movl (%edx),%ebx
-	movl 4(%edx),%esp
-	movl 8(%edx),%ebp
-	movl 12(%edx),%esi
-	movl 16(%edx),%edi
-	jmp *20(%edx)
+	movl    (%edx),%ebx
+	movl 1*4(%edx),%esp  # change stack now
+	movl 2*4(%edx),%ebp
+	movl 3*4(%edx),%esi
+	movl 4*4(%edx),%edi
+
+	movl 5*4(%edx),%edx; push %edx  # destination
+	push %eax  # retval
+
+	lea 2*4(%esp),%edx; push %edx  # new_sp
+	push %ecx  # old_sp
+	push $VG_USERREQ__STACK_SWITCH  # request
+	movl %esp,%eax  # &vector
+
+	roll $3,  %edi ; roll $13, %edi  # signature for VEX translator
+	roll $29, %edi ; roll $19, %edi
+	xchgl %ebx,%ebx
+
+	addl $3*4,%esp  # remove vector
+	pop %eax  # retval
+	ret  # goto destination
 
 	.size longjmp,.-longjmp
diff -ur linux-2.6.22.5-old/arch/um/sys-i386/stub_segv.c linux-2.6.22.5/arch/um/sys-i386/stub_segv.c
--- linux-2.6.22.5-old/arch/um/sys-i386/stub_segv.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/arch/um/sys-i386/stub_segv.c	2007-12-05 13:21:53.000000000 -0800
@@ -16,7 +16,6 @@
 {
 	struct sigcontext *sc = (struct sigcontext *) (&sig + 1);
 	int pid;
-
 	GET_FAULTINFO_FROM_SC(*((struct faultinfo *) UML_CONFIG_STUB_DATA),
 			      sc);
 
diff -ur linux-2.6.22.5-old/block/cfq-iosched.c linux-2.6.22.5/block/cfq-iosched.c
--- linux-2.6.22.5-old/block/cfq-iosched.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/block/cfq-iosched.c	2007-12-16 14:16:36.000000000 -0800
@@ -1251,7 +1251,7 @@
 {
 	struct cfq_io_context *cic;
 
-	cic = kmem_cache_alloc_node(cfq_ioc_pool, gfp_mask, cfqd->queue->node);
+	cic = kmem_cache_alloc_node(cfq_ioc_pool, gfp_mask, cfqd->queue->node, sizeof(*cic));
 	if (cic) {
 		memset(cic, 0, sizeof(*cic));
 		cic->last_end_request = jiffies;
@@ -1376,11 +1376,13 @@
 			 * free memory.
 			 */
 			spin_unlock_irq(cfqd->queue->queue_lock);
-			new_cfqq = kmem_cache_alloc_node(cfq_pool, gfp_mask|__GFP_NOFAIL, cfqd->queue->node);
+			new_cfqq = kmem_cache_alloc_node(cfq_pool, gfp_mask|__GFP_NOFAIL,
+				cfqd->queue->node, sizeof(*new_cfqq));
 			spin_lock_irq(cfqd->queue->queue_lock);
 			goto retry;
 		} else {
-			cfqq = kmem_cache_alloc_node(cfq_pool, gfp_mask, cfqd->queue->node);
+			cfqq = kmem_cache_alloc_node(cfq_pool, gfp_mask, cfqd->queue->node,
+				sizeof(*cfqq));
 			if (!cfqq)
 				goto out;
 		}
diff -ur linux-2.6.22.5-old/block/ll_rw_blk.c linux-2.6.22.5/block/ll_rw_blk.c
--- linux-2.6.22.5-old/block/ll_rw_blk.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/block/ll_rw_blk.c	2007-12-16 14:15:48.000000000 -0800
@@ -1837,7 +1837,7 @@
 {
 	request_queue_t *q;
 
-	q = kmem_cache_alloc_node(requestq_cachep, gfp_mask, node_id);
+	q = kmem_cache_alloc_node(requestq_cachep, gfp_mask, node_id, sizeof(*q));
 	if (!q)
 		return NULL;
 
@@ -3794,7 +3794,7 @@
 	if (likely(ret))
 		return ret;
 
-	ret = kmem_cache_alloc_node(iocontext_cachep, gfp_flags, node);
+	ret = kmem_cache_alloc_node(iocontext_cachep, gfp_flags, node, sizeof(*ret));
 	if (ret) {
 		atomic_set(&ret->refcount, 1);
 		ret->task = current;
diff -ur linux-2.6.22.5-old/drivers/char/random.c linux-2.6.22.5/drivers/char/random.c
--- linux-2.6.22.5-old/drivers/char/random.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/drivers/char/random.c	2007-12-19 13:35:12.000000000 -0800
@@ -708,6 +708,8 @@
 
 		bytes=extract_entropy(r->pull, tmp, bytes,
 				      random_read_wakeup_thresh / 8, rsvd);
+		/* clear uninitialized bytes at the end to make valgrind happy */
+		memset((char *)tmp + bytes, 0, -bytes & 3);
 		add_entropy_words(r, tmp, (bytes + 3) / 4);
 		credit_entropy_store(r, bytes*8);
 	}
diff -ur linux-2.6.22.5-old/drivers/ieee1394/eth1394.c linux-2.6.22.5/drivers/ieee1394/eth1394.c
--- linux-2.6.22.5-old/drivers/ieee1394/eth1394.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/drivers/ieee1394/eth1394.c	2007-12-16 13:24:56.000000000 -0800
@@ -1579,7 +1579,7 @@
 	struct eth1394_node_ref *node;
 	struct eth1394_node_info *node_info = NULL;
 
-	ptask = kmem_cache_alloc(packet_task_cache, GFP_ATOMIC);
+	ptask = kmem_cache_alloc(packet_task_cache, GFP_ATOMIC, sizeof(*ptask));
 	if (ptask == NULL)
 		goto fail;
 
diff -ur linux-2.6.22.5-old/drivers/infiniband/core/mad.c linux-2.6.22.5/drivers/infiniband/core/mad.c
--- linux-2.6.22.5-old/drivers/infiniband/core/mad.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/drivers/infiniband/core/mad.c	2007-12-16 13:24:55.000000000 -0800
@@ -706,7 +706,7 @@
 	}
 	local->mad_priv = NULL;
 	local->recv_mad_agent = NULL;
-	mad_priv = kmem_cache_alloc(ib_mad_cache, GFP_ATOMIC);
+	mad_priv = kmem_cache_alloc(ib_mad_cache, GFP_ATOMIC, sizeof(*mad_priv));
 	if (!mad_priv) {
 		ret = -ENOMEM;
 		printk(KERN_ERR PFX "No memory for local response MAD\n");
@@ -1840,7 +1840,7 @@
 	struct ib_mad_list_head *mad_list;
 	struct ib_mad_agent_private *mad_agent;
 
-	response = kmem_cache_alloc(ib_mad_cache, GFP_KERNEL);
+	response = kmem_cache_alloc(ib_mad_cache, GFP_KERNEL, sizeof(*response));
 	if (!response)
 		printk(KERN_ERR PFX "ib_mad_recv_done_handler no memory "
 		       "for response buffer\n");
@@ -2528,7 +2528,7 @@
 			mad_priv = mad;
 			mad = NULL;
 		} else {
-			mad_priv = kmem_cache_alloc(ib_mad_cache, GFP_KERNEL);
+			mad_priv = kmem_cache_alloc(ib_mad_cache, GFP_KERNEL, sizeof(*mad_priv));
 			if (!mad_priv) {
 				printk(KERN_ERR PFX "No memory for receive buffer\n");
 				ret = -ENOMEM;
diff -ur linux-2.6.22.5-old/drivers/infiniband/hw/ehca/ehca_av.c linux-2.6.22.5/drivers/infiniband/hw/ehca/ehca_av.c
--- linux-2.6.22.5-old/drivers/infiniband/hw/ehca/ehca_av.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/drivers/infiniband/hw/ehca/ehca_av.c	2007-12-16 13:24:55.000000000 -0800
@@ -57,7 +57,7 @@
 	struct ehca_shca *shca = container_of(pd->device, struct ehca_shca,
 					      ib_device);
 
-	av = kmem_cache_alloc(av_cache, GFP_KERNEL);
+	av = kmem_cache_alloc(av_cache, GFP_KERNEL, sizeof(*av));
 	if (!av) {
 		ehca_err(pd->device, "Out of memory pd=%p ah_attr=%p",
 			 pd, ah_attr);
diff -ur linux-2.6.22.5-old/drivers/infiniband/ulp/iser/iser_initiator.c linux-2.6.22.5/drivers/infiniband/ulp/iser/iser_initiator.c
--- linux-2.6.22.5-old/drivers/infiniband/ulp/iser/iser_initiator.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/drivers/infiniband/ulp/iser/iser_initiator.c	2007-12-16 13:24:54.000000000 -0800
@@ -189,7 +189,7 @@
 	struct iser_device  *device = iser_conn->ib_conn->device;
 	int rx_data_size, err = 0;
 
-	rx_desc = kmem_cache_alloc(ig.desc_cache, GFP_NOIO);
+	rx_desc = kmem_cache_alloc(ig.desc_cache, GFP_NOIO, sizeof(*rx_desc));
 	if (rx_desc == NULL) {
 		iser_err("Failed to alloc desc for post recv\n");
 		return -ENOMEM;
@@ -431,7 +431,7 @@
 	iser_dbg("%s itt %d dseg_len %d offset %d\n",
 		 __func__,(int)itt,(int)data_seg_len,(int)buf_offset);
 
-	tx_desc = kmem_cache_alloc(ig.desc_cache, GFP_NOIO);
+	tx_desc = kmem_cache_alloc(ig.desc_cache, GFP_NOIO, sizeof(*tx_desc));
 	if (tx_desc == NULL) {
 		iser_err("Failed to alloc desc for post dataout\n");
 		return -ENOMEM;
diff -ur linux-2.6.22.5-old/drivers/md/dm-snap.c linux-2.6.22.5/drivers/md/dm-snap.c
--- linux-2.6.22.5-old/drivers/md/dm-snap.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/drivers/md/dm-snap.c	2007-12-16 13:24:55.000000000 -0800
@@ -283,9 +283,9 @@
 {
 	struct exception *e;
 
-	e = kmem_cache_alloc(exception_cache, GFP_NOIO);
+	e = kmem_cache_alloc(exception_cache, GFP_NOIO, sizeof(*e));
 	if (!e)
-		e = kmem_cache_alloc(exception_cache, GFP_ATOMIC);
+		e = kmem_cache_alloc(exception_cache, GFP_ATOMIC, sizeof(*e));
 
 	return e;
 }
diff -ur linux-2.6.22.5-old/drivers/md/raid5.c linux-2.6.22.5/drivers/md/raid5.c
--- linux-2.6.22.5-old/drivers/md/raid5.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/drivers/md/raid5.c	2007-12-16 13:24:55.000000000 -0800
@@ -327,7 +327,7 @@
 static int grow_one_stripe(raid5_conf_t *conf)
 {
 	struct stripe_head *sh;
-	sh = kmem_cache_alloc(conf->slab_cache, GFP_KERNEL);
+	sh = kmem_cache_alloc(conf->slab_cache, GFP_KERNEL, sizeof(*sh));
 	if (!sh)
 		return 0;
 	memset(sh, 0, sizeof(*sh) + (conf->raid_disks-1)*sizeof(struct r5dev));
@@ -415,7 +415,7 @@
 		return -ENOMEM;
 
 	for (i = conf->max_nr_stripes; i; i--) {
-		nsh = kmem_cache_alloc(sc, GFP_KERNEL);
+		nsh = kmem_cache_alloc(sc, GFP_KERNEL, sizeof(*nsh));
 		if (!nsh)
 			break;
 
diff -ur linux-2.6.22.5-old/drivers/mtd/ubi/eba.c linux-2.6.22.5/drivers/mtd/ubi/eba.c
--- linux-2.6.22.5-old/drivers/mtd/ubi/eba.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/drivers/mtd/ubi/eba.c	2007-12-16 13:24:56.000000000 -0800
@@ -157,7 +157,7 @@
 {
 	struct ltree_entry *le, *le1, *le_free;
 
-	le = kmem_cache_alloc(ltree_slab, GFP_KERNEL);
+	le = kmem_cache_alloc(ltree_slab, GFP_KERNEL, sizeof(*le));
 	if (!le)
 		return ERR_PTR(-ENOMEM);
 
diff -ur linux-2.6.22.5-old/drivers/mtd/ubi/wl.c linux-2.6.22.5/drivers/mtd/ubi/wl.c
--- linux-2.6.22.5-old/drivers/mtd/ubi/wl.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/drivers/mtd/ubi/wl.c	2007-12-16 13:24:56.000000000 -0800
@@ -1457,7 +1457,7 @@
 	list_for_each_entry_safe(seb, tmp, &si->erase, u.list) {
 		cond_resched();
 
-		e = kmem_cache_alloc(wl_entries_slab, GFP_KERNEL);
+		e = kmem_cache_alloc(wl_entries_slab, GFP_KERNEL, sizeof(*e));
 		if (!e)
 			goto out_free;
 
@@ -1473,7 +1473,7 @@
 	list_for_each_entry(seb, &si->free, u.list) {
 		cond_resched();
 
-		e = kmem_cache_alloc(wl_entries_slab, GFP_KERNEL);
+		e = kmem_cache_alloc(wl_entries_slab, GFP_KERNEL, sizeof(*e));
 		if (!e)
 			goto out_free;
 
@@ -1487,7 +1487,7 @@
 	list_for_each_entry(seb, &si->corr, u.list) {
 		cond_resched();
 
-		e = kmem_cache_alloc(wl_entries_slab, GFP_KERNEL);
+		e = kmem_cache_alloc(wl_entries_slab, GFP_KERNEL, sizeof(*e));
 		if (!e)
 			goto out_free;
 
@@ -1504,7 +1504,7 @@
 		ubi_rb_for_each_entry(rb2, seb, &sv->root, u.rb) {
 			cond_resched();
 
-			e = kmem_cache_alloc(wl_entries_slab, GFP_KERNEL);
+			e = kmem_cache_alloc(wl_entries_slab, GFP_KERNEL, sizeof(*e));
 			if (!e)
 				goto out_free;
 
diff -ur linux-2.6.22.5-old/drivers/scsi/scsi_tgt_lib.c linux-2.6.22.5/drivers/scsi/scsi_tgt_lib.c
--- linux-2.6.22.5-old/drivers/scsi/scsi_tgt_lib.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/drivers/scsi/scsi_tgt_lib.c	2007-12-16 13:24:55.000000000 -0800
@@ -84,7 +84,7 @@
 	if (!get_device(&shost->shost_gendev))
 		return NULL;
 
-	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC);
+	tcmd = kmem_cache_alloc(scsi_tgt_cmd_cache, GFP_ATOMIC, sizeof(*tcmd));
 	if (!tcmd)
 		goto put_dev;
 
diff -ur linux-2.6.22.5-old/fs/adfs/super.c linux-2.6.22.5/fs/adfs/super.c
--- linux-2.6.22.5-old/fs/adfs/super.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/adfs/super.c	2007-12-16 13:24:58.000000000 -0800
@@ -217,7 +217,7 @@
 static struct inode *adfs_alloc_inode(struct super_block *sb)
 {
 	struct adfs_inode_info *ei;
-	ei = (struct adfs_inode_info *)kmem_cache_alloc(adfs_inode_cachep, GFP_KERNEL);
+	ei = (struct adfs_inode_info *)kmem_cache_alloc(adfs_inode_cachep, GFP_KERNEL, sizeof(*ei));
 	if (!ei)
 		return NULL;
 	return &ei->vfs_inode;
diff -ur linux-2.6.22.5-old/fs/affs/super.c linux-2.6.22.5/fs/affs/super.c
--- linux-2.6.22.5-old/fs/affs/super.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/affs/super.c	2007-12-16 13:24:59.000000000 -0800
@@ -72,7 +72,7 @@
 static struct inode *affs_alloc_inode(struct super_block *sb)
 {
 	struct affs_inode_info *ei;
-	ei = (struct affs_inode_info *)kmem_cache_alloc(affs_inode_cachep, GFP_KERNEL);
+	ei = (struct affs_inode_info *)kmem_cache_alloc(affs_inode_cachep, GFP_KERNEL, sizeof(*ei));
 	if (!ei)
 		return NULL;
 	ei->vfs_inode.i_version = 1;
diff -ur linux-2.6.22.5-old/fs/afs/super.c linux-2.6.22.5/fs/afs/super.c
--- linux-2.6.22.5-old/fs/afs/super.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/afs/super.c	2007-12-16 13:24:57.000000000 -0800
@@ -470,7 +470,7 @@
 {
 	struct afs_vnode *vnode;
 
-	vnode = kmem_cache_alloc(afs_inode_cachep, GFP_KERNEL);
+	vnode = kmem_cache_alloc(afs_inode_cachep, GFP_KERNEL, sizeof(*vnode));
 	if (!vnode)
 		return NULL;
 
diff -ur linux-2.6.22.5-old/fs/aio.c linux-2.6.22.5/fs/aio.c
--- linux-2.6.22.5-old/fs/aio.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/aio.c	2007-12-16 14:10:17.000000000 -0800
@@ -209,7 +209,7 @@
 	if ((unsigned long)nr_events > aio_max_nr)
 		return ERR_PTR(-EAGAIN);
 
-	ctx = kmem_cache_zalloc(kioctx_cachep, GFP_KERNEL);
+	ctx = kmem_cache_zalloc(kioctx_cachep, GFP_KERNEL, sizeof(*ctx));
 	if (!ctx)
 		return ERR_PTR(-ENOMEM);
 
@@ -404,7 +404,7 @@
 	struct aio_ring *ring;
 	int okay = 0;
 
-	req = kmem_cache_alloc(kiocb_cachep, GFP_KERNEL);
+	req = kmem_cache_alloc(kiocb_cachep, GFP_KERNEL, sizeof(*req));
 	if (unlikely(!req))
 		return NULL;
 
diff -ur linux-2.6.22.5-old/fs/bfs/inode.c linux-2.6.22.5/fs/bfs/inode.c
--- linux-2.6.22.5-old/fs/bfs/inode.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/bfs/inode.c	2007-12-16 13:24:57.000000000 -0800
@@ -233,7 +233,7 @@
 static struct inode *bfs_alloc_inode(struct super_block *sb)
 {
 	struct bfs_inode_info *bi;
-	bi = kmem_cache_alloc(bfs_inode_cachep, GFP_KERNEL);
+	bi = kmem_cache_alloc(bfs_inode_cachep, GFP_KERNEL, sizeof(*bi));
 	if (!bi)
 		return NULL;
 	return &bi->vfs_inode;
diff -ur linux-2.6.22.5-old/fs/block_dev.c linux-2.6.22.5/fs/block_dev.c
--- linux-2.6.22.5-old/fs/block_dev.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/block_dev.c	2007-12-16 14:10:55.000000000 -0800
@@ -439,7 +439,7 @@
 
 static struct inode *bdev_alloc_inode(struct super_block *sb)
 {
-	struct bdev_inode *ei = kmem_cache_alloc(bdev_cachep, GFP_KERNEL);
+	struct bdev_inode *ei = kmem_cache_alloc(bdev_cachep, GFP_KERNEL, sizeof(*ei));
 	if (!ei)
 		return NULL;
 	return &ei->vfs_inode;
diff -ur linux-2.6.22.5-old/fs/buffer.c linux-2.6.22.5/fs/buffer.c
--- linux-2.6.22.5-old/fs/buffer.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/buffer.c	2007-12-16 14:10:40.000000000 -0800
@@ -2899,7 +2899,7 @@
 	
 struct buffer_head *alloc_buffer_head(gfp_t gfp_flags)
 {
-	struct buffer_head *ret = kmem_cache_zalloc(bh_cachep, gfp_flags);
+	struct buffer_head *ret = kmem_cache_zalloc(bh_cachep, gfp_flags, sizeof(*ret));
 	if (ret) {
 		INIT_LIST_HEAD(&ret->b_assoc_buffers);
 		get_cpu_var(bh_accounting).nr++;
diff -ur linux-2.6.22.5-old/fs/cifs/cifsfs.c linux-2.6.22.5/fs/cifs/cifsfs.c
--- linux-2.6.22.5-old/fs/cifs/cifsfs.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/cifs/cifsfs.c	2007-12-16 13:24:58.000000000 -0800
@@ -255,7 +255,7 @@
 cifs_alloc_inode(struct super_block *sb)
 {
 	struct cifsInodeInfo *cifs_inode;
-	cifs_inode = kmem_cache_alloc(cifs_inode_cachep, GFP_KERNEL);
+	cifs_inode = kmem_cache_alloc(cifs_inode_cachep, GFP_KERNEL, sizeof(*cifs_inode));
 	if (!cifs_inode)
 		return NULL;
 	cifs_inode->cifsAttrs = 0x20;	/* default */
diff -ur linux-2.6.22.5-old/fs/coda/inode.c linux-2.6.22.5/fs/coda/inode.c
--- linux-2.6.22.5-old/fs/coda/inode.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/coda/inode.c	2007-12-16 13:24:58.000000000 -0800
@@ -43,7 +43,7 @@
 static struct inode *coda_alloc_inode(struct super_block *sb)
 {
 	struct coda_inode_info *ei;
-	ei = (struct coda_inode_info *)kmem_cache_alloc(coda_inode_cachep, GFP_KERNEL);
+	ei = (struct coda_inode_info *)kmem_cache_alloc(coda_inode_cachep, GFP_KERNEL, sizeof(*ei));
 	if (!ei)
 		return NULL;
 	memset(&ei->c_fid, 0, sizeof(struct CodaFid));
diff -ur linux-2.6.22.5-old/fs/dcache.c linux-2.6.22.5/fs/dcache.c
--- linux-2.6.22.5-old/fs/dcache.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/dcache.c	2007-12-16 13:25:04.000000000 -0800
@@ -898,7 +898,7 @@
 	struct dentry *dentry;
 	char *dname;
 
-	dentry = kmem_cache_alloc(dentry_cache, GFP_KERNEL); 
+	dentry = kmem_cache_alloc(dentry_cache, GFP_KERNEL, sizeof(*dentry)); 
 	if (!dentry)
 		return NULL;
 
diff -ur linux-2.6.22.5-old/fs/dcookies.c linux-2.6.22.5/fs/dcookies.c
--- linux-2.6.22.5-old/fs/dcookies.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/dcookies.c	2007-12-16 13:24:59.000000000 -0800
@@ -91,7 +91,7 @@
 static struct dcookie_struct * alloc_dcookie(struct dentry * dentry,
 	struct vfsmount * vfsmnt)
 {
-	struct dcookie_struct * dcs = kmem_cache_alloc(dcookie_cache, GFP_KERNEL);
+	struct dcookie_struct * dcs = kmem_cache_alloc(dcookie_cache, GFP_KERNEL, sizeof(*dcs));
 	if (!dcs)
 		return NULL;
 
diff -ur linux-2.6.22.5-old/fs/dnotify.c linux-2.6.22.5/fs/dnotify.c
--- linux-2.6.22.5-old/fs/dnotify.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/dnotify.c	2007-12-16 13:24:58.000000000 -0800
@@ -77,7 +77,7 @@
 	inode = filp->f_path.dentry->d_inode;
 	if (!S_ISDIR(inode->i_mode))
 		return -ENOTDIR;
-	dn = kmem_cache_alloc(dn_cache, GFP_KERNEL);
+	dn = kmem_cache_alloc(dn_cache, GFP_KERNEL, sizeof(*dn));
 	if (dn == NULL)
 		return -ENOMEM;
 	spin_lock(&inode->i_lock);
diff -ur linux-2.6.22.5-old/fs/dquot.c linux-2.6.22.5/fs/dquot.c
--- linux-2.6.22.5-old/fs/dquot.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/dquot.c	2007-12-16 14:12:34.000000000 -0800
@@ -600,7 +600,7 @@
 {
 	struct dquot *dquot;
 
-	dquot = kmem_cache_zalloc(dquot_cachep, GFP_NOFS);
+	dquot = kmem_cache_zalloc(dquot_cachep, GFP_NOFS, sizeof(*dquot));
 	if(!dquot)
 		return NODQUOT;
 
diff -ur linux-2.6.22.5-old/fs/ecryptfs/crypto.c linux-2.6.22.5/fs/ecryptfs/crypto.c
--- linux-2.6.22.5-old/fs/ecryptfs/crypto.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/ecryptfs/crypto.c	2007-12-16 13:25:01.000000000 -0800
@@ -1625,7 +1625,7 @@
 	ecryptfs_copy_mount_wide_flags_to_inode_flags(crypt_stat,
 						      mount_crypt_stat);
 	/* Read the first page from the underlying file */
-	page_virt = kmem_cache_alloc(ecryptfs_header_cache_1, GFP_USER);
+	page_virt = kmem_cache_alloc(ecryptfs_header_cache_1, GFP_USER, sizeof(*page_virt));
 	if (!page_virt) {
 		rc = -ENOMEM;
 		ecryptfs_printk(KERN_ERR, "Unable to allocate page_virt\n");
diff -ur linux-2.6.22.5-old/fs/ecryptfs/keystore.c linux-2.6.22.5/fs/ecryptfs/keystore.c
--- linux-2.6.22.5-old/fs/ecryptfs/keystore.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/ecryptfs/keystore.c	2007-12-16 13:25:02.000000000 -0800
@@ -1670,7 +1670,7 @@
 	int rc = 0;
 
 	(*len) = 0;
-	key_rec = kmem_cache_alloc(ecryptfs_key_record_cache, GFP_KERNEL);
+	key_rec = kmem_cache_alloc(ecryptfs_key_record_cache, GFP_KERNEL, sizeof(*key_rec));
 	if (!key_rec) {
 		rc = -ENOMEM;
 		goto out;
diff -ur linux-2.6.22.5-old/fs/ecryptfs/mmap.c linux-2.6.22.5/fs/ecryptfs/mmap.c
--- linux-2.6.22.5-old/fs/ecryptfs/mmap.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/ecryptfs/mmap.c	2007-12-16 13:25:03.000000000 -0800
@@ -523,7 +523,7 @@
 	u64 file_size;
 	int rc;
 
-	xattr_virt = kmem_cache_alloc(ecryptfs_xattr_cache, GFP_KERNEL);
+	xattr_virt = kmem_cache_alloc(ecryptfs_xattr_cache, GFP_KERNEL, sizeof(*xattr_virt));
 	if (!xattr_virt) {
 		printk(KERN_ERR "Out of memory whilst attempting to write "
 		       "inode size to xattr\n");
diff -ur linux-2.6.22.5-old/fs/efs/super.c linux-2.6.22.5/fs/efs/super.c
--- linux-2.6.22.5-old/fs/efs/super.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/efs/super.c	2007-12-16 13:25:01.000000000 -0800
@@ -57,7 +57,7 @@
 static struct inode *efs_alloc_inode(struct super_block *sb)
 {
 	struct efs_inode_info *ei;
-	ei = (struct efs_inode_info *)kmem_cache_alloc(efs_inode_cachep, GFP_KERNEL);
+	ei = (struct efs_inode_info *)kmem_cache_alloc(efs_inode_cachep, GFP_KERNEL, sizeof(*ei));
 	if (!ei)
 		return NULL;
 	return &ei->vfs_inode;
diff -ur linux-2.6.22.5-old/fs/eventpoll.c linux-2.6.22.5/fs/eventpoll.c
--- linux-2.6.22.5-old/fs/eventpoll.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/eventpoll.c	2007-12-16 14:11:51.000000000 -0800
@@ -682,7 +682,8 @@
 	struct epitem *epi = ep_item_from_epqueue(pt);
 	struct eppoll_entry *pwq;
 
-	if (epi->nwait >= 0 && (pwq = kmem_cache_alloc(pwq_cache, GFP_KERNEL))) {
+	if (epi->nwait >= 0 && (pwq = kmem_cache_alloc(pwq_cache, GFP_KERNEL,
+		sizeof(*pwq)))) {
 		init_waitqueue_func_entry(&pwq->wait, ep_poll_callback);
 		pwq->whead = whead;
 		pwq->base = epi;
@@ -726,7 +727,7 @@
 	struct ep_pqueue epq;
 
 	error = -ENOMEM;
-	if (!(epi = kmem_cache_alloc(epi_cache, GFP_KERNEL)))
+	if (!(epi = kmem_cache_alloc(epi_cache, GFP_KERNEL, sizeof(*epi))))
 		goto error_return;
 
 	/* Item initialization follow here ... */
diff -ur linux-2.6.22.5-old/fs/exec.c linux-2.6.22.5/fs/exec.c
--- linux-2.6.22.5-old/fs/exec.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/exec.c	2007-12-16 14:09:01.000000000 -0800
@@ -410,7 +410,7 @@
 		bprm->loader += stack_base;
 	bprm->exec += stack_base;
 
-	mpnt = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
+	mpnt = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL, sizeof(*mpnt));
 	if (!mpnt)
 		return -ENOMEM;
 
@@ -602,7 +602,7 @@
 		return 0;
 	}
 
-	newsighand = kmem_cache_alloc(sighand_cachep, GFP_KERNEL);
+	newsighand = kmem_cache_alloc(sighand_cachep, GFP_KERNEL, sizeof(*newsighand));
 	if (!newsighand)
 		return -ENOMEM;
 
@@ -1149,6 +1149,8 @@
 
 EXPORT_SYMBOL(search_binary_handler);
 
+#include "valgrind.h"
+
 /*
  * sys_execve() executes a new program.
  */
diff -ur linux-2.6.22.5-old/fs/ext2/super.c linux-2.6.22.5/fs/ext2/super.c
--- linux-2.6.22.5-old/fs/ext2/super.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/ext2/super.c	2007-12-16 13:24:58.000000000 -0800
@@ -140,7 +140,7 @@
 static struct inode *ext2_alloc_inode(struct super_block *sb)
 {
 	struct ext2_inode_info *ei;
-	ei = (struct ext2_inode_info *)kmem_cache_alloc(ext2_inode_cachep, GFP_KERNEL);
+	ei = (struct ext2_inode_info *)kmem_cache_alloc(ext2_inode_cachep, GFP_KERNEL, sizeof(*ei));
 	if (!ei)
 		return NULL;
 #ifdef CONFIG_EXT2_FS_POSIX_ACL
diff -ur linux-2.6.22.5-old/fs/ext3/super.c linux-2.6.22.5/fs/ext3/super.c
--- linux-2.6.22.5-old/fs/ext3/super.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/ext3/super.c	2007-12-16 13:24:59.000000000 -0800
@@ -445,7 +445,7 @@
 {
 	struct ext3_inode_info *ei;
 
-	ei = kmem_cache_alloc(ext3_inode_cachep, GFP_NOFS);
+	ei = kmem_cache_alloc(ext3_inode_cachep, GFP_NOFS, sizeof(*ei));
 	if (!ei)
 		return NULL;
 #ifdef CONFIG_EXT3_FS_POSIX_ACL
diff -ur linux-2.6.22.5-old/fs/ext4/super.c linux-2.6.22.5/fs/ext4/super.c
--- linux-2.6.22.5-old/fs/ext4/super.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/ext4/super.c	2007-12-16 13:24:57.000000000 -0800
@@ -495,7 +495,7 @@
 {
 	struct ext4_inode_info *ei;
 
-	ei = kmem_cache_alloc(ext4_inode_cachep, GFP_NOFS);
+	ei = kmem_cache_alloc(ext4_inode_cachep, GFP_NOFS, sizeof(*ei));
 	if (!ei)
 		return NULL;
 #ifdef CONFIG_EXT4DEV_FS_POSIX_ACL
diff -ur linux-2.6.22.5-old/fs/fat/inode.c linux-2.6.22.5/fs/fat/inode.c
--- linux-2.6.22.5-old/fs/fat/inode.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/fat/inode.c	2007-12-16 13:24:59.000000000 -0800
@@ -485,7 +485,7 @@
 static struct inode *fat_alloc_inode(struct super_block *sb)
 {
 	struct msdos_inode_info *ei;
-	ei = kmem_cache_alloc(fat_inode_cachep, GFP_KERNEL);
+	ei = kmem_cache_alloc(fat_inode_cachep, GFP_KERNEL, sizeof(*ei));
 	if (!ei)
 		return NULL;
 	return &ei->vfs_inode;
diff -ur linux-2.6.22.5-old/fs/fcntl.c linux-2.6.22.5/fs/fcntl.c
--- linux-2.6.22.5-old/fs/fcntl.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/fcntl.c	2007-12-16 13:24:57.000000000 -0800
@@ -566,7 +566,7 @@
 	int result = 0;
 
 	if (on) {
-		new = kmem_cache_alloc(fasync_cache, GFP_KERNEL);
+		new = kmem_cache_alloc(fasync_cache, GFP_KERNEL, sizeof(*new));
 		if (!new)
 			return -ENOMEM;
 	}
diff -ur linux-2.6.22.5-old/fs/file_table.c linux-2.6.22.5/fs/file_table.c
--- linux-2.6.22.5-old/fs/file_table.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/file_table.c	2007-12-16 13:24:59.000000000 -0800
@@ -102,7 +102,7 @@
 			goto over;
 	}
 
-	f = kmem_cache_alloc(filp_cachep, GFP_KERNEL);
+	f = kmem_cache_alloc(filp_cachep, GFP_KERNEL, sizeof(*f));
 	if (f == NULL)
 		goto fail;
 
diff -ur linux-2.6.22.5-old/fs/fuse/dev.c linux-2.6.22.5/fs/fuse/dev.c
--- linux-2.6.22.5-old/fs/fuse/dev.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/fuse/dev.c	2007-12-16 13:24:58.000000000 -0800
@@ -41,7 +41,7 @@
 
 struct fuse_req *fuse_request_alloc(void)
 {
-	struct fuse_req *req = kmem_cache_alloc(fuse_req_cachep, GFP_KERNEL);
+	struct fuse_req *req = kmem_cache_alloc(fuse_req_cachep, GFP_KERNEL, sizeof(**req));
 	if (req)
 		fuse_request_init(req);
 	return req;
diff -ur linux-2.6.22.5-old/fs/fuse/inode.c linux-2.6.22.5/fs/fuse/inode.c
--- linux-2.6.22.5-old/fs/fuse/inode.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/fuse/inode.c	2007-12-16 13:24:58.000000000 -0800
@@ -48,7 +48,7 @@
 	struct inode *inode;
 	struct fuse_inode *fi;
 
-	inode = kmem_cache_alloc(fuse_inode_cachep, GFP_KERNEL);
+	inode = kmem_cache_alloc(fuse_inode_cachep, GFP_KERNEL, sizeof(*inode));
 	if (!inode)
 		return NULL;
 
diff -ur linux-2.6.22.5-old/fs/gfs2/glock.c linux-2.6.22.5/fs/gfs2/glock.c
--- linux-2.6.22.5-old/fs/gfs2/glock.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/gfs2/glock.c	2007-12-16 13:25:03.000000000 -0800
@@ -307,7 +307,7 @@
 		return 0;
 	}
 
-	gl = kmem_cache_alloc(gfs2_glock_cachep, GFP_KERNEL);
+	gl = kmem_cache_alloc(gfs2_glock_cachep, GFP_KERNEL, sizeof(*gl));
 	if (!gl)
 		return -ENOMEM;
 
diff -ur linux-2.6.22.5-old/fs/gfs2/ops_super.c linux-2.6.22.5/fs/gfs2/ops_super.c
--- linux-2.6.22.5-old/fs/gfs2/ops_super.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/gfs2/ops_super.c	2007-12-16 13:25:03.000000000 -0800
@@ -479,7 +479,7 @@
 {
 	struct gfs2_inode *ip;
 
-	ip = kmem_cache_alloc(gfs2_inode_cachep, GFP_KERNEL);
+	ip = kmem_cache_alloc(gfs2_inode_cachep, GFP_KERNEL, sizeof(*ip));
 	if (ip) {
 		ip->i_flags = 0;
 		ip->i_gl = NULL;
diff -ur linux-2.6.22.5-old/fs/hfs/super.c linux-2.6.22.5/fs/hfs/super.c
--- linux-2.6.22.5-old/fs/hfs/super.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/hfs/super.c	2007-12-16 13:24:58.000000000 -0800
@@ -145,7 +145,7 @@
 {
 	struct hfs_inode_info *i;
 
-	i = kmem_cache_alloc(hfs_inode_cachep, GFP_KERNEL);
+	i = kmem_cache_alloc(hfs_inode_cachep, GFP_KERNEL, sizeof(*i));
 	return i ? &i->vfs_inode : NULL;
 }
 
diff -ur linux-2.6.22.5-old/fs/hfsplus/super.c linux-2.6.22.5/fs/hfsplus/super.c
--- linux-2.6.22.5-old/fs/hfsplus/super.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/hfsplus/super.c	2007-12-16 13:25:03.000000000 -0800
@@ -439,7 +439,7 @@
 {
 	struct hfsplus_inode_info *i;
 
-	i = kmem_cache_alloc(hfsplus_inode_cachep, GFP_KERNEL);
+	i = kmem_cache_alloc(hfsplus_inode_cachep, GFP_KERNEL, sizeof(*i));
 	return i ? &i->vfs_inode : NULL;
 }
 
diff -ur linux-2.6.22.5-old/fs/hpfs/super.c linux-2.6.22.5/fs/hpfs/super.c
--- linux-2.6.22.5-old/fs/hpfs/super.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/hpfs/super.c	2007-12-16 13:24:59.000000000 -0800
@@ -161,7 +161,7 @@
 static struct inode *hpfs_alloc_inode(struct super_block *sb)
 {
 	struct hpfs_inode_info *ei;
-	ei = (struct hpfs_inode_info *)kmem_cache_alloc(hpfs_inode_cachep, GFP_NOFS);
+	ei = (struct hpfs_inode_info *)kmem_cache_alloc(hpfs_inode_cachep, GFP_NOFS, sizeof(*ei));
 	if (!ei)
 		return NULL;
 	ei->vfs_inode.i_version = 1;
diff -ur linux-2.6.22.5-old/fs/hugetlbfs/inode.c linux-2.6.22.5/fs/hugetlbfs/inode.c
--- linux-2.6.22.5-old/fs/hugetlbfs/inode.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/hugetlbfs/inode.c	2007-12-16 13:24:58.000000000 -0800
@@ -529,7 +529,7 @@
 
 	if (unlikely(!hugetlbfs_dec_free_inodes(sbinfo)))
 		return NULL;
-	p = kmem_cache_alloc(hugetlbfs_inode_cachep, GFP_KERNEL);
+	p = kmem_cache_alloc(hugetlbfs_inode_cachep, GFP_KERNEL, sizeof(*p));
 	if (unlikely(!p)) {
 		hugetlbfs_inc_free_inodes(sbinfo);
 		return NULL;
diff -ur linux-2.6.22.5-old/fs/inode.c linux-2.6.22.5/fs/inode.c
--- linux-2.6.22.5-old/fs/inode.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/inode.c	2007-12-16 13:24:58.000000000 -0800
@@ -109,7 +109,7 @@
 	if (sb->s_op->alloc_inode)
 		inode = sb->s_op->alloc_inode(sb);
 	else
-		inode = (struct inode *) kmem_cache_alloc(inode_cachep, GFP_KERNEL);
+		inode = (struct inode *) kmem_cache_alloc(inode_cachep, GFP_KERNEL, sizeof(*inode));
 
 	if (inode) {
 		struct address_space * const mapping = &inode->i_data;
diff -ur linux-2.6.22.5-old/fs/inotify_user.c linux-2.6.22.5/fs/inotify_user.c
--- linux-2.6.22.5-old/fs/inotify_user.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/inotify_user.c	2007-12-16 13:24:58.000000000 -0800
@@ -187,7 +187,7 @@
 {
 	struct inotify_kernel_event *kevent;
 
-	kevent = kmem_cache_alloc(event_cachep, GFP_NOFS);
+	kevent = kmem_cache_alloc(event_cachep, GFP_NOFS, sizeof(*kevent));
 	if (unlikely(!kevent))
 		return NULL;
 
@@ -370,7 +370,7 @@
 			inotify_max_user_watches)
 		return -ENOSPC;
 
-	watch = kmem_cache_alloc(watch_cachep, GFP_KERNEL);
+	watch = kmem_cache_alloc(watch_cachep, GFP_KERNEL, sizeof(*watch));
 	if (unlikely(!watch))
 		return -ENOMEM;
 
diff -ur linux-2.6.22.5-old/fs/isofs/inode.c linux-2.6.22.5/fs/isofs/inode.c
--- linux-2.6.22.5-old/fs/isofs/inode.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/isofs/inode.c	2007-12-16 13:24:59.000000000 -0800
@@ -62,7 +62,7 @@
 static struct inode *isofs_alloc_inode(struct super_block *sb)
 {
 	struct iso_inode_info *ei;
-	ei = kmem_cache_alloc(isofs_inode_cachep, GFP_KERNEL);
+	ei = kmem_cache_alloc(isofs_inode_cachep, GFP_KERNEL, sizeof(*ei));
 	if (!ei)
 		return NULL;
 	return &ei->vfs_inode;
diff -ur linux-2.6.22.5-old/fs/jbd/journal.c linux-2.6.22.5/fs/jbd/journal.c
--- linux-2.6.22.5-old/fs/jbd/journal.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/jbd/journal.c	2007-12-16 14:14:04.000000000 -0800
@@ -1682,7 +1682,7 @@
 
 	idx = JBD_SLAB_INDEX(size);
 	BUG_ON(jbd_slab[idx] == NULL);
-	return kmem_cache_alloc(jbd_slab[idx], flags | __GFP_NOFAIL);
+	return kmem_cache_alloc(jbd_slab[idx], flags | __GFP_NOFAIL, size);
 }
 
 void jbd_slab_free(void *ptr,  size_t size)
@@ -1739,7 +1739,7 @@
 #ifdef CONFIG_JBD_DEBUG
 	atomic_inc(&nr_journal_heads);
 #endif
-	ret = kmem_cache_alloc(journal_head_cache, GFP_NOFS);
+	ret = kmem_cache_alloc(journal_head_cache, GFP_NOFS, sizeof(*ret));
 	if (ret == 0) {
 		jbd_debug(1, "out of memory for journal_head\n");
 		if (time_after(jiffies, last_warning + 5*HZ)) {
@@ -1749,7 +1749,7 @@
 		}
 		while (ret == 0) {
 			yield();
-			ret = kmem_cache_alloc(journal_head_cache, GFP_NOFS);
+			ret = kmem_cache_alloc(journal_head_cache, GFP_NOFS, sizeof(*ret));
 		}
 	}
 	return ret;
diff -ur linux-2.6.22.5-old/fs/jbd/revoke.c linux-2.6.22.5/fs/jbd/revoke.c
--- linux-2.6.22.5-old/fs/jbd/revoke.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/jbd/revoke.c	2007-12-16 13:24:58.000000000 -0800
@@ -122,7 +122,7 @@
 	struct jbd_revoke_record_s *record;
 
 repeat:
-	record = kmem_cache_alloc(revoke_record_cache, GFP_NOFS);
+	record = kmem_cache_alloc(revoke_record_cache, GFP_NOFS, sizeof(*record));
 	if (!record)
 		goto oom;
 
@@ -205,7 +205,7 @@
 	while((tmp >>= 1UL) != 0UL)
 		shift++;
 
-	journal->j_revoke_table[0] = kmem_cache_alloc(revoke_table_cache, GFP_KERNEL);
+	journal->j_revoke_table[0] = kmem_cache_alloc(revoke_table_cache, GFP_KERNEL, sizeof(*journal->j_revoke_table[0]));
 	if (!journal->j_revoke_table[0])
 		return -ENOMEM;
 	journal->j_revoke = journal->j_revoke_table[0];
@@ -228,7 +228,7 @@
 	for (tmp = 0; tmp < hash_size; tmp++)
 		INIT_LIST_HEAD(&journal->j_revoke->hash_table[tmp]);
 
-	journal->j_revoke_table[1] = kmem_cache_alloc(revoke_table_cache, GFP_KERNEL);
+	journal->j_revoke_table[1] = kmem_cache_alloc(revoke_table_cache, GFP_KERNEL, sizeof(*journal->j_revoke_table[1]));
 	if (!journal->j_revoke_table[1]) {
 		kfree(journal->j_revoke_table[0]->hash_table);
 		kmem_cache_free(revoke_table_cache, journal->j_revoke_table[0]);
diff -ur linux-2.6.22.5-old/fs/jbd2/journal.c linux-2.6.22.5/fs/jbd2/journal.c
--- linux-2.6.22.5-old/fs/jbd2/journal.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/jbd2/journal.c	2007-12-16 13:24:58.000000000 -0800
@@ -1750,7 +1750,7 @@
 #ifdef CONFIG_JBD_DEBUG
 	atomic_inc(&nr_journal_heads);
 #endif
-	ret = kmem_cache_alloc(jbd2_journal_head_cache, GFP_NOFS);
+	ret = kmem_cache_alloc(jbd2_journal_head_cache, GFP_NOFS, sizeof(*ret));
 	if (ret == 0) {
 		jbd_debug(1, "out of memory for journal_head\n");
 		if (time_after(jiffies, last_warning + 5*HZ)) {
@@ -1760,7 +1760,7 @@
 		}
 		while (ret == 0) {
 			yield();
-			ret = kmem_cache_alloc(jbd2_journal_head_cache, GFP_NOFS);
+			ret = kmem_cache_alloc(jbd2_journal_head_cache, GFP_NOFS, sizeof(*ret));
 		}
 	}
 	return ret;
diff -ur linux-2.6.22.5-old/fs/jbd2/revoke.c linux-2.6.22.5/fs/jbd2/revoke.c
--- linux-2.6.22.5-old/fs/jbd2/revoke.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/jbd2/revoke.c	2007-12-16 13:24:58.000000000 -0800
@@ -123,7 +123,7 @@
 	struct jbd2_revoke_record_s *record;
 
 repeat:
-	record = kmem_cache_alloc(jbd2_revoke_record_cache, GFP_NOFS);
+	record = kmem_cache_alloc(jbd2_revoke_record_cache, GFP_NOFS, sizeof(*record));
 	if (!record)
 		goto oom;
 
@@ -206,7 +206,7 @@
 	while((tmp >>= 1UL) != 0UL)
 		shift++;
 
-	journal->j_revoke_table[0] = kmem_cache_alloc(jbd2_revoke_table_cache, GFP_KERNEL);
+	journal->j_revoke_table[0] = kmem_cache_alloc(jbd2_revoke_table_cache, GFP_KERNEL, sizeof(*journal->j_revoke_table[0]));
 	if (!journal->j_revoke_table[0])
 		return -ENOMEM;
 	journal->j_revoke = journal->j_revoke_table[0];
@@ -229,7 +229,7 @@
 	for (tmp = 0; tmp < hash_size; tmp++)
 		INIT_LIST_HEAD(&journal->j_revoke->hash_table[tmp]);
 
-	journal->j_revoke_table[1] = kmem_cache_alloc(jbd2_revoke_table_cache, GFP_KERNEL);
+	journal->j_revoke_table[1] = kmem_cache_alloc(jbd2_revoke_table_cache, GFP_KERNEL, sizeof(*journal->j_revoke_table[1]));
 	if (!journal->j_revoke_table[1]) {
 		kfree(journal->j_revoke_table[0]->hash_table);
 		kmem_cache_free(jbd2_revoke_table_cache, journal->j_revoke_table[0]);
diff -ur linux-2.6.22.5-old/fs/jffs2/malloc.c linux-2.6.22.5/fs/jffs2/malloc.c
--- linux-2.6.22.5-old/fs/jffs2/malloc.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/jffs2/malloc.c	2007-12-16 13:24:58.000000000 -0800
@@ -134,7 +134,7 @@
 struct jffs2_full_dnode *jffs2_alloc_full_dnode(void)
 {
 	struct jffs2_full_dnode *ret;
-	ret = kmem_cache_alloc(full_dnode_slab, GFP_KERNEL);
+	ret = kmem_cache_alloc(full_dnode_slab, GFP_KERNEL, sizeof(*ret));
 	dbg_memalloc("%p\n", ret);
 	return ret;
 }
@@ -148,7 +148,7 @@
 struct jffs2_raw_dirent *jffs2_alloc_raw_dirent(void)
 {
 	struct jffs2_raw_dirent *ret;
-	ret = kmem_cache_alloc(raw_dirent_slab, GFP_KERNEL);
+	ret = kmem_cache_alloc(raw_dirent_slab, GFP_KERNEL, sizeof(*ret));
 	dbg_memalloc("%p\n", ret);
 	return ret;
 }
@@ -162,7 +162,7 @@
 struct jffs2_raw_inode *jffs2_alloc_raw_inode(void)
 {
 	struct jffs2_raw_inode *ret;
-	ret = kmem_cache_alloc(raw_inode_slab, GFP_KERNEL);
+	ret = kmem_cache_alloc(raw_inode_slab, GFP_KERNEL, sizeof(*ret));
 	dbg_memalloc("%p\n", ret);
 	return ret;
 }
@@ -176,7 +176,7 @@
 struct jffs2_tmp_dnode_info *jffs2_alloc_tmp_dnode_info(void)
 {
 	struct jffs2_tmp_dnode_info *ret;
-	ret = kmem_cache_alloc(tmp_dnode_info_slab, GFP_KERNEL);
+	ret = kmem_cache_alloc(tmp_dnode_info_slab, GFP_KERNEL, sizeof(*ret));
 	dbg_memalloc("%p\n",
 		ret);
 	return ret;
@@ -192,7 +192,7 @@
 {
 	struct jffs2_raw_node_ref *ret;
 
-	ret = kmem_cache_alloc(raw_node_ref_slab, GFP_KERNEL);
+	ret = kmem_cache_alloc(raw_node_ref_slab, GFP_KERNEL, sizeof(*ret));
 	if (ret) {
 		int i = 0;
 		for (i=0; i < REFS_PER_BLOCK; i++) {
@@ -255,7 +255,7 @@
 struct jffs2_node_frag *jffs2_alloc_node_frag(void)
 {
 	struct jffs2_node_frag *ret;
-	ret = kmem_cache_alloc(node_frag_slab, GFP_KERNEL);
+	ret = kmem_cache_alloc(node_frag_slab, GFP_KERNEL, sizeof(*ret));
 	dbg_memalloc("%p\n", ret);
 	return ret;
 }
@@ -269,7 +269,7 @@
 struct jffs2_inode_cache *jffs2_alloc_inode_cache(void)
 {
 	struct jffs2_inode_cache *ret;
-	ret = kmem_cache_alloc(inode_cache_slab, GFP_KERNEL);
+	ret = kmem_cache_alloc(inode_cache_slab, GFP_KERNEL, sizeof(*ret));
 	dbg_memalloc("%p\n", ret);
 	return ret;
 }
@@ -284,7 +284,7 @@
 struct jffs2_xattr_datum *jffs2_alloc_xattr_datum(void)
 {
 	struct jffs2_xattr_datum *xd;
-	xd = kmem_cache_alloc(xattr_datum_cache, GFP_KERNEL);
+	xd = kmem_cache_alloc(xattr_datum_cache, GFP_KERNEL, sizeof(*xd));
 	dbg_memalloc("%p\n", xd);
 
 	memset(xd, 0, sizeof(struct jffs2_xattr_datum));
@@ -303,7 +303,7 @@
 struct jffs2_xattr_ref *jffs2_alloc_xattr_ref(void)
 {
 	struct jffs2_xattr_ref *ref;
-	ref = kmem_cache_alloc(xattr_ref_cache, GFP_KERNEL);
+	ref = kmem_cache_alloc(xattr_ref_cache, GFP_KERNEL, sizeof(*ref));
 	dbg_memalloc("%p\n", ref);
 
 	memset(ref, 0, sizeof(struct jffs2_xattr_ref));
diff -ur linux-2.6.22.5-old/fs/jffs2/super.c linux-2.6.22.5/fs/jffs2/super.c
--- linux-2.6.22.5-old/fs/jffs2/super.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/jffs2/super.c	2007-12-16 13:24:58.000000000 -0800
@@ -32,7 +32,7 @@
 static struct inode *jffs2_alloc_inode(struct super_block *sb)
 {
 	struct jffs2_inode_info *ei;
-	ei = (struct jffs2_inode_info *)kmem_cache_alloc(jffs2_inode_cachep, GFP_KERNEL);
+	ei = (struct jffs2_inode_info *)kmem_cache_alloc(jffs2_inode_cachep, GFP_KERNEL, sizeof(*ei));
 	if (!ei)
 		return NULL;
 	return &ei->vfs_inode;
diff -ur linux-2.6.22.5-old/fs/jfs/super.c linux-2.6.22.5/fs/jfs/super.c
--- linux-2.6.22.5-old/fs/jfs/super.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/jfs/super.c	2007-12-16 13:25:01.000000000 -0800
@@ -105,7 +105,7 @@
 {
 	struct jfs_inode_info *jfs_inode;
 
-	jfs_inode = kmem_cache_alloc(jfs_inode_cachep, GFP_NOFS);
+	jfs_inode = kmem_cache_alloc(jfs_inode_cachep, GFP_NOFS, sizeof(*jfs_inode));
 	if (!jfs_inode)
 		return NULL;
 	return &jfs_inode->vfs_inode;
diff -ur linux-2.6.22.5-old/fs/locks.c linux-2.6.22.5/fs/locks.c
--- linux-2.6.22.5-old/fs/locks.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/locks.c	2007-12-16 14:09:32.000000000 -0800
@@ -147,7 +147,8 @@
 /* Allocate an empty lock structure. */
 static struct file_lock *locks_alloc_lock(void)
 {
-	return kmem_cache_alloc(filelock_cache, GFP_KERNEL);
+	return kmem_cache_alloc(filelock_cache, GFP_KERNEL,
+		sizeof(struct file_lock));
 }
 
 static void locks_release_private(struct file_lock *fl)
diff -ur linux-2.6.22.5-old/fs/minix/inode.c linux-2.6.22.5/fs/minix/inode.c
--- linux-2.6.22.5-old/fs/minix/inode.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/minix/inode.c	2007-12-16 13:25:03.000000000 -0800
@@ -58,7 +58,7 @@
 static struct inode *minix_alloc_inode(struct super_block *sb)
 {
 	struct minix_inode_info *ei;
-	ei = (struct minix_inode_info *)kmem_cache_alloc(minix_inode_cachep, GFP_KERNEL);
+	ei = (struct minix_inode_info *)kmem_cache_alloc(minix_inode_cachep, GFP_KERNEL, sizeof(*ei));
 	if (!ei)
 		return NULL;
 	return &ei->vfs_inode;
diff -ur linux-2.6.22.5-old/fs/mpage.c linux-2.6.22.5/fs/mpage.c
--- linux-2.6.22.5-old/fs/mpage.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/mpage.c	2007-12-12 09:53:36.000000000 -0800
@@ -395,6 +395,7 @@
 	pagevec_init(&lru_pvec, 0);
 	for (page_idx = 0; page_idx < nr_pages; page_idx++) {
 		struct page *page = list_entry(pages->prev, struct page, lru);
+		VALGRIND_MAKE_MEM_DEFINED(page, sizeof(*page));
 
 		prefetchw(&page->flags);
 		list_del(&page->lru);
diff -ur linux-2.6.22.5-old/fs/namespace.c linux-2.6.22.5/fs/namespace.c
--- linux-2.6.22.5-old/fs/namespace.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/namespace.c	2007-12-16 14:10:01.000000000 -0800
@@ -53,7 +53,8 @@
 
 struct vfsmount *alloc_vfsmnt(const char *name)
 {
-	struct vfsmount *mnt = kmem_cache_zalloc(mnt_cache, GFP_KERNEL);
+	struct vfsmount *mnt = kmem_cache_zalloc(mnt_cache, GFP_KERNEL,
+		sizeof(*mnt));
 	if (mnt) {
 		atomic_set(&mnt->mnt_count, 1);
 		INIT_LIST_HEAD(&mnt->mnt_hash);
diff -ur linux-2.6.22.5-old/fs/ncpfs/inode.c linux-2.6.22.5/fs/ncpfs/inode.c
--- linux-2.6.22.5-old/fs/ncpfs/inode.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/ncpfs/inode.c	2007-12-16 13:24:57.000000000 -0800
@@ -45,7 +45,7 @@
 static struct inode *ncp_alloc_inode(struct super_block *sb)
 {
 	struct ncp_inode_info *ei;
-	ei = (struct ncp_inode_info *)kmem_cache_alloc(ncp_inode_cachep, GFP_KERNEL);
+	ei = (struct ncp_inode_info *)kmem_cache_alloc(ncp_inode_cachep, GFP_KERNEL, sizeof(*ei));
 	if (!ei)
 		return NULL;
 	return &ei->vfs_inode;
diff -ur linux-2.6.22.5-old/fs/nfs/direct.c linux-2.6.22.5/fs/nfs/direct.c
--- linux-2.6.22.5-old/fs/nfs/direct.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/nfs/direct.c	2007-12-16 13:25:04.000000000 -0800
@@ -149,7 +149,7 @@
 {
 	struct nfs_direct_req *dreq;
 
-	dreq = kmem_cache_alloc(nfs_direct_cachep, GFP_KERNEL);
+	dreq = kmem_cache_alloc(nfs_direct_cachep, GFP_KERNEL, sizeof(*dreq));
 	if (!dreq)
 		return NULL;
 
diff -ur linux-2.6.22.5-old/fs/nfs/inode.c linux-2.6.22.5/fs/nfs/inode.c
--- linux-2.6.22.5-old/fs/nfs/inode.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/nfs/inode.c	2007-12-16 13:25:04.000000000 -0800
@@ -1130,7 +1130,7 @@
 struct inode *nfs_alloc_inode(struct super_block *sb)
 {
 	struct nfs_inode *nfsi;
-	nfsi = (struct nfs_inode *)kmem_cache_alloc(nfs_inode_cachep, GFP_KERNEL);
+	nfsi = (struct nfs_inode *)kmem_cache_alloc(nfs_inode_cachep, GFP_KERNEL, sizeof(*nfsi));
 	if (!nfsi)
 		return NULL;
 	nfsi->flags = 0UL;
diff -ur linux-2.6.22.5-old/fs/nfs/pagelist.c linux-2.6.22.5/fs/nfs/pagelist.c
--- linux-2.6.22.5-old/fs/nfs/pagelist.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/nfs/pagelist.c	2007-12-16 13:25:03.000000000 -0800
@@ -27,7 +27,7 @@
 nfs_page_alloc(void)
 {
 	struct nfs_page	*p;
-	p = kmem_cache_alloc(nfs_page_cachep, GFP_KERNEL);
+	p = kmem_cache_alloc(nfs_page_cachep, GFP_KERNEL, sizeof(*p));
 	if (p) {
 		memset(p, 0, sizeof(*p));
 		INIT_LIST_HEAD(&p->wb_list);
diff -ur linux-2.6.22.5-old/fs/nfsd/nfs4state.c linux-2.6.22.5/fs/nfsd/nfs4state.c
--- linux-2.6.22.5-old/fs/nfsd/nfs4state.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/nfsd/nfs4state.c	2007-12-16 13:25:00.000000000 -0800
@@ -194,7 +194,7 @@
 	dprintk("NFSD alloc_init_deleg\n");
 	if (num_delegations > STATEID_HASH_SIZE * 4)
 		return NULL;
-	dp = kmem_cache_alloc(deleg_slab, GFP_KERNEL);
+	dp = kmem_cache_alloc(deleg_slab, GFP_KERNEL, sizeof(*dp));
 	if (dp == NULL)
 		return dp;
 	num_delegations++;
@@ -991,7 +991,7 @@
 	struct nfs4_file *fp;
 	unsigned int hashval = file_hashval(ino);
 
-	fp = kmem_cache_alloc(file_slab, GFP_KERNEL);
+	fp = kmem_cache_alloc(file_slab, GFP_KERNEL, sizeof(*fp));
 	if (fp) {
 		kref_init(&fp->fi_ref);
 		INIT_LIST_HEAD(&fp->fi_hash);
diff -ur linux-2.6.22.5-old/fs/ntfs/attrib.c linux-2.6.22.5/fs/ntfs/attrib.c
--- linux-2.6.22.5-old/fs/ntfs/attrib.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/ntfs/attrib.c	2007-12-16 13:25:03.000000000 -0800
@@ -1272,7 +1272,7 @@
 {
 	ntfs_attr_search_ctx *ctx;
 
-	ctx = kmem_cache_alloc(ntfs_attr_ctx_cache, GFP_NOFS);
+	ctx = kmem_cache_alloc(ntfs_attr_ctx_cache, GFP_NOFS, sizeof(*ctx));
 	if (ctx)
 		ntfs_attr_init_search_ctx(ctx, ni, mrec);
 	return ctx;
diff -ur linux-2.6.22.5-old/fs/ntfs/index.c linux-2.6.22.5/fs/ntfs/index.c
--- linux-2.6.22.5-old/fs/ntfs/index.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/ntfs/index.c	2007-12-16 13:25:03.000000000 -0800
@@ -38,7 +38,7 @@
 {
 	ntfs_index_context *ictx;
 
-	ictx = kmem_cache_alloc(ntfs_index_ctx_cache, GFP_NOFS);
+	ictx = kmem_cache_alloc(ntfs_index_ctx_cache, GFP_NOFS, sizeof(*ictx));
 	if (ictx)
 		*ictx = (ntfs_index_context){ .idx_ni = idx_ni };
 	return ictx;
diff -ur linux-2.6.22.5-old/fs/ntfs/inode.c linux-2.6.22.5/fs/ntfs/inode.c
--- linux-2.6.22.5-old/fs/ntfs/inode.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/ntfs/inode.c	2007-12-16 13:25:03.000000000 -0800
@@ -323,7 +323,7 @@
 	ntfs_inode *ni;
 
 	ntfs_debug("Entering.");
-	ni = kmem_cache_alloc(ntfs_big_inode_cache, GFP_NOFS);
+	ni = kmem_cache_alloc(ntfs_big_inode_cache, GFP_NOFS, sizeof(*ni));
 	if (likely(ni != NULL)) {
 		ni->state = 0;
 		return VFS_I(ni);
@@ -348,7 +348,7 @@
 	ntfs_inode *ni;
 
 	ntfs_debug("Entering.");
-	ni = kmem_cache_alloc(ntfs_inode_cache, GFP_NOFS);
+	ni = kmem_cache_alloc(ntfs_inode_cache, GFP_NOFS, sizeof(*ni));
 	if (likely(ni != NULL)) {
 		ni->state = 0;
 		return ni;
diff -ur linux-2.6.22.5-old/fs/ntfs/unistr.c linux-2.6.22.5/fs/ntfs/unistr.c
--- linux-2.6.22.5-old/fs/ntfs/unistr.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/ntfs/unistr.c	2007-12-16 13:25:03.000000000 -0800
@@ -266,7 +266,7 @@
 
 	/* We do not trust outside sources. */
 	if (likely(ins)) {
-		ucs = kmem_cache_alloc(ntfs_name_cache, GFP_NOFS);
+		ucs = kmem_cache_alloc(ntfs_name_cache, GFP_NOFS, sizeof(*ucs));
 		if (likely(ucs)) {
 			for (i = o = 0; i < ins_len; i += wc_len) {
 				wc_len = nls->char2uni(ins + i, ins_len - i,
diff -ur linux-2.6.22.5-old/fs/ocfs2/dlm/dlmfs.c linux-2.6.22.5/fs/ocfs2/dlm/dlmfs.c
--- linux-2.6.22.5-old/fs/ocfs2/dlm/dlmfs.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/ocfs2/dlm/dlmfs.c	2007-12-16 13:25:04.000000000 -0800
@@ -272,7 +272,7 @@
 {
 	struct dlmfs_inode_private *ip;
 
-	ip = kmem_cache_alloc(dlmfs_inode_cache, GFP_NOFS);
+	ip = kmem_cache_alloc(dlmfs_inode_cache, GFP_NOFS, sizeof(*ip));
 	if (!ip)
 		return NULL;
 
diff -ur linux-2.6.22.5-old/fs/ocfs2/super.c linux-2.6.22.5/fs/ocfs2/super.c
--- linux-2.6.22.5-old/fs/ocfs2/super.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/ocfs2/super.c	2007-12-16 13:25:04.000000000 -0800
@@ -303,7 +303,7 @@
 {
 	struct ocfs2_inode_info *oi;
 
-	oi = kmem_cache_alloc(ocfs2_inode_cachep, GFP_NOFS);
+	oi = kmem_cache_alloc(ocfs2_inode_cachep, GFP_NOFS, sizeof(*oi));
 	if (!oi)
 		return NULL;
 
diff -ur linux-2.6.22.5-old/fs/ocfs2/uptodate.c linux-2.6.22.5/fs/ocfs2/uptodate.c
--- linux-2.6.22.5-old/fs/ocfs2/uptodate.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/ocfs2/uptodate.c	2007-12-16 13:25:04.000000000 -0800
@@ -350,7 +350,7 @@
 	     (unsigned long long)oi->ip_blkno,
 	     (unsigned long long)block, expand_tree);
 
-	new = kmem_cache_alloc(ocfs2_uptodate_cachep, GFP_NOFS);
+	new = kmem_cache_alloc(ocfs2_uptodate_cachep, GFP_NOFS, sizeof(*new));
 	if (!new) {
 		mlog_errno(-ENOMEM);
 		return;
diff -ur linux-2.6.22.5-old/fs/openpromfs/inode.c linux-2.6.22.5/fs/openpromfs/inode.c
--- linux-2.6.22.5-old/fs/openpromfs/inode.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/openpromfs/inode.c	2007-12-16 13:24:58.000000000 -0800
@@ -336,7 +336,7 @@
 {
 	struct op_inode_info *oi;
 
-	oi = kmem_cache_alloc(op_inode_cachep, GFP_KERNEL);
+	oi = kmem_cache_alloc(op_inode_cachep, GFP_KERNEL, sizeof(*oi));
 	if (!oi)
 		return NULL;
 
diff -ur linux-2.6.22.5-old/fs/pipe.c linux-2.6.22.5/fs/pipe.c
--- linux-2.6.22.5-old/fs/pipe.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/pipe.c	2007-12-12 09:59:49.000000000 -0800
@@ -152,6 +152,7 @@
 				  struct pipe_buffer *buf)
 {
 	struct page *page = buf->page;
+	VALGRIND_MAKE_MEM_DEFINED(page, sizeof(*page));
 
 	/*
 	 * If nobody else uses this page, and we don't already have a
diff -ur linux-2.6.22.5-old/fs/proc/inode.c linux-2.6.22.5/fs/proc/inode.c
--- linux-2.6.22.5-old/fs/proc/inode.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/proc/inode.c	2007-12-16 13:24:57.000000000 -0800
@@ -88,7 +88,7 @@
 	struct proc_inode *ei;
 	struct inode *inode;
 
-	ei = (struct proc_inode *)kmem_cache_alloc(proc_inode_cachep, GFP_KERNEL);
+	ei = (struct proc_inode *)kmem_cache_alloc(proc_inode_cachep, GFP_KERNEL, sizeof(*ei));
 	if (!ei)
 		return NULL;
 	ei->pid = NULL;
diff -ur linux-2.6.22.5-old/fs/qnx4/inode.c linux-2.6.22.5/fs/qnx4/inode.c
--- linux-2.6.22.5-old/fs/qnx4/inode.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/qnx4/inode.c	2007-12-16 13:25:03.000000000 -0800
@@ -520,7 +520,7 @@
 static struct inode *qnx4_alloc_inode(struct super_block *sb)
 {
 	struct qnx4_inode_info *ei;
-	ei = kmem_cache_alloc(qnx4_inode_cachep, GFP_KERNEL);
+	ei = kmem_cache_alloc(qnx4_inode_cachep, GFP_KERNEL, sizeof(*ei));
 	if (!ei)
 		return NULL;
 	return &ei->vfs_inode;
diff -ur linux-2.6.22.5-old/fs/reiserfs/super.c linux-2.6.22.5/fs/reiserfs/super.c
--- linux-2.6.22.5-old/fs/reiserfs/super.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/reiserfs/super.c	2007-12-16 14:14:40.000000000 -0800
@@ -496,7 +496,7 @@
 {
 	struct reiserfs_inode_info *ei;
 	ei = (struct reiserfs_inode_info *)
-	    kmem_cache_alloc(reiserfs_inode_cachep, GFP_KERNEL);
+	    kmem_cache_alloc(reiserfs_inode_cachep, GFP_KERNEL, sizeof(*ei));
 	if (!ei)
 		return NULL;
 	return &ei->vfs_inode;
diff -ur linux-2.6.22.5-old/fs/romfs/inode.c linux-2.6.22.5/fs/romfs/inode.c
--- linux-2.6.22.5-old/fs/romfs/inode.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/romfs/inode.c	2007-12-16 13:24:58.000000000 -0800
@@ -555,7 +555,7 @@
 static struct inode *romfs_alloc_inode(struct super_block *sb)
 {
 	struct romfs_inode_info *ei;
-	ei = (struct romfs_inode_info *)kmem_cache_alloc(romfs_inode_cachep, GFP_KERNEL);
+	ei = (struct romfs_inode_info *)kmem_cache_alloc(romfs_inode_cachep, GFP_KERNEL, sizeof(*ei));
 	if (!ei)
 		return NULL;
 	return &ei->vfs_inode;
diff -ur linux-2.6.22.5-old/fs/smbfs/inode.c linux-2.6.22.5/fs/smbfs/inode.c
--- linux-2.6.22.5-old/fs/smbfs/inode.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/smbfs/inode.c	2007-12-16 13:24:59.000000000 -0800
@@ -56,7 +56,7 @@
 static struct inode *smb_alloc_inode(struct super_block *sb)
 {
 	struct smb_inode_info *ei;
-	ei = (struct smb_inode_info *)kmem_cache_alloc(smb_inode_cachep, GFP_KERNEL);
+	ei = (struct smb_inode_info *)kmem_cache_alloc(smb_inode_cachep, GFP_KERNEL, sizeof(*ei));
 	if (!ei)
 		return NULL;
 	return &ei->vfs_inode;
diff -ur linux-2.6.22.5-old/fs/sysfs/dir.c linux-2.6.22.5/fs/sysfs/dir.c
--- linux-2.6.22.5-old/fs/sysfs/dir.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/sysfs/dir.c	2007-12-16 14:15:07.000000000 -0800
@@ -57,7 +57,7 @@
 {
 	struct sysfs_dirent * sd;
 
-	sd = kmem_cache_zalloc(sysfs_dir_cachep, GFP_KERNEL);
+	sd = kmem_cache_zalloc(sysfs_dir_cachep, GFP_KERNEL, sizeof(*sd));
 	if (!sd)
 		return NULL;
 
diff -ur linux-2.6.22.5-old/fs/sysv/inode.c linux-2.6.22.5/fs/sysv/inode.c
--- linux-2.6.22.5-old/fs/sysv/inode.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/sysv/inode.c	2007-12-16 13:24:59.000000000 -0800
@@ -307,7 +307,7 @@
 {
 	struct sysv_inode_info *si;
 
-	si = kmem_cache_alloc(sysv_inode_cachep, GFP_KERNEL);
+	si = kmem_cache_alloc(sysv_inode_cachep, GFP_KERNEL, sizeof(*si));
 	if (!si)
 		return NULL;
 	return &si->vfs_inode;
diff -ur linux-2.6.22.5-old/fs/udf/super.c linux-2.6.22.5/fs/udf/super.c
--- linux-2.6.22.5-old/fs/udf/super.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/udf/super.c	2007-12-16 13:25:03.000000000 -0800
@@ -112,7 +112,7 @@
 static struct inode *udf_alloc_inode(struct super_block *sb)
 {
 	struct udf_inode_info *ei;
-	ei = (struct udf_inode_info *)kmem_cache_alloc(udf_inode_cachep, GFP_KERNEL);
+	ei = (struct udf_inode_info *)kmem_cache_alloc(udf_inode_cachep, GFP_KERNEL, sizeof(*ei));
 	if (!ei)
 		return NULL;
 
diff -ur linux-2.6.22.5-old/fs/xfs/linux-2.6/kmem.c linux-2.6.22.5/fs/xfs/linux-2.6/kmem.c
--- linux-2.6.22.5-old/fs/xfs/linux-2.6/kmem.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/fs/xfs/linux-2.6/kmem.c	2007-12-16 13:25:04.000000000 -0800
@@ -124,7 +124,7 @@
 	void	*ptr;
 
 	do {
-		ptr = kmem_cache_alloc(zone, lflags);
+		ptr = kmem_cache_alloc(zone, lflags, sizeof(*ptr));
 		if (ptr || (flags & (KM_MAYFAIL|KM_NOSLEEP)))
 			return ptr;
 		if (!(++retries % 100))
diff -ur linux-2.6.22.5-old/include/acpi/platform/aclinux.h linux-2.6.22.5/include/acpi/platform/aclinux.h
--- linux-2.6.22.5-old/include/acpi/platform/aclinux.h	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/include/acpi/platform/aclinux.h	2007-12-16 13:36:54.000000000 -0800
@@ -127,7 +127,7 @@
 static inline void *acpi_os_acquire_object(acpi_cache_t * cache)
 {
 	return kmem_cache_zalloc(cache,
-				 irqs_disabled()? GFP_ATOMIC : GFP_KERNEL);
+				 irqs_disabled()? GFP_ATOMIC : GFP_KERNEL, 0);  // XXX 2007-12-16
 }
 
 #define ACPI_ALLOCATE(a)	acpi_os_allocate(a)
diff -ur linux-2.6.22.5-old/include/asm-arm26/pgalloc.h linux-2.6.22.5/include/asm-arm26/pgalloc.h
--- linux-2.6.22.5-old/include/asm-arm26/pgalloc.h	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/include/asm-arm26/pgalloc.h	2007-12-16 13:26:39.000000000 -0800
@@ -18,7 +18,7 @@
 extern struct kmem_cache *pte_cache;
 
 static inline pte_t *pte_alloc_one_kernel(struct mm_struct *mm, unsigned long addr){
-	return kmem_cache_alloc(pte_cache, GFP_KERNEL);
+	return kmem_cache_alloc(pte_cache, GFP_KERNEL, sizeof(pte_t));
 }
 
 static inline void pte_free_kernel(pte_t *pte){
diff -ur linux-2.6.22.5-old/include/asm-generic/memory_model.h linux-2.6.22.5/include/asm-generic/memory_model.h
--- linux-2.6.22.5-old/include/asm-generic/memory_model.h	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/include/asm-generic/memory_model.h	2007-12-12 13:31:08.000000000 -0800
@@ -28,7 +28,12 @@
  */
 #if defined(CONFIG_FLATMEM)
 
-#define __pfn_to_page(pfn)	(mem_map + ((pfn) - ARCH_PFN_OFFSET))
+#include "memcheck.h"
+
+#define __pfn_to_page(pfn) \
+ ({ struct page *const pg = (mem_map + ((pfn) - ARCH_PFN_OFFSET)); \
+    VALGRIND_MAKE_MEM_DEFINED(pg, sizeof(*pg)); \
+    pg; })
 #define __page_to_pfn(page)	((unsigned long)((page) - mem_map) + \
 				 ARCH_PFN_OFFSET)
 #elif defined(CONFIG_DISCONTIGMEM)
diff -ur linux-2.6.22.5-old/include/asm-i386/page.h linux-2.6.22.5/include/asm-i386/page.h
--- linux-2.6.22.5-old/include/asm-i386/page.h	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/include/asm-i386/page.h	2007-12-12 11:27:18.000000000 -0800
@@ -26,15 +26,24 @@
  *	Maybe the K6-III ?
  */
  
-#define clear_page(page)	memset((void *)(page), 0, PAGE_SIZE)
-#define copy_page(to,from)	memcpy((void *)(to), (void *)(from), PAGE_SIZE)
+#define clear_page(page) do {\
+      VALGRIND_MAKE_MEM_DEFINED((void *)(page), PAGE_SIZE); \
+      memset((void *)(page), 0, PAGE_SIZE); \
+   } while (0)
+#define copy_page(to,from) do {\
+      VALGRIND_MAKE_MEM_DEFINED((void *)(to), PAGE_SIE); \
+      memcpy((void *)(to), (void *)(from), PAGE_SIZE); \
+   } while (0)
 
 #endif
 
 #define clear_user_page(page, vaddr, pg)	clear_page(page)
 #define copy_user_page(to, from, vaddr, pg)	copy_page(to, from)
 
-#define alloc_zeroed_user_highpage(vma, vaddr) alloc_page_vma(GFP_HIGHUSER | __GFP_ZERO, vma, vaddr)
+#define alloc_zeroed_user_highpage(vma, vaddr) do {\
+      alloc_page_vma(GFP_HIGHUSER | __GFP_ZERO, vma, vaddr);\
+      VALGRIND_MALLOCLIKE_BLOCK(vaddr, PAGE_SIZE, 0, 1/*is_defined*/);\
+   } while (0)
 #define __HAVE_ARCH_ALLOC_ZEROED_USER_HIGHPAGE
 
 /*
diff -ur linux-2.6.22.5-old/include/asm-powerpc/pgalloc-64.h linux-2.6.22.5/include/asm-powerpc/pgalloc-64.h
--- linux-2.6.22.5-old/include/asm-powerpc/pgalloc-64.h	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/include/asm-powerpc/pgalloc-64.h	2007-12-16 13:33:15.000000000 -0800
@@ -22,7 +22,7 @@
 
 static inline pgd_t *pgd_alloc(struct mm_struct *mm)
 {
-	return kmem_cache_alloc(pgtable_cache[PGD_CACHE_NUM], GFP_KERNEL);
+	return kmem_cache_alloc(pgtable_cache[PGD_CACHE_NUM], GFP_KERNEL, sizeof(pgd_t));
 }
 
 static inline void pgd_free(pgd_t *pgd)
@@ -37,7 +37,7 @@
 static inline pud_t *pud_alloc_one(struct mm_struct *mm, unsigned long addr)
 {
 	return kmem_cache_alloc(pgtable_cache[PUD_CACHE_NUM],
-				GFP_KERNEL|__GFP_REPEAT);
+				GFP_KERNEL|__GFP_REPEAT, sizeof(pud_t));
 }
 
 static inline void pud_free(pud_t *pud)
@@ -73,7 +73,7 @@
 static inline pmd_t *pmd_alloc_one(struct mm_struct *mm, unsigned long addr)
 {
 	return kmem_cache_alloc(pgtable_cache[PMD_CACHE_NUM],
-				GFP_KERNEL|__GFP_REPEAT);
+				GFP_KERNEL|__GFP_REPEAT, sizeof(pmd_t));
 }
 
 static inline void pmd_free(pmd_t *pmd)
diff -ur linux-2.6.22.5-old/include/asm-um/page.h linux-2.6.22.5/include/asm-um/page.h
--- linux-2.6.22.5-old/include/asm-um/page.h	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/include/asm-um/page.h	2007-12-11 14:48:35.000000000 -0800
@@ -10,6 +10,7 @@
 struct page;
 
 #include <asm/vm-flags.h>
+#include "memcheck.h"
 
 /* PAGE_SHIFT determines the page size */
 #define PAGE_SHIFT	12
@@ -20,8 +21,14 @@
  * These are used to make use of C type-checking..
  */
 
-#define clear_page(page)	memset((void *)(page), 0, PAGE_SIZE)
-#define copy_page(to,from)	memcpy((void *)(to), (void *)(from), PAGE_SIZE)
+#define clear_page(page) do {\
+      VALGRIND_MAKE_MEM_DEFINED((void *)(page), PAGE_SIZE); \
+      memset((void *)(page), 0, PAGE_SIZE); \
+   } while (0)
+#define copy_page(to,from) do {\
+      VALGRIND_MAKE_MEM_DEFINED((void *)(to), PAGE_SIZE); \
+      memcpy((void *)(to), (void *)(from), PAGE_SIZE); \
+   } while (0)
 
 #define clear_user_page(page, vaddr, pg)	clear_page(page)
 #define copy_user_page(to, from, vaddr, pg)	copy_page(to, from)
diff -ur linux-2.6.22.5-old/include/asm-um/thread_info.h linux-2.6.22.5/include/asm-um/thread_info.h
--- linux-2.6.22.5-old/include/asm-um/thread_info.h	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/include/asm-um/thread_info.h	2007-11-07 16:16:56.000000000 -0800
@@ -53,10 +53,8 @@
 }
 
 /* thread information allocation */
-#define alloc_thread_info(tsk) \
-	((struct thread_info *) kmalloc(THREAD_SIZE, GFP_KERNEL))
-#define free_thread_info(ti) kfree(ti)
-
+extern struct thread_info *alloc_thread_info(struct task_struct *);
+extern void                 free_thread_info(struct thread_info *);
 #endif
 
 #define PREEMPT_ACTIVE		0x10000000
diff -ur linux-2.6.22.5-old/include/linux/fs.h linux-2.6.22.5/include/linux/fs.h
--- linux-2.6.22.5-old/include/linux/fs.h	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/include/linux/fs.h	2007-12-16 13:29:45.000000000 -0800
@@ -1513,7 +1513,7 @@
 
 extern struct kmem_cache *names_cachep;
 
-#define __getname()	kmem_cache_alloc(names_cachep, GFP_KERNEL)
+#define __getname()	kmem_cache_alloc(names_cachep, GFP_KERNEL, 0)  /* XXX 2007-12-16 */
 #define __putname(name) kmem_cache_free(names_cachep, (void *)(name))
 #ifndef CONFIG_AUDITSYSCALL
 #define putname(name)   __putname(name)
diff -ur linux-2.6.22.5-old/include/linux/gfp.h linux-2.6.22.5/include/linux/gfp.h
--- linux-2.6.22.5-old/include/linux/gfp.h	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/include/linux/gfp.h	2007-12-19 12:51:39.000000000 -0800
@@ -5,6 +5,7 @@
 #include <linux/stddef.h>
 #include <linux/linkage.h>
 
+extern int printf(const char *fmt, ...);
 struct vm_area_struct;
 
 /*
@@ -127,6 +128,7 @@
 static inline struct page *alloc_pages_node(int nid, gfp_t gfp_mask,
 						unsigned int order)
 {
+	struct page *rv;
 	if (unlikely(order >= MAX_ORDER))
 		return NULL;
 
@@ -134,8 +136,12 @@
 	if (nid < 0)
 		nid = numa_node_id();
 
-	return __alloc_pages(gfp_mask, order,
+	rv = __alloc_pages(gfp_mask, order,
 		NODE_DATA(nid)->node_zonelists + gfp_zone(gfp_mask));
+//VALGRIND_PRINTF("alloc_pages_node rv=%p  pc=%p\n", rv, __builtin_return_address(0));
+	//VALGRIND_MALLOCLIKE_BLOCK(rv, /*sizeof(*rv)*/ 32<<order, 0, 0);  // XXX 2007-12-19
+	VALGRIND_MAKE_MEM_DEFINED(rv, /*sizeof(*rv)*/ 32<<order);  //  XXX 2007-12-19
+	return rv;
 }
 
 #ifdef CONFIG_NUMA
diff -ur linux-2.6.22.5-old/include/linux/jbd2.h linux-2.6.22.5/include/linux/jbd2.h
--- linux-2.6.22.5-old/include/linux/jbd2.h	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/include/linux/jbd2.h	2007-12-16 13:32:43.000000000 -0800
@@ -961,7 +961,7 @@
 
 static inline handle_t *jbd_alloc_handle(gfp_t gfp_flags)
 {
-	return kmem_cache_alloc(jbd2_handle_cache, gfp_flags);
+	return kmem_cache_alloc(jbd2_handle_cache, gfp_flags, sizeof(*handle_t));
 }
 
 static inline void jbd_free_handle(handle_t *handle)
diff -ur linux-2.6.22.5-old/include/linux/jbd.h linux-2.6.22.5/include/linux/jbd.h
--- linux-2.6.22.5-old/include/linux/jbd.h	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/include/linux/jbd.h	2007-12-16 13:28:05.000000000 -0800
@@ -952,7 +952,7 @@
 
 static inline handle_t *jbd_alloc_handle(gfp_t gfp_flags)
 {
-	return kmem_cache_alloc(jbd_handle_cache, gfp_flags);
+	return kmem_cache_alloc(jbd_handle_cache, gfp_flags, sizeof(handle_t));
 }
 
 static inline void jbd_free_handle(handle_t *handle)
diff -ur linux-2.6.22.5-old/include/linux/mm.h linux-2.6.22.5/include/linux/mm.h
--- linux-2.6.22.5-old/include/linux/mm.h	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/include/linux/mm.h	2007-12-11 17:18:01.000000000 -0800
@@ -286,9 +286,12 @@
 	atomic_inc(&page->_count);
 }
 
+#include "memcheck.h"
+
 static inline struct page *virt_to_head_page(const void *x)
 {
 	struct page *page = virt_to_page(x);
+	VALGRIND_MAKE_MEM_DEFINED(page, sizeof(*page));
 	return compound_head(page);
 }
 
diff -ur linux-2.6.22.5-old/include/linux/rmap.h linux-2.6.22.5/include/linux/rmap.h
--- linux-2.6.22.5-old/include/linux/rmap.h	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/include/linux/rmap.h	2007-12-16 13:37:23.000000000 -0800
@@ -34,7 +34,7 @@
 
 static inline struct anon_vma *anon_vma_alloc(void)
 {
-	return kmem_cache_alloc(anon_vma_cachep, GFP_KERNEL);
+	return kmem_cache_alloc(anon_vma_cachep, GFP_KERNEL, sizeof(struct anon_vma));
 }
 
 static inline void anon_vma_free(struct anon_vma *anon_vma)
diff -ur linux-2.6.22.5-old/include/linux/skbuff.h linux-2.6.22.5/include/linux/skbuff.h
--- linux-2.6.22.5-old/include/linux/skbuff.h	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/include/linux/skbuff.h	2007-12-15 17:53:19.000000000 -0800
@@ -327,16 +327,19 @@
 extern void	       __kfree_skb(struct sk_buff *skb);
 extern struct sk_buff *__alloc_skb(unsigned int size,
 				   gfp_t priority, int fclone, int node);
+// __alloc_skb allocates and initializes, so valgrind accounting is there.
 static inline struct sk_buff *alloc_skb(unsigned int size,
 					gfp_t priority)
 {
-	return __alloc_skb(size, priority, 0, -1);
+	struct sk_buff *skb =__alloc_skb(size, priority, 0, -1);
+	return skb;
 }
 
 static inline struct sk_buff *alloc_skb_fclone(unsigned int size,
 					       gfp_t priority)
 {
-	return __alloc_skb(size, priority, 1, -1);
+	struct sk_buff *skb =__alloc_skb(size, priority, 1, -1);
+	return skb;
 }
 
 extern void	       kfree_skbmem(struct sk_buff *skb);
diff -ur linux-2.6.22.5-old/include/linux/slab_def.h linux-2.6.22.5/include/linux/slab_def.h
--- linux-2.6.22.5-old/include/linux/slab_def.h	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/include/linux/slab_def.h	2007-12-17 10:27:49.000000000 -0800
@@ -1,6 +1,7 @@
 #ifndef _LINUX_SLAB_DEF_H
 #define	_LINUX_SLAB_DEF_H
 
+//extern int printf(const char *fmt, ...);
 /*
  * Definitions unique to the original Linux SLAB allocator.
  *
@@ -25,8 +26,11 @@
 };
 extern struct cache_sizes malloc_sizes[];
 
+#include "valgrind.h"
+
 static inline void *kmalloc(size_t size, gfp_t flags)
 {
+	void *rv;
 	if (__builtin_constant_p(size)) {
 		int i = 0;
 #define CACHE(x) \
@@ -40,19 +44,27 @@
 			extern void __you_cannot_kmalloc_that_much(void);
 			__you_cannot_kmalloc_that_much();
 		}
-found:
+found: ;
 #ifdef CONFIG_ZONE_DMA
-		if (flags & GFP_DMA)
-			return kmem_cache_alloc(malloc_sizes[i].cs_dmacachep,
-						flags);
+		if (flags & GFP_DMA) {
+			rv = kmem_cache_alloc(malloc_sizes[i].cs_dmacachep,
+						flags, size);
+//printf("kmalloc 1 %p\n", rv);
+			return rv;
+		}
 #endif
-		return kmem_cache_alloc(malloc_sizes[i].cs_cachep, flags);
+		rv = kmem_cache_alloc(malloc_sizes[i].cs_cachep, flags, size);
+//printf("kmalloc 2 %p\n", rv);
+		return rv;
 	}
-	return __kmalloc(size, flags);
+	rv = __kmalloc(size, flags);
+//printf("kmalloc 3 %p\n", rv);
+	return rv;
 }
 
 static inline void *kzalloc(size_t size, gfp_t flags)
 {
+	void *rv;
 	if (__builtin_constant_p(size)) {
 		int i = 0;
 #define CACHE(x) \
@@ -66,15 +78,22 @@
 			extern void __you_cannot_kzalloc_that_much(void);
 			__you_cannot_kzalloc_that_much();
 		}
-found:
+found: ;
 #ifdef CONFIG_ZONE_DMA
-		if (flags & GFP_DMA)
-			return kmem_cache_zalloc(malloc_sizes[i].cs_dmacachep,
-						flags);
+		if (flags & GFP_DMA) {
+			rv = kmem_cache_zalloc(malloc_sizes[i].cs_dmacachep,
+						flags, size);
+//printf("kzalloc 1 %p\n", rv);
+			return rv;
+		}
 #endif
-		return kmem_cache_zalloc(malloc_sizes[i].cs_cachep, flags);
+		rv = kmem_cache_zalloc(malloc_sizes[i].cs_cachep, flags, size);
+//printf("kzalloc 2 %p\n", rv);
+		return rv;
 	}
-	return __kzalloc(size, flags);
+	rv = __kzalloc(size, flags);
+//printf("kzalloc 3 %p\n", rv);
+	return rv;
 }
 
 #ifdef CONFIG_NUMA
@@ -82,6 +101,7 @@
 
 static inline void *kmalloc_node(size_t size, gfp_t flags, int node)
 {
+	void *rv;
 	if (__builtin_constant_p(size)) {
 		int i = 0;
 #define CACHE(x) \
@@ -95,16 +115,19 @@
 			extern void __you_cannot_kmalloc_that_much(void);
 			__you_cannot_kmalloc_that_much();
 		}
-found:
+found: ;
 #ifdef CONFIG_ZONE_DMA
-		if (flags & GFP_DMA)
-			return kmem_cache_alloc_node(malloc_sizes[i].cs_dmacachep,
-						flags, node);
+		if (flags & GFP_DMA) {
+			rv = kmem_cache_alloc_node(malloc_sizes[i].cs_dmacachep,
+						flags, node, size);
+		}
 #endif
-		return kmem_cache_alloc_node(malloc_sizes[i].cs_cachep,
-						flags, node);
+		rv = kmem_cache_alloc_node(malloc_sizes[i].cs_cachep,
+						flags, node, size);
+		return rv;
 	}
-	return __kmalloc_node(size, flags, node);
+	rv = __kmalloc_node(size, flags, node);
+	return rv;
 }
 
 #endif	/* CONFIG_NUMA */
diff -ur linux-2.6.22.5-old/include/linux/slab.h linux-2.6.22.5/include/linux/slab.h
--- linux-2.6.22.5-old/include/linux/slab.h	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/include/linux/slab.h	2007-12-17 14:45:32.000000000 -0800
@@ -44,8 +44,8 @@
 			void (*)(void *, struct kmem_cache *, unsigned long));
 void kmem_cache_destroy(struct kmem_cache *);
 int kmem_cache_shrink(struct kmem_cache *);
-void *kmem_cache_alloc(struct kmem_cache *, gfp_t);
-void *kmem_cache_zalloc(struct kmem_cache *, gfp_t);
+void *kmem_cache_alloc(struct kmem_cache *, gfp_t, size_t);
+void *kmem_cache_zalloc(struct kmem_cache *, gfp_t, size_t);
 void kmem_cache_free(struct kmem_cache *, void *);
 unsigned int kmem_cache_size(struct kmem_cache *);
 const char *kmem_cache_name(struct kmem_cache *);
@@ -64,12 +64,12 @@
 		(__flags), NULL, NULL)
 
 #ifdef CONFIG_NUMA
-extern void *kmem_cache_alloc_node(struct kmem_cache *, gfp_t flags, int node);
+extern void *kmem_cache_alloc_node(struct kmem_cache *, gfp_t flags, int node, size_t size);
 #else
 static inline void *kmem_cache_alloc_node(struct kmem_cache *cachep,
-					gfp_t flags, int node)
+					gfp_t flags, int node, size_t size)
 {
-	return kmem_cache_alloc(cachep, flags);
+	return kmem_cache_alloc(cachep, flags, size);
 }
 #endif
 
@@ -176,7 +176,10 @@
  */
 static inline void *kmalloc(size_t size, gfp_t flags)
 {
-	return __kmalloc(size, flags);
+	void *const rv = __kmalloc(size, flags);
+	printf("kmalloc slab.h\n");
+	VALGRIND_MALLOCLIKE_BLOCK(rv, size, 0, 0);
+	return rv;
 }
 
 /**
@@ -186,7 +189,10 @@
  */
 static inline void *kzalloc(size_t size, gfp_t flags)
 {
-	return __kzalloc(size, flags);
+	void *const rv= __kzalloc(size, flags);
+	printf("kzalloc slab.h\n");
+	VALGRIND_MALLOCLIKE_BLOCK(rv, size, 0, 1);
+	return rv;
 }
 #endif
 
@@ -212,11 +218,17 @@
  */
 #if defined(CONFIG_DEBUG_SLAB) || defined(CONFIG_SLUB)
 extern void *__kmalloc_track_caller(size_t, gfp_t, void*);
-#define kmalloc_track_caller(size, flags) \
-	__kmalloc_track_caller(size, flags, __builtin_return_address(0))
+#define kmalloc_track_caller(size, flags) ({\
+	void *const rv = __kmalloc_track_caller(size, flags, __builtin_return_address(0)); \
+	/*printf("kmalloc_track_caller\n");*/\
+	/*subsumed VALGRIND_MALLOCLIKE_BLOCK(rv, size, 0, 0);*/\
+	rv; })
 #else
-#define kmalloc_track_caller(size, flags) \
-	__kmalloc(size, flags)
+#define kmalloc_track_caller(size, flags) ){\
+	void *const rv = __kmalloc(size, flags);\
+	/*printf("kmalloc_track_caller\n");*/\
+	/*subsumed VALGRIND_MALLOCLIKE_BLOCK(rv, size, 0, 0);*/\
+	rv; })
 #endif /* DEBUG_SLAB */
 
 #ifdef CONFIG_NUMA
diff -ur linux-2.6.22.5-old/include/linux/slub_def.h linux-2.6.22.5/include/linux/slub_def.h
--- linux-2.6.22.5-old/include/linux/slub_def.h	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/include/linux/slub_def.h	2007-12-16 13:36:03.000000000 -0800
@@ -179,7 +179,7 @@
 		if (!s)
 			return ZERO_SIZE_PTR;
 
-		return kmem_cache_alloc(s, flags);
+		return kmem_cache_alloc(s, flags, size);
 	} else
 		return __kmalloc(size, flags);
 }
@@ -192,7 +192,7 @@
 		if (!s)
 			return ZERO_SIZE_PTR;
 
-		return kmem_cache_zalloc(s, flags);
+		return kmem_cache_zalloc(s, flags, size);
 	} else
 		return __kzalloc(size, flags);
 }
@@ -208,7 +208,7 @@
 		if (!s)
 			return ZERO_SIZE_PTR;
 
-		return kmem_cache_alloc_node(s, flags, node);
+		return kmem_cache_alloc_node(s, flags, node, size);
 	} else
 		return __kmalloc_node(size, flags, node);
 }
diff -ur linux-2.6.22.5-old/include/net/request_sock.h linux-2.6.22.5/include/net/request_sock.h
--- linux-2.6.22.5-old/include/net/request_sock.h	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/include/net/request_sock.h	2007-12-16 14:17:41.000000000 -0800
@@ -60,7 +60,8 @@
 
 static inline struct request_sock *reqsk_alloc(const struct request_sock_ops *ops)
 {
-	struct request_sock *req = kmem_cache_alloc(ops->slab, GFP_ATOMIC);
+	struct request_sock *req = kmem_cache_alloc(ops->slab, GFP_ATOMIC,
+		sizeof(struct request_sock));
 
 	if (req != NULL)
 		req->rsk_ops = ops;
diff -ur linux-2.6.22.5-old/include/scsi/libsas.h linux-2.6.22.5/include/scsi/libsas.h
--- linux-2.6.22.5-old/include/scsi/libsas.h	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/include/scsi/libsas.h	2007-12-16 13:36:26.000000000 -0800
@@ -566,7 +566,7 @@
 static inline struct sas_task *sas_alloc_task(gfp_t flags)
 {
 	extern struct kmem_cache *sas_task_cache;
-	struct sas_task *task = kmem_cache_zalloc(sas_task_cache, flags);
+	struct sas_task *task = kmem_cache_zalloc(sas_task_cache, flags, sizeof(*task));
 
 	if (task) {
 		INIT_LIST_HEAD(&task->list);
diff -ur linux-2.6.22.5-old/ipc/mqueue.c linux-2.6.22.5/ipc/mqueue.c
--- linux-2.6.22.5-old/ipc/mqueue.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/ipc/mqueue.c	2007-12-16 13:24:57.000000000 -0800
@@ -222,7 +222,7 @@
 {
 	struct mqueue_inode_info *ei;
 
-	ei = kmem_cache_alloc(mqueue_inode_cachep, GFP_KERNEL);
+	ei = kmem_cache_alloc(mqueue_inode_cachep, GFP_KERNEL, sizeof(*ei));
 	if (!ei)
 		return NULL;
 	return &ei->vfs_inode;
diff -ur linux-2.6.22.5-old/kernel/exit.c linux-2.6.22.5/kernel/exit.c
--- linux-2.6.22.5-old/kernel/exit.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/kernel/exit.c	2007-12-12 13:33:45.000000000 -0800
@@ -859,6 +859,8 @@
 		release_task(tsk);
 }
 
+#include "valgrind.h"
+
 fastcall NORET_TYPE void do_exit(long code)
 {
 	struct task_struct *tsk = current;
diff -ur linux-2.6.22.5-old/kernel/fork.c linux-2.6.22.5/kernel/fork.c
--- linux-2.6.22.5-old/kernel/fork.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/kernel/fork.c	2007-12-16 20:49:21.000000000 -0800
@@ -81,7 +81,7 @@
 }
 
 #ifndef __HAVE_ARCH_TASK_STRUCT_ALLOCATOR
-# define alloc_task_struct()	kmem_cache_alloc(task_struct_cachep, GFP_KERNEL)
+# define alloc_task_struct()	kmem_cache_alloc(task_struct_cachep, GFP_KERNEL, sizeof(struct task_struct))
 # define free_task_struct(tsk)	kmem_cache_free(task_struct_cachep, (tsk))
 static struct kmem_cache *task_struct_cachep;
 #endif
@@ -238,7 +238,7 @@
 				goto fail_nomem;
 			charge = len;
 		}
-		tmp = kmem_cache_alloc(vm_area_cachep, GFP_KERNEL);
+		tmp = kmem_cache_alloc(vm_area_cachep, GFP_KERNEL, sizeof(*tmp));
 		if (!tmp)
 			goto fail_nomem;
 		*tmp = *mpnt;
@@ -322,7 +322,7 @@
 
  __cacheline_aligned_in_smp DEFINE_SPINLOCK(mmlist_lock);
 
-#define allocate_mm()	(kmem_cache_alloc(mm_cachep, GFP_KERNEL))
+#define allocate_mm()	(kmem_cache_alloc(mm_cachep, GFP_KERNEL, sizeof(struct mm_struct)))
 #define free_mm(mm)	(kmem_cache_free(mm_cachep, (mm)))
 
 #include <linux/init_task.h>
@@ -572,7 +572,7 @@
 
 static inline struct fs_struct *__copy_fs_struct(struct fs_struct *old)
 {
-	struct fs_struct *fs = kmem_cache_alloc(fs_cachep, GFP_KERNEL);
+	struct fs_struct *fs = kmem_cache_alloc(fs_cachep, GFP_KERNEL, sizeof(*fs));
 	/* We don't need to lock fs - think why ;-) */
 	if (fs) {
 		atomic_set(&fs->count, 1);
@@ -633,7 +633,7 @@
 	struct files_struct *newf;
 	struct fdtable *fdt;
 
-	newf = kmem_cache_alloc(files_cachep, GFP_KERNEL);
+	newf = kmem_cache_alloc(files_cachep, GFP_KERNEL, sizeof(*newf));
 	if (!newf)
 		goto out;
 
@@ -813,7 +813,7 @@
 		atomic_inc(&current->sighand->count);
 		return 0;
 	}
-	sig = kmem_cache_alloc(sighand_cachep, GFP_KERNEL);
+	sig = kmem_cache_alloc(sighand_cachep, GFP_KERNEL, sizeof(*sig));
 	rcu_assign_pointer(tsk->sighand, sig);
 	if (!sig)
 		return -ENOMEM;
@@ -838,7 +838,7 @@
 		atomic_inc(&current->signal->live);
 		return 0;
 	}
-	sig = kmem_cache_alloc(signal_cachep, GFP_KERNEL);
+	sig = kmem_cache_alloc(signal_cachep, GFP_KERNEL, sizeof(*sig));
 	tsk->signal = sig;
 	if (!sig)
 		return -ENOMEM;
@@ -943,6 +943,8 @@
 #endif
 }
 
+#include "valgrind.h"
+
 /*
  * This creates a new process as a copy of the old one,
  * but does not actually start it yet.
@@ -962,23 +964,26 @@
 	int retval;
 	struct task_struct *p = NULL;
 
-	if ((clone_flags & (CLONE_NEWNS|CLONE_FS)) == (CLONE_NEWNS|CLONE_FS))
+	if ((clone_flags & (CLONE_NEWNS|CLONE_FS)) == (CLONE_NEWNS|CLONE_FS)) {
 		return ERR_PTR(-EINVAL);
+	}
 
 	/*
 	 * Thread groups must share signals as well, and detached threads
 	 * can only be started up within the thread group.
 	 */
-	if ((clone_flags & CLONE_THREAD) && !(clone_flags & CLONE_SIGHAND))
+	if ((clone_flags & CLONE_THREAD) && !(clone_flags & CLONE_SIGHAND)) {
 		return ERR_PTR(-EINVAL);
+	}
 
 	/*
 	 * Shared signal handlers imply shared VM. By way of the above,
 	 * thread groups also imply shared VM. Blocking this case allows
 	 * for various simplifications in other code.
 	 */
-	if ((clone_flags & CLONE_SIGHAND) && !(clone_flags & CLONE_VM))
+	if ((clone_flags & CLONE_SIGHAND) && !(clone_flags & CLONE_VM)) {
 		return ERR_PTR(-EINVAL);
+	}
 
 	retval = security_task_create(clone_flags);
 	if (retval)
diff -ur linux-2.6.22.5-old/kernel/pid.c linux-2.6.22.5/kernel/pid.c
--- linux-2.6.22.5-old/kernel/pid.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/kernel/pid.c	2007-12-16 13:24:57.000000000 -0800
@@ -209,7 +209,7 @@
 	enum pid_type type;
 	int nr = -1;
 
-	pid = kmem_cache_alloc(pid_cachep, GFP_KERNEL);
+	pid = kmem_cache_alloc(pid_cachep, GFP_KERNEL, sizeof(*pid));
 	if (!pid)
 		goto out;
 
diff -ur linux-2.6.22.5-old/kernel/posix-timers.c linux-2.6.22.5/kernel/posix-timers.c
--- linux-2.6.22.5-old/kernel/posix-timers.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/kernel/posix-timers.c	2007-12-16 13:48:18.000000000 -0800
@@ -429,7 +429,7 @@
 static struct k_itimer * alloc_posix_timer(void)
 {
 	struct k_itimer *tmr;
-	tmr = kmem_cache_zalloc(posix_timers_cache, GFP_KERNEL);
+	tmr = kmem_cache_zalloc(posix_timers_cache, GFP_KERNEL, sizeof(*tmr));
 	if (!tmr)
 		return tmr;
 	if (unlikely(!(tmr->sigq = sigqueue_alloc()))) {
diff -ur linux-2.6.22.5-old/kernel/rcupdate.c linux-2.6.22.5/kernel/rcupdate.c
--- linux-2.6.22.5-old/kernel/rcupdate.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/kernel/rcupdate.c	2007-12-20 19:32:24.000000000 -0800
@@ -49,6 +49,8 @@
 #include <linux/cpu.h>
 #include <linux/mutex.h>
 
+#include "memcheck.h"
+
 /* Definition for rcupdate control block. */
 static struct rcu_ctrlblk rcu_ctrlblk = {
 	.cur = -300,
@@ -103,6 +105,55 @@
 }
 #endif
 
+static void vg_check_rcu_head(struct rcu_head const *head, int a)
+{
+	int j;
+	struct rcu_head const *const head0 = head;
+	char vbits[sizeof(*head)];
+	for (; head; head= head->next) {
+		int r = VALGRIND_GET_VBITS(head, &vbits, sizeof(vbits));
+		if (1!=r) {
+			VALGRIND_PRINTF("vg_check_rcu_head vbits=%d  addr=%p\n", r, head);
+		}
+		else for (j=0; j < sizeof(vbits); ++j) if (0!=vbits[j]) {
+			VALGRIND_PRINTF("vg_check_rcu_head head0=%p  head=%p %d\n", head0, head, j);
+		}
+	}
+}
+
+static void vg_check_vbits(void const *ptr, unsigned size)
+{
+	int j;
+	void const *const ptr0 = ptr;
+	unsigned const size0 = size;
+	unsigned char vbits[128];
+	for (j=0; j < size; (ptr+= sizeof(vbits)), (j+=sizeof(vbits))) {
+		int k;
+		int const n = min_t(unsigned, sizeof(vbits), size - j);
+		VALGRIND_GET_VBITS(ptr, vbits, n);
+		for (k=0; k < n; ++k) if (0!=vbits[k]) {
+			VALGRIND_PRINTF("vg_check_vbits ptr0=%p  size0=%d  j=%d k=%d\n",
+				ptr0, size0, j, k);
+			for(;;);
+		}
+	}
+}
+
+static void vg_bogey(struct rcu_head **tail)
+{
+	if (tail) {
+		vg_check_vbits(tail, sizeof(struct rcu_head));
+	}
+}
+
+static void vg_check_rcu_data(struct rcu_data const *rdp, int k)
+{
+	vg_check_vbits(rdp, sizeof(*rdp));
+	vg_check_rcu_head(rdp->nxtlist, 1+k);
+	vg_check_rcu_head(rdp->curlist, 2+k);
+	vg_check_rcu_head(rdp->donelist, 3+k);
+}
+
 /**
  * call_rcu - Queue an RCU callback for invocation after a grace period.
  * @head: structure to be used for queueing the RCU updates.
@@ -123,9 +174,12 @@
 	head->func = func;
 	head->next = NULL;
 	local_irq_save(flags);
+vg_check_rcu_head(head, 4);
 	rdp = &__get_cpu_var(rcu_data);
+vg_check_rcu_data(rdp, 1<<2);
 	*rdp->nxttail = head;
 	rdp->nxttail = &head->next;
+	vg_bogey(rdp->nxttail);
 	if (unlikely(++rdp->qlen > qhimark)) {
 		rdp->blimit = INT_MAX;
 		force_quiescent_state(rdp, &rcu_ctrlblk);
@@ -158,9 +212,12 @@
 	head->func = func;
 	head->next = NULL;
 	local_irq_save(flags);
+vg_check_rcu_head(head, 5);
 	rdp = &__get_cpu_var(rcu_bh_data);
+vg_check_rcu_data(rdp, 2>>2);
 	*rdp->nxttail = head;
 	rdp->nxttail = &head->next;
+	vg_bogey(rdp->nxttail);
 
 	if (unlikely(++rdp->qlen > qhimark)) {
 		rdp->blimit = INT_MAX;
@@ -190,6 +247,7 @@
 
 static void rcu_barrier_callback(struct rcu_head *notused)
 {
+	vg_check_rcu_head(notused, 6);
 	if (atomic_dec_and_test(&rcu_barrier_cpu_count))
 		complete(&rcu_barrier_completion);
 }
@@ -203,7 +261,9 @@
 	struct rcu_data *rdp = &per_cpu(rcu_data, cpu);
 	struct rcu_head *head;
 
+vg_check_rcu_data(rdp, 3<<2);
 	head = &rdp->barrier;
+vg_check_rcu_head(head, 7);
 	atomic_inc(&rcu_barrier_cpu_count);
 	call_rcu(head, rcu_barrier_callback);
 }
@@ -224,6 +284,9 @@
 }
 EXPORT_SYMBOL_GPL(rcu_barrier);
 
+char vg_rcu_data[sizeof(struct rcu_data)];
+char vg_rcu_list[sizeof(struct rcu_head)];
+struct rcu_head *vg_donelist;
 /*
  * Invoke the completed RCU callbacks. They are expected to be in
  * a per-cpu list.
@@ -233,9 +296,17 @@
 	struct rcu_head *next, *list;
 	int count = 0;
 
+//printf("rcu_do_batch rdp=%p  list=%p\n", rdp, rdp->donelist);
+	VALGRIND_GET_VBITS(rdp, &vg_rcu_data, sizeof(vg_rcu_data));
+//	VALGRIND_MAKE_MEM_DEFINED(rdp, sizeof(*rdp));  // XXX 2007-12-12 jreiser
 	list = rdp->donelist;
+	vg_donelist = rdp->donelist;
 	while (list) {
+		vg_check_rcu_head(list, 8);
+//printf("..list=%p\n", list);
+//		VALGRIND_MAKE_MEM_DEFINED(list, sizeof(*list));  // XXX 2007-12-12 jreiser
 		next = list->next;
+		vg_check_rcu_head(next, 9);
 		prefetch(next);
 		list->func(list);
 		list = next;
@@ -372,9 +443,13 @@
 				struct rcu_head **tail)
 {
 	local_irq_disable();
+vg_check_rcu_head(list, 10);
 	*this_rdp->nxttail = list;
-	if (list)
+	if (list) {
 		this_rdp->nxttail = tail;
+		if (tail) 
+			vg_bogey(this_rdp->nxttail);
+	}
 	local_irq_enable();
 }
 
@@ -399,6 +474,8 @@
 	struct rcu_data *this_rdp = &get_cpu_var(rcu_data);
 	struct rcu_data *this_bh_rdp = &get_cpu_var(rcu_bh_data);
 
+vg_check_rcu_data(this_rdp, 4<<2);
+vg_check_rcu_data(this_bh_rdp, 5<<2);
 	__rcu_offline_cpu(this_rdp, &rcu_ctrlblk,
 					&per_cpu(rcu_data, cpu));
 	__rcu_offline_cpu(this_bh_rdp, &rcu_bh_ctrlblk,
@@ -422,6 +499,8 @@
 static void __rcu_process_callbacks(struct rcu_ctrlblk *rcp,
 					struct rcu_data *rdp)
 {
+vg_check_vbits(rcp, sizeof(*rcp));
+vg_check_rcu_data(rdp, 6<<2);
 	if (rdp->curlist && !rcu_batch_before(rcp->completed, rdp->batch)) {
 		*rdp->donetail = rdp->curlist;
 		rdp->donetail = rdp->curtail;
@@ -435,6 +514,7 @@
 		rdp->curtail = rdp->nxttail;
 		rdp->nxtlist = NULL;
 		rdp->nxttail = &rdp->nxtlist;
+		vg_bogey(rdp->nxttail);
 		local_irq_enable();
 
 		/*
@@ -514,6 +594,8 @@
 	struct rcu_data *rdp = &per_cpu(rcu_data, cpu);
 	struct rcu_data *rdp_bh = &per_cpu(rcu_bh_data, cpu);
 
+vg_check_rcu_data(rdp, 7<<2);
+vg_check_rcu_data(rdp_bh, 8<<2);
 	return (!!rdp->curlist || !!rdp_bh->curlist || rcu_pending(cpu));
 }
 
@@ -535,6 +617,7 @@
 	memset(rdp, 0, sizeof(*rdp));
 	rdp->curtail = &rdp->curlist;
 	rdp->nxttail = &rdp->nxtlist;
+	vg_bogey(rdp->nxttail);
 	rdp->donetail = &rdp->donelist;
 	rdp->quiescbatch = rcp->completed;
 	rdp->qs_pending = 0;
@@ -547,6 +630,8 @@
 	struct rcu_data *rdp = &per_cpu(rcu_data, cpu);
 	struct rcu_data *bh_rdp = &per_cpu(rcu_bh_data, cpu);
 
+vg_check_rcu_data(rdp, 9<<2);
+vg_check_rcu_data(bh_rdp, 10<<2);
 	rcu_init_percpu_data(cpu, &rcu_ctrlblk, rdp);
 	rcu_init_percpu_data(cpu, &rcu_bh_ctrlblk, bh_rdp);
 	tasklet_init(&per_cpu(rcu_tasklet, cpu), rcu_process_callbacks, 0UL);
@@ -599,6 +684,7 @@
 {
 	struct rcu_synchronize *rcu;
 
+vg_check_rcu_head(head, 11);
 	rcu = container_of(head, struct rcu_synchronize, head);
 	complete(&rcu->completion);
 }
@@ -618,6 +704,7 @@
 void synchronize_rcu(void)
 {
 	struct rcu_synchronize rcu;
+	memset(&rcu, 0, sizeof(rcu));  // 2007-12-18 jreiser
 
 	init_completion(&rcu.completion);
 	/* Will wake me after RCU finished */
diff -ur linux-2.6.22.5-old/kernel/signal.c linux-2.6.22.5/kernel/signal.c
--- linux-2.6.22.5-old/kernel/signal.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/kernel/signal.c	2007-12-16 13:24:57.000000000 -0800
@@ -181,7 +181,7 @@
 	if (override_rlimit ||
 	    atomic_read(&user->sigpending) <=
 			t->signal->rlim[RLIMIT_SIGPENDING].rlim_cur)
-		q = kmem_cache_alloc(sigqueue_cachep, flags);
+		q = kmem_cache_alloc(sigqueue_cachep, flags, sizeof(*q));
 	if (unlikely(q == NULL)) {
 		atomic_dec(&user->sigpending);
 	} else {
@@ -655,7 +655,6 @@
 {
 	struct sigqueue * q = NULL;
 	int ret = 0;
-
 	/*
 	 * Deliver the signal to listening signalfds. This must be called
 	 * with the sighand lock held.
@@ -744,6 +743,8 @@
 	return ret;
 }
 
+#include "valgrind.h"
+
 /*
  * Force a signal that the process can't ignore: if necessary
  * we unblock the signal and change any SIG_IGN to SIG_DFL.
@@ -761,6 +762,7 @@
 	int ret, blocked, ignored;
 	struct k_sigaction *action;
 
+VALGRIND_PRINTF_BACKTRACE("force_sig_info sig=%d  pit=%d\n", sig, t->pid);
 	spin_lock_irqsave(&t->sighand->siglock, flags);
 	action = &t->sighand->action[sig-1];
 	ignored = action->sa.sa_handler == SIG_IGN;
@@ -1140,6 +1142,8 @@
  * These are for backward compatibility with the rest of the kernel source.
  */
 
+#include "valgrind.h"
+
 /*
  * These two are the most common entry points.  They send a signal
  * just to the specific thread.
@@ -1150,6 +1154,7 @@
 	int ret;
 	unsigned long flags;
 
+VALGRIND_PRINTF_BACKTRACE("send_sig_info sig=%d  pid=%d\n", sig, p->pid);
 	/*
 	 * Make sure legacy kernel users don't send in bad values
 	 * (normal paths check this in check_kill_permission).
diff -ur linux-2.6.22.5-old/kernel/user.c linux-2.6.22.5/kernel/user.c
--- linux-2.6.22.5-old/kernel/user.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/kernel/user.c	2007-12-16 13:24:57.000000000 -0800
@@ -132,7 +132,7 @@
 	if (!up) {
 		struct user_struct *new;
 
-		new = kmem_cache_alloc(uid_cachep, GFP_KERNEL);
+		new = kmem_cache_alloc(uid_cachep, GFP_KERNEL, sizeof(*new));
 		if (!new)
 			return NULL;
 		new->uid = uid;
diff -ur linux-2.6.22.5-old/lib/idr.c linux-2.6.22.5/lib/idr.c
--- linux-2.6.22.5-old/lib/idr.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/lib/idr.c	2007-12-17 10:42:13.000000000 -0800
@@ -86,7 +86,12 @@
 {
 	while (idp->id_free_cnt < IDR_FREE_MAX) {
 		struct idr_layer *new;
-		new = kmem_cache_alloc(idr_layer_cache, gfp_mask);
+//printf("idr_pre_get idp=%p  size=%d  id_free_cnt=%d  max=%d\n",
+//   idp, sizeof(*new), idp->id_free_cnt, IDR_FREE_MAX);
+		new = kmem_cache_alloc(idr_layer_cache, gfp_mask, sizeof(*new));
+		/* idr_cache_ctor will have zeroed *new */
+		//VALGRIND_MAKE_MEM_DEFINED(new, sizeof(*new));  // XXX 2007-12-16
+//printf("idr_pre_get new=%p\n", new);
 		if (new == NULL)
 			return (0);
 		free_layer(idp, new);
@@ -448,11 +453,15 @@
 static void idr_cache_ctor(void * idr_layer, struct kmem_cache *idr_layer_cache,
 		unsigned long flags)
 {
+//printf("idr_cache_ctor idr_layer=%p  size=%d  pc=%p\n",
+//   idr_layer, sizeof(struct idr_layer), __builtin_return_address(0));
 	memset(idr_layer, 0, sizeof(struct idr_layer));
 }
 
 static  int init_id_cache(void)
 {
+//printf("init_id_cache idr_layer_cache=%p kmem_cache_create=%p  pc=%p\n",
+//   idr_layer_cache, &kmem_cache_create, __builtin_return_address(0));
 	if (!idr_layer_cache)
 		idr_layer_cache = kmem_cache_create("idr_layer_cache",
 			sizeof(struct idr_layer), 0, 0, idr_cache_ctor, NULL);
diff -ur linux-2.6.22.5-old/lib/radix-tree.c linux-2.6.22.5/lib/radix-tree.c
--- linux-2.6.22.5-old/lib/radix-tree.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/lib/radix-tree.c	2007-12-16 13:24:57.000000000 -0800
@@ -93,7 +93,7 @@
 	struct radix_tree_node *ret;
 	gfp_t gfp_mask = root_gfp_mask(root);
 
-	ret = kmem_cache_alloc(radix_tree_node_cachep, gfp_mask);
+	ret = kmem_cache_alloc(radix_tree_node_cachep, gfp_mask, sizeof(*ret));
 	if (ret == NULL && !(gfp_mask & __GFP_WAIT)) {
 		struct radix_tree_preload *rtp;
 
@@ -137,7 +137,7 @@
 	rtp = &__get_cpu_var(radix_tree_preloads);
 	while (rtp->nr < ARRAY_SIZE(rtp->nodes)) {
 		preempt_enable();
-		node = kmem_cache_alloc(radix_tree_node_cachep, gfp_mask);
+		node = kmem_cache_alloc(radix_tree_node_cachep, gfp_mask, sizeof(*node));
 		if (node == NULL)
 			goto out;
 		preempt_disable();
diff -ur linux-2.6.22.5-old/mm/filemap.c linux-2.6.22.5/mm/filemap.c
--- linux-2.6.22.5-old/mm/filemap.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/mm/filemap.c	2007-12-12 09:58:12.000000000 -0800
@@ -443,6 +443,7 @@
 		write_lock_irq(&mapping->tree_lock);
 		error = radix_tree_insert(&mapping->page_tree, offset, page);
 		if (!error) {
+			VALGRIND_MAKE_MEM_DEFINED(page, sizeof(*page));
 			page_cache_get(page);
 			SetPageLocked(page);
 			page->mapping = mapping;
@@ -675,6 +676,7 @@
 			if (!cached_page)
 				return NULL;
 		}
+		VALGRIND_MAKE_MEM_DEFINED(cached_page, sizeof(*cached_page));
 		err = add_to_page_cache_lru(cached_page, mapping,
 					index, gfp_mask);
 		if (!err) {
@@ -1745,6 +1747,7 @@
 	if (!page) {
 		if (!cached_page) {
 			cached_page = page_cache_alloc_cold(mapping);
+			VALGRIND_MAKE_MEM_DEFINED(cached_page, sizeof(*cached_page));  // XXX 2007-12-11 jreiser
 			if (!cached_page)
 				return ERR_PTR(-ENOMEM);
 		}
diff -ur linux-2.6.22.5-old/mm/mempolicy.c linux-2.6.22.5/mm/mempolicy.c
--- linux-2.6.22.5-old/mm/mempolicy.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/mm/mempolicy.c	2007-12-16 13:24:54.000000000 -0800
@@ -178,7 +178,7 @@
 	PDprintk("setting mode %d nodes[0] %lx\n", mode, nodes_addr(*nodes)[0]);
 	if (mode == MPOL_DEFAULT)
 		return NULL;
-	policy = kmem_cache_alloc(policy_cache, GFP_KERNEL);
+	policy = kmem_cache_alloc(policy_cache, GFP_KERNEL, sizeof(*policy));
 	if (!policy)
 		return ERR_PTR(-ENOMEM);
 	atomic_set(&policy->refcnt, 1);
@@ -1314,7 +1314,7 @@
 /* Slow path of a mempolicy copy */
 struct mempolicy *__mpol_copy(struct mempolicy *old)
 {
-	struct mempolicy *new = kmem_cache_alloc(policy_cache, GFP_KERNEL);
+	struct mempolicy *new = kmem_cache_alloc(policy_cache, GFP_KERNEL, sizeof(**new));
 
 	if (!new)
 		return ERR_PTR(-ENOMEM);
@@ -1468,7 +1468,7 @@
 struct sp_node *
 sp_alloc(unsigned long start, unsigned long end, struct mempolicy *pol)
 {
-	struct sp_node *n = kmem_cache_alloc(sn_cache, GFP_KERNEL);
+	struct sp_node *n = kmem_cache_alloc(sn_cache, GFP_KERNEL, sizeof(**n));
 
 	if (!n)
 		return NULL;
diff -ur linux-2.6.22.5-old/mm/mempool.c linux-2.6.22.5/mm/mempool.c
--- linux-2.6.22.5-old/mm/mempool.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/mm/mempool.c	2007-12-16 14:06:45.000000000 -0800
@@ -284,7 +284,7 @@
 void *mempool_alloc_slab(gfp_t gfp_mask, void *pool_data)
 {
 	struct kmem_cache *mem = pool_data;
-	return kmem_cache_alloc(mem, gfp_mask);
+	return kmem_cache_alloc(mem, gfp_mask, 0);  // XXX 2007-12-16
 }
 EXPORT_SYMBOL(mempool_alloc_slab);
 
diff -ur linux-2.6.22.5-old/mm/mmap.c linux-2.6.22.5/mm/mmap.c
--- linux-2.6.22.5-old/mm/mmap.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/mm/mmap.c	2007-12-16 14:07:27.000000000 -0800
@@ -1072,7 +1072,7 @@
 	 * specific mapper. the address has already been validated, but
 	 * not unmapped, but the maps are removed from the list.
 	 */
-	vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
+	vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL, sizeof(*vma));
 	if (!vma) {
 		error = -ENOMEM;
 		goto unacct_error;
@@ -1739,7 +1739,7 @@
 	if (mm->map_count >= sysctl_max_map_count)
 		return -ENOMEM;
 
-	new = kmem_cache_alloc(vm_area_cachep, GFP_KERNEL);
+	new = kmem_cache_alloc(vm_area_cachep, GFP_KERNEL, sizeof(*new));
 	if (!new)
 		return -ENOMEM;
 
@@ -1940,7 +1940,7 @@
 	/*
 	 * create a vma struct for an anonymous mapping
 	 */
-	vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
+	vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL, sizeof(*vma));
 	if (!vma) {
 		vm_unacct_memory(len >> PAGE_SHIFT);
 		return -ENOMEM;
@@ -2063,7 +2063,7 @@
 		    vma_start < new_vma->vm_end)
 			*vmap = new_vma;
 	} else {
-		new_vma = kmem_cache_alloc(vm_area_cachep, GFP_KERNEL);
+		new_vma = kmem_cache_alloc(vm_area_cachep, GFP_KERNEL, sizeof(*new_vma));
 		if (new_vma) {
 			*new_vma = *vma;
 			pol = mpol_copy(vma_policy(vma));
@@ -2149,7 +2149,7 @@
 {
 	struct vm_area_struct *vma;
 
-	vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
+	vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL, sizeof(*vma));
 	if (unlikely(vma == NULL))
 		return -ENOMEM;
 
diff -ur linux-2.6.22.5-old/mm/page_alloc.c linux-2.6.22.5/mm/page_alloc.c
--- linux-2.6.22.5-old/mm/page_alloc.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/mm/page_alloc.c	2007-12-19 13:01:32.000000000 -0800
@@ -45,6 +45,7 @@
 #include <asm/tlbflush.h>
 #include <asm/div64.h>
 #include "internal.h"
+#include "valgrind.h"
 
 /*
  * MCD - HACK: Find somewhere to initialize this EARLY, or make this
@@ -411,6 +412,7 @@
 		struct page *buddy;
 
 		buddy = __page_find_buddy(page, page_idx, order);
+		VALGRIND_MAKE_MEM_DEFINED(buddy, sizeof(*buddy));
 		if (!page_is_buddy(page, buddy, order))
 			break;		/* Move the buddy up one level. */
 
@@ -430,6 +432,7 @@
 
 static inline int free_pages_check(struct page *page)
 {
+	VALGRIND_MAKE_MEM_DEFINED(page, sizeof(*page));
 	if (unlikely(page_mapcount(page) |
 		(page->mapping != NULL)  |
 		(page_count(page) != 0)  |
@@ -494,6 +497,7 @@
 	spin_lock(&zone->lock);
 	zone->all_unreclaimable = 0;
 	zone->pages_scanned = 0;
+	VALGRIND_MAKE_MEM_DEFINED(page, sizeof(*page)<<order);
 	__free_one_page(page, zone, order);
 	spin_unlock(&zone->lock);
 }
@@ -777,6 +781,7 @@
  */
 static void fastcall free_hot_cold_page(struct page *page, int cold)
 {
+	VALGRIND_MAKE_MEM_DEFINED(page, sizeof(*page));  // XXX 2007-12-13 jreiser
 	struct zone *zone = page_zone(page);
 	struct per_cpu_pages *pcp;
 	unsigned long flags;
@@ -859,11 +864,13 @@
 				goto failed;
 		}
 		page = list_entry(pcp->list.next, struct page, lru);
+		VALGRIND_MAKE_MEM_DEFINED(page, sizeof(*page));  // XXX 2007-1213 jreiser
 		list_del(&page->lru);
 		pcp->count--;
 	} else {
 		spin_lock_irqsave(&zone->lock, flags);
 		page = __rmqueue(zone, order);
+		VALGRIND_MAKE_MEM_DEFINED(page, sizeof(*page));  // XXX 2007-1213 jreiser
 		spin_unlock(&zone->lock);
 		if (!page)
 			goto failed;
@@ -1380,11 +1387,16 @@
  */
 fastcall unsigned long __get_free_pages(gfp_t gfp_mask, unsigned int order)
 {
+	void *rv;
 	struct page * page;
 	page = alloc_pages(gfp_mask, order);
 	if (!page)
 		return 0;
-	return (unsigned long) page_address(page);
+	rv = page_address(page);
+//printf("__get_free_pages %p\n", __builtin_return_address(0));
+	//VALGRIND_MALLOCLIKE_BLOCK(rv, PAGE_SIZE<<order, 0, 0);  // XXX 2007-12-19
+	VALGRIND_MAKE_MEM_UNDEFINED(rv, PAGE_SIZE<<order);  // XXX 2007-12-19
+	return (unsigned long) rv;
 }
 
 EXPORT_SYMBOL(__get_free_pages);
@@ -1400,8 +1412,11 @@
 	VM_BUG_ON((gfp_mask & __GFP_HIGHMEM) != 0);
 
 	page = alloc_pages(gfp_mask | __GFP_ZERO, 0);
-	if (page)
-		return (unsigned long) page_address(page);
+	if (page) {
+		void *const rv = page_address(page);
+		VALGRIND_MAKE_MEM_DEFINED(rv, PAGE_SIZE);
+		return (unsigned long) rv;
+	}
 	return 0;
 }
 
@@ -1417,6 +1432,7 @@
 
 fastcall void __free_pages(struct page *page, unsigned int order)
 {
+	VALGRIND_MAKE_MEM_DEFINED(page, sizeof(*page));  // XXX 2007-12-13 jreiser
 	if (put_page_testzero(page)) {
 		if (order == 0)
 			free_hot_page(page);
@@ -1432,6 +1448,7 @@
 	if (addr != 0) {
 		VM_BUG_ON(!virt_addr_valid((void *)addr));
 		__free_pages(virt_to_page((void *)addr), order);
+		//VALGRIND_FREELIKE_BLOCK(addr, 0);  // XXX 2007-12-19
 	}
 }
 
diff -ur linux-2.6.22.5-old/mm/shmem.c linux-2.6.22.5/mm/shmem.c
--- linux-2.6.22.5-old/mm/shmem.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/mm/shmem.c	2007-12-16 13:24:54.000000000 -0800
@@ -2339,7 +2339,7 @@
 static struct inode *shmem_alloc_inode(struct super_block *sb)
 {
 	struct shmem_inode_info *p;
-	p = (struct shmem_inode_info *)kmem_cache_alloc(shmem_inode_cachep, GFP_KERNEL);
+	p = (struct shmem_inode_info *)kmem_cache_alloc(shmem_inode_cachep, GFP_KERNEL, sizeof(*p));
 	if (!p)
 		return NULL;
 	return &p->vfs_inode;
diff -ur linux-2.6.22.5-old/mm/slab.c linux-2.6.22.5/mm/slab.c
--- linux-2.6.22.5-old/mm/slab.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/mm/slab.c	2007-12-20 18:30:10.000000000 -0800
@@ -115,6 +115,8 @@
 #include	<asm/tlbflush.h>
 #include	<asm/page.h>
 
+#include "memcheck.h"
+
 /*
  * DEBUG	- 1 for kmem_cache_create() to honour; SLAB_RED_ZONE & SLAB_POISON.
  *		  0 for faster, smaller code (especially in the critical paths).
@@ -362,15 +364,26 @@
 
 #define MAKE_LIST(cachep, listp, slab, nodeid)				\
 	do {								\
+		VALGRIND_MAKE_MEM_DEFINED(listp, 2*sizeof(struct list_head *));\
+		VALGRIND_MAKE_MEM_DEFINED(&(cachep->nodelists[nodeid]->slab), \
+			2*sizeof(struct list_head *));\
 		INIT_LIST_HEAD(listp);					\
+		VALGRIND_MAKE_MEM_DEFINED(&(&(cachep->nodelists[nodeid]->slab))->next->prev, sizeof(struct list_head *));\
+		VALGRIND_MAKE_MEM_DEFINED(&(&(cachep->nodelists[nodeid]->slab))->prev->next, sizeof(struct list_head *));\
 		list_splice(&(cachep->nodelists[nodeid]->slab), listp);	\
+		VALGRIND_MAKE_MEM_UNDEFINED(&(cachep->nodelists[nodeid]->slab), 2*sizeof(struct list_head *));                      \
+		VALGRIND_MAKE_MEM_UNDEFINED(listp, 2*sizeof(struct list_head *));                      \
 	} while (0)
 
 #define	MAKE_ALL_LISTS(cachep, ptr, nodeid)				\
 	do {								\
+	/*VALGRIND_PRINTF("MAL A\n");*/                                     \
 	MAKE_LIST((cachep), (&(ptr)->slabs_full), slabs_full, nodeid);	\
+	/*VALGRIND_PRINTF("MAL B\n");*/                                     \
 	MAKE_LIST((cachep), (&(ptr)->slabs_partial), slabs_partial, nodeid); \
+	/*VALGRIND_PRINTF("MAL C\n");*/                                     \
 	MAKE_LIST((cachep), (&(ptr)->slabs_free), slabs_free, nodeid);	\
+	/*VALGRIND_PRINTF("MAL D\n");*/                                     \
 	} while (0)
 
 /*
@@ -619,7 +632,11 @@
 static inline void *index_to_obj(struct kmem_cache *cache, struct slab *slab,
 				 unsigned int idx)
 {
-	return slab->s_mem + cache->buffer_size * idx;
+	void *s_mem;
+	VALGRIND_MAKE_MEM_DEFINED(&slab->s_mem, sizeof(slab->s_mem));
+	s_mem = slab->s_mem;
+	VALGRIND_MAKE_MEM_UNDEFINED(&slab->s_mem, sizeof(slab->s_mem));
+	return s_mem + cache->buffer_size * idx;
 }
 
 /*
@@ -631,7 +648,10 @@
 static inline unsigned int obj_to_index(const struct kmem_cache *cache,
 					const struct slab *slab, void *obj)
 {
-	u32 offset = (obj - slab->s_mem);
+	u32 offset;
+	VALGRIND_MAKE_MEM_DEFINED(&slab->s_mem, sizeof(slab->s_mem));
+	offset = (obj - slab->s_mem);
+	VALGRIND_MAKE_MEM_UNDEFINED(&slab->s_mem, sizeof(slab->s_mem));
 	return reciprocal_divide(offset, cache->reciprocal_buffer_size);
 }
 
@@ -1153,6 +1173,18 @@
 }
 #endif
 
+#define slab_list_for_each_entry(pos, head, member)                     \
+	for ((VALGRIND_MAKE_MEM_DEFINED(&(head)->next, sizeof(void *))), \
+	     pos = list_entry((head)->next, typeof(*pos), member),	\
+	     (VALGRIND_MAKE_MEM_UNDEFINED(&(head)->next, sizeof(void *)));                 \
+	                                                                \
+	     prefetch(pos->member.next), &pos->member != (head); 	\
+	                                                                \
+	     ({ void *const VmlB = &(pos->member.next);                \
+                VALGRIND_MAKE_MEM_DEFINED(VmlB, sizeof(void *)); \
+	        pos = list_entry(pos->member.next, typeof(*pos), member);\
+	        VALGRIND_MAKE_MEM_UNDEFINED(VmlB, sizeof(void *)); }))
+
 static int __cpuinit cpuup_callback(struct notifier_block *nfb,
 				    unsigned long action, void *hcpu)
 {
@@ -1175,7 +1207,7 @@
 		 * kmem_list3 and not this cpu's kmem_list3
 		 */
 
-		list_for_each_entry(cachep, &cache_chain, next) {
+		slab_list_for_each_entry(cachep, &cache_chain, next) {
 			/*
 			 * Set up the size64 kmemlist for cpu before we can
 			 * begin anything. Make sure some other cpu on this
@@ -1208,7 +1240,7 @@
 		 * Now we can go ahead with allocating the shared arrays and
 		 * array caches
 		 */
-		list_for_each_entry(cachep, &cache_chain, next) {
+		slab_list_for_each_entry(cachep, &cache_chain, next) {
 			struct array_cache *nc;
 			struct array_cache *shared = NULL;
 			struct array_cache **alien = NULL;
@@ -1288,7 +1320,7 @@
 #endif
 	case CPU_UP_CANCELED:
 	case CPU_UP_CANCELED_FROZEN:
-		list_for_each_entry(cachep, &cache_chain, next) {
+		slab_list_for_each_entry(cachep, &cache_chain, next) {
 			struct array_cache *nc;
 			struct array_cache *shared;
 			struct array_cache **alien;
@@ -1340,7 +1372,7 @@
 		 * the respective cache's slabs,  now we can go ahead and
 		 * shrink each nodelist to its limit.
 		 */
-		list_for_each_entry(cachep, &cache_chain, next) {
+		slab_list_for_each_entry(cachep, &cache_chain, next) {
 			l3 = cachep->nodelists[node];
 			if (!l3)
 				continue;
@@ -1372,7 +1404,9 @@
 	BUG_ON(!ptr);
 
 	local_irq_disable();
+	VALGRIND_MAKE_MEM_DEFINED(list, sizeof(*list));
 	memcpy(ptr, list, sizeof(struct kmem_list3));
+	VALGRIND_MAKE_MEM_UNDEFINED(list, sizeof(*list));
 	/*
 	 * Do not assume that spinlocks can be initialized via memcpy:
 	 */
@@ -1383,6 +1417,57 @@
 	local_irq_enable();
 }
 
+static int slab_list_empty(const struct list_head *head)
+{
+	int rv;
+	struct list_head const **const head_next = (struct list_head const **)&head->next;
+	VALGRIND_MAKE_MEM_DEFINED(head_next, sizeof(*head_next));
+	rv = list_empty(head);
+	VALGRIND_MAKE_MEM_UNDEFINED(head_next, sizeof(*head_next));
+	return rv;
+}
+
+static void slab_list_add(struct list_head *new, struct list_head *head)
+{
+	struct list_head **const head_next = &head->next;
+	VALGRIND_MAKE_MEM_DEFINED(head_next, sizeof(*head_next));
+	struct list_head **const next_prev = &head->next->prev;
+	VALGRIND_MAKE_MEM_DEFINED(next_prev, sizeof(*next_prev));
+
+	VALGRIND_MAKE_MEM_DEFINED(new, 2*sizeof(struct list_head *));
+	list_add(new, head);
+	VALGRIND_MAKE_MEM_UNDEFINED(new, 2*sizeof(struct list_head *));
+
+	VALGRIND_MAKE_MEM_UNDEFINED(next_prev, sizeof(*next_prev));
+	VALGRIND_MAKE_MEM_UNDEFINED(head_next, sizeof(*head_next));
+}
+
+static void slab_list_add_tail(struct list_head *new, struct list_head *head)
+{
+	struct list_head **const head_prev = &head->prev;
+	VALGRIND_MAKE_MEM_DEFINED(head_prev, sizeof(*head_prev));
+	struct list_head **const prev_next = &head->prev->next;
+	VALGRIND_MAKE_MEM_DEFINED(prev_next, sizeof(*prev_next));
+
+	VALGRIND_MAKE_MEM_DEFINED(new, 2*sizeof(struct list_head *));
+	list_add_tail(new, head);
+	VALGRIND_MAKE_MEM_UNDEFINED(new, 2*sizeof(struct list_head *));
+
+	VALGRIND_MAKE_MEM_UNDEFINED(prev_next, sizeof(*prev_next));
+	VALGRIND_MAKE_MEM_UNDEFINED(head_prev, sizeof(*head_prev));
+}
+
+static void slab_list_del(struct list_head *entry)
+{
+	struct list_head **const next_prev = &entry->next->prev;
+	struct list_head **const prev_next = &entry->prev->next;
+	VALGRIND_MAKE_MEM_DEFINED(next_prev, sizeof(*next_prev));
+	VALGRIND_MAKE_MEM_DEFINED(prev_next, sizeof(*prev_next));
+	list_del(entry);
+	VALGRIND_MAKE_MEM_UNDEFINED(next_prev, sizeof(*next_prev));
+	VALGRIND_MAKE_MEM_UNDEFINED(prev_next, sizeof(*next_prev));
+}
+
 /*
  * Initialisation.  Called after the page allocator have been initialised and
  * before smp_init().
@@ -1436,7 +1521,7 @@
 
 	/* 1) create the cache_cache */
 	INIT_LIST_HEAD(&cache_chain);
-	list_add(&cache_cache.next, &cache_chain);
+	slab_list_add(&cache_cache.next, &cache_chain);
 	cache_cache.colour_off = cache_line_size();
 	cache_cache.array[smp_processor_id()] = &initarray_cache.cache;
 	cache_cache.nodelists[node] = &initkmem_list3[CACHE_CACHE];
@@ -1556,28 +1641,34 @@
 		local_irq_enable();
 	}
 	/* 5) Replace the bootstrap kmem_list3's */
+//VALGRIND_PRINTF("kmem_cache_init A\n");
 	{
 		int nid;
 
 		/* Replace the static kmem_list3 structures for the boot cpu */
 		init_list(&cache_cache, &initkmem_list3[CACHE_CACHE], node);
+//VALGRIND_PRINTF("kmem_cache_init B\n");
 
 		for_each_online_node(nid) {
+//VALGRIND_PRINTF("kmem_cache_init C\n");
 			init_list(malloc_sizes[INDEX_AC].cs_cachep,
 				  &initkmem_list3[SIZE_AC + nid], nid);
 
 			if (INDEX_AC != INDEX_L3) {
+//VALGRIND_PRINTF("kmem_cache_init D\n");
 				init_list(malloc_sizes[INDEX_L3].cs_cachep,
 					  &initkmem_list3[SIZE_L3 + nid], nid);
 			}
 		}
+//VALGRIND_PRINTF("kmem_cache_init E\n");
 	}
 
 	/* 6) resize the head arrays to their final sizes */
 	{
 		struct kmem_cache *cachep;
 		mutex_lock(&cache_chain_mutex);
-		list_for_each_entry(cachep, &cache_chain, next)
+//VALGRIND_PRINTF("kmem_cache_init F\n");
+		slab_list_for_each_entry(cachep, &cache_chain, next)
 			if (enable_cpucache(cachep))
 				BUG();
 		mutex_unlock(&cache_chain_mutex);
@@ -1654,11 +1745,14 @@
 	return page_address(page);
 }
 
+__u32 vg_page_word0;
 /*
  * Interface to system's page release.
  */
 static void kmem_freepages(struct kmem_cache *cachep, void *addr)
 {
+	VALGRIND_MAKE_MEM_DEFINED(&cachep, sizeof(cachep));  // XXX 2007-12-12 jreiser
+	VALGRIND_MAKE_MEM_DEFINED(cachep, sizeof(*cachep));  // XXX 2007-12-12 jreiser
 	unsigned long i = (1 << cachep->gfporder);
 	struct page *page = virt_to_page(addr);
 	const unsigned long nr_freed = i;
@@ -1670,6 +1764,8 @@
 		sub_zone_page_state(page_zone(page),
 				NR_SLAB_UNRECLAIMABLE, nr_freed);
 	while (i--) {
+		VALGRIND_GET_VBITS(page, &vg_page_word0, sizeof(vg_page_word0));
+		VALGRIND_MAKE_MEM_DEFINED(page, sizeof(*page));  // XXX 2007-12-13 jreiser
 		BUG_ON(!PageSlab(page));
 		__ClearPageSlab(page);
 		page++;
@@ -1679,11 +1775,14 @@
 	free_pages((unsigned long)addr, cachep->gfporder);
 }
 
+__u32 vg_word1;
+
 static void kmem_rcu_free(struct rcu_head *head)
 {
 	struct slab_rcu *slab_rcu = (struct slab_rcu *)head;
 	struct kmem_cache *cachep = slab_rcu->cachep;
 
+	VALGRIND_GET_VBITS(&slab_rcu->addr, &vg_word1, sizeof(slab_rcu->addr));
 	kmem_freepages(cachep, slab_rcu->addr);
 	if (OFF_SLAB(cachep))
 		kmem_cache_free(cachep->slabp_cache, slab_rcu);
@@ -1730,8 +1829,12 @@
 	int size = obj_size(cachep);
 	addr = &((char *)addr)[obj_offset(cachep)];
 
+	VALGRIND_MAKE_MEM_DEFINED(addr, size);
 	memset(addr, val, size);
 	*(unsigned char *)(addr + size - 1) = POISON_END;
+	if (POISON_FREE==val) {
+		VALGRIND_MAKE_MEM_NOACCESS(addr, size);
+	}
 }
 
 static void dump_line(char *data, int offset, int limit)
@@ -1805,6 +1908,7 @@
 
 	realobj = (char *)objp + obj_offset(cachep);
 	size = obj_size(cachep);
+	VALGRIND_MAKE_MEM_DEFINED(realobj, size);
 
 	for (i = 0; i < size; i++) {
 		char exp = POISON_FREE;
@@ -1887,12 +1991,20 @@
 #endif
 		}
 		if (cachep->flags & SLAB_RED_ZONE) {
-			if (*dbg_redzone1(cachep, objp) != RED_INACTIVE)
+			unsigned long long *p;
+			p= dbg_redzone1(cachep, objp);
+			VALGRIND_MAKE_MEM_DEFINED(p, sizeof(*p));
+			if (*p != RED_INACTIVE)
 				slab_error(cachep, "start of a freed object "
 					   "was overwritten");
-			if (*dbg_redzone2(cachep, objp) != RED_INACTIVE)
+			VALGRIND_MAKE_MEM_UNDEFINED(p, sizeof(*p));
+
+			p= dbg_redzone2(cachep, objp);
+			VALGRIND_MAKE_MEM_DEFINED(p, sizeof(*p));
+			if (*p != RED_INACTIVE)
 				slab_error(cachep, "end of a freed object "
 					   "was overwritten");
+			VALGRIND_MAKE_MEM_UNDEFINED(p, sizeof(*p));
 		}
 	}
 }
@@ -1920,6 +2032,7 @@
 		struct slab_rcu *slab_rcu;
 
 		slab_rcu = (struct slab_rcu *)slabp;
+		VALGRIND_MAKE_MEM_DEFINED(slab_rcu, sizeof(*slab_rcu));
 		slab_rcu->cachep = cachep;
 		slab_rcu->addr = addr;
 		call_rcu(&slab_rcu->head, kmem_rcu_free);
@@ -2145,7 +2258,9 @@
 	 */
 	mutex_lock(&cache_chain_mutex);
 
-	list_for_each_entry(pc, &cache_chain, next) {
+	VALGRIND_MAKE_MEM_DEFINED(&cache_chain, sizeof(cache_chain));
+	VALGRIND_MAKE_MEM_DEFINED(cache_chain.next, sizeof(struct list_head *));
+	slab_list_for_each_entry(pc, &cache_chain, next) {
 		char tmp;
 		int res;
 
@@ -2253,7 +2368,7 @@
 	align = ralign;
 
 	/* Get cache's description obj. */
-	cachep = kmem_cache_zalloc(&cache_cache, GFP_KERNEL);
+	cachep = kmem_cache_zalloc(&cache_cache, GFP_KERNEL, sizeof(*cachep));
 	if (!cachep)
 		goto oops;
 
@@ -2363,7 +2478,7 @@
 	}
 
 	/* cache setup completed, link it into the list */
-	list_add(&cachep->next, &cache_chain);
+	slab_list_add(&cachep->next, &cache_chain);
 oops:
 	if (!cachep && (flags & SLAB_PANIC))
 		panic("kmem_cache_create(): failed to create slab `%s'\n",
@@ -2452,15 +2567,16 @@
  * Returns the actual number of slabs released.
  */
 static int drain_freelist(struct kmem_cache *cache,
-			struct kmem_list3 *l3, int tofree)
+			struct kmem_list3 *const l3, int tofree)
 {
 	struct list_head *p;
 	int nr_freed;
 	struct slab *slabp;
 
 	nr_freed = 0;
-	while (nr_freed < tofree && !list_empty(&l3->slabs_free)) {
-
+	VALGRIND_MAKE_MEM_DEFINED(l3, sizeof(*l3));
+	while (nr_freed < tofree && !slab_list_empty(&l3->slabs_free)) {
+		VALGRIND_MAKE_MEM_DEFINED(l3, sizeof(*l3));
 		spin_lock_irq(&l3->list_lock);
 		p = l3->slabs_free.prev;
 		if (p == &l3->slabs_free) {
@@ -2469,10 +2585,11 @@
 		}
 
 		slabp = list_entry(p, struct slab, list);
+		VALGRIND_MAKE_MEM_DEFINED(slabp, sizeof(*slabp));
 #if DEBUG
 		BUG_ON(slabp->inuse);
 #endif
-		list_del(&slabp->list);
+		slab_list_del(&slabp->list);
 		/*
 		 * Safe to drop the lock. The slab is no longer linked
 		 * to the cache.
@@ -2481,8 +2598,10 @@
 		spin_unlock_irq(&l3->list_lock);
 		slab_destroy(cache, slabp);
 		nr_freed++;
+		//VALGRIND_MAKE_MEM_UNDEFINED(slabp, sizeof(*slabp));  // XXX 2007-12-18 jreiser ???
 	}
 out:
+	VALGRIND_MAKE_MEM_UNDEFINED(l3, sizeof(*l3));
 	return nr_freed;
 }
 
@@ -2502,8 +2621,8 @@
 
 		drain_freelist(cachep, l3, l3->free_objects);
 
-		ret += !list_empty(&l3->slabs_full) ||
-			!list_empty(&l3->slabs_partial);
+		ret += !slab_list_empty(&l3->slabs_full) ||
+			!slab_list_empty(&l3->slabs_partial);
 	}
 	return (ret ? 1 : 0);
 }
@@ -2552,10 +2671,10 @@
 	/*
 	 * the chain is never empty, cache_cache is never destroyed
 	 */
-	list_del(&cachep->next);
+	slab_list_del(&cachep->next);
 	if (__cache_shrink(cachep)) {
 		slab_error(cachep, "Can't free all objects");
-		list_add(&cachep->next, &cache_chain);
+		slab_list_add(&cachep->next, &cache_chain);
 		mutex_unlock(&cache_chain_mutex);
 		return;
 	}
@@ -2588,12 +2707,15 @@
 	if (OFF_SLAB(cachep)) {
 		/* Slab management obj is off-slab. */
 		slabp = kmem_cache_alloc_node(cachep->slabp_cache,
-					      local_flags & ~GFP_THISNODE, nodeid);
+			local_flags & ~GFP_THISNODE, nodeid, sizeof(*slabp));
 		if (!slabp)
 			return NULL;
 	} else {
 		slabp = objp + colour_off;
 		colour_off += cachep->slab_size;
+//printf("alloc_slabmgmt  slabp=%p  pc=%p\n", slabp, __builtin_return_address(0));
+		//VALGRIND_MALLOCLIKE_BLOCK(slabp, sizeof(*slabp), 0, 0);  // XXX 2007-12-19
+		VALGRIND_MAKE_MEM_DEFINED(slabp, sizeof(*slabp));  // XXX 2007-12-19
 	}
 	slabp->inuse = 0;
 	slabp->colouroff = colour_off;
@@ -2618,41 +2740,73 @@
 		/* need to poison the objs? */
 		if (cachep->flags & SLAB_POISON)
 			poison_obj(cachep, objp, POISON_FREE);
-		if (cachep->flags & SLAB_STORE_USER)
-			*dbg_userword(cachep, objp) = NULL;
+		if (cachep->flags & SLAB_STORE_USER) {
+			void **const p = dbg_userword(cachep, objp);
+			VALGRIND_MAKE_MEM_DEFINED(p, sizeof(*p));
+			*p = NULL;
+			VALGRIND_MAKE_MEM_UNDEFINED(p, sizeof(*p));
+		}
 
 		if (cachep->flags & SLAB_RED_ZONE) {
-			*dbg_redzone1(cachep, objp) = RED_INACTIVE;
-			*dbg_redzone2(cachep, objp) = RED_INACTIVE;
+			unsigned long long *p;
+
+			p = dbg_redzone1(cachep, objp);
+			VALGRIND_MAKE_MEM_DEFINED(p, sizeof(*p));
+			*p = RED_INACTIVE;
+
+			p = dbg_redzone2(cachep, objp);
+			VALGRIND_MAKE_MEM_DEFINED(p, sizeof(*p));
+			*p = RED_INACTIVE;
 		}
 		/*
 		 * Constructors are not allowed to allocate memory from the same
 		 * cache which they are a constructor for.  Otherwise, deadlock.
 		 * They must also be threaded.
 		 */
-		if (cachep->ctor && !(cachep->flags & SLAB_POISON))
+		if (cachep->ctor && !(cachep->flags & SLAB_POISON)) {
+//printf("cache_init_objs ctor=%p  arg=%p\n", cachep->ctor, objp + obj_offset(cachep));
 			cachep->ctor(objp + obj_offset(cachep), cachep,
 				     0);
+		}
 
 		if (cachep->flags & SLAB_RED_ZONE) {
-			if (*dbg_redzone2(cachep, objp) != RED_INACTIVE)
+			unsigned long long *p;
+
+			p = dbg_redzone2(cachep, objp);
+			if (*p != RED_INACTIVE)
 				slab_error(cachep, "constructor overwrote the"
 					   " end of an object");
-			if (*dbg_redzone1(cachep, objp) != RED_INACTIVE)
+			VALGRIND_MAKE_MEM_UNDEFINED(p, sizeof(*p));
+
+			p = dbg_redzone1(cachep, objp);
+			if (*p != RED_INACTIVE)
 				slab_error(cachep, "constructor overwrote the"
 					   " start of an object");
+			VALGRIND_MAKE_MEM_UNDEFINED(p, sizeof(*p));
 		}
 		if ((cachep->buffer_size % PAGE_SIZE) == 0 &&
 			    OFF_SLAB(cachep) && cachep->flags & SLAB_POISON)
 			kernel_map_pages(virt_to_page(objp),
 					 cachep->buffer_size / PAGE_SIZE, 0);
 #else
-		if (cachep->ctor)
+		if (cachep->ctor) {
+//printf("cache_init_objs ctor=%p  arg=%p\n", cachep->ctor, objp);
 			cachep->ctor(objp, cachep, 0);
+		}
 #endif
-		slab_bufctl(slabp)[i] = i + 1;
+		{
+			kmem_bufctl_t *const p = &slab_bufctl(slabp)[i];
+			VALGRIND_MAKE_MEM_DEFINED(p, sizeof(*p));
+			*p = i + 1;
+			VALGRIND_MAKE_MEM_UNDEFINED(p, sizeof(*p));
+		}
+	}
+	{
+		kmem_bufctl_t *const p = &slab_bufctl(slabp)[i - 1];
+		VALGRIND_MAKE_MEM_DEFINED(p, sizeof(*p));
+		*p = BUFCTL_END;
+		VALGRIND_MAKE_MEM_UNDEFINED(p, sizeof(*p));
 	}
-	slab_bufctl(slabp)[i - 1] = BUFCTL_END;
 	slabp->free = 0;
 }
 
@@ -2670,14 +2824,18 @@
 				int nodeid)
 {
 	void *objp = index_to_obj(cachep, slabp, slabp->free);
-	kmem_bufctl_t next;
+	kmem_bufctl_t next, *const p = &slab_bufctl(slabp)[slabp->free];
 
 	slabp->inuse++;
-	next = slab_bufctl(slabp)[slabp->free];
+	VALGRIND_MAKE_MEM_DEFINED(p, sizeof(*p));
+	next = *p;
 #if DEBUG
-	slab_bufctl(slabp)[slabp->free] = BUFCTL_FREE;
+	*p = BUFCTL_FREE;
+
 	WARN_ON(slabp->nodeid != nodeid);
 #endif
+	VALGRIND_MAKE_MEM_UNDEFINED(p, sizeof(*p));
+
 	slabp->free = next;
 
 	return objp;
@@ -2688,6 +2846,7 @@
 {
 	unsigned int objnr = obj_to_index(cachep, slabp, objp);
 
+	VALGRIND_MAKE_MEM_DEFINED(&slab_bufctl(slabp)[objnr], sizeof(kmem_bufctl_t *));
 #if DEBUG
 	/* Verify that the slab belongs to the intended node */
 	WARN_ON(slabp->nodeid != nodeid);
@@ -2699,6 +2858,7 @@
 	}
 #endif
 	slab_bufctl(slabp)[objnr] = slabp->free;
+	VALGRIND_MAKE_MEM_UNDEFINED(&slab_bufctl(slabp)[objnr], sizeof(kmem_bufctl_t *));
 	slabp->free = objnr;
 	slabp->inuse--;
 }
@@ -2715,6 +2875,7 @@
 	struct page *page;
 
 	page = virt_to_page(addr);
+	VALGRIND_MAKE_MEM_DEFINED(page, sizeof(*page));  // XXX 2007-12-11 jreiser
 
 	nr_pages = 1;
 	if (likely(!PageCompound(page)))
@@ -2749,6 +2910,7 @@
 	/* Take the l3 list lock to change the colour_next on this node */
 	check_irq_off();
 	l3 = cachep->nodelists[nodeid];
+	VALGRIND_MAKE_MEM_DEFINED(l3, sizeof(*l3));
 	spin_lock(&l3->list_lock);
 
 	/* Get colour for the slab, and cal the next value. */
@@ -2797,10 +2959,11 @@
 	spin_lock(&l3->list_lock);
 
 	/* Make slab active. */
-	list_add_tail(&slabp->list, &(l3->slabs_free));
+	slab_list_add_tail(&slabp->list, &(l3->slabs_free));
 	STATS_INC_GROWN(cachep);
 	l3->free_objects += cachep->num;
 	spin_unlock(&l3->list_lock);
+	VALGRIND_MAKE_MEM_UNDEFINED(l3, sizeof(*l3));
 	return 1;
 opps1:
 	kmem_freepages(cachep, objp);
@@ -2862,12 +3025,23 @@
 	slabp = page_get_slab(page);
 
 	if (cachep->flags & SLAB_RED_ZONE) {
+		unsigned long long *const p1 = dbg_redzone1(cachep, objp);
+		unsigned long long *const p2 = dbg_redzone2(cachep, objp);
+
+		VALGRIND_MAKE_MEM_DEFINED(p1, sizeof(*p1));
+		VALGRIND_MAKE_MEM_DEFINED(p2, sizeof(*p2));
 		verify_redzone_free(cachep, objp);
-		*dbg_redzone1(cachep, objp) = RED_INACTIVE;
-		*dbg_redzone2(cachep, objp) = RED_INACTIVE;
+		*p1 = RED_INACTIVE;
+		*p2 = RED_INACTIVE;
+		VALGRIND_MAKE_MEM_UNDEFINED(p1, sizeof(*p1));
+		VALGRIND_MAKE_MEM_UNDEFINED(p2, sizeof(*p2));
+	}
+	if (cachep->flags & SLAB_STORE_USER) {
+		void **const p = dbg_userword(cachep, objp);
+		VALGRIND_MAKE_MEM_DEFINED(p, sizeof(*p));
+		*p = caller;
+		VALGRIND_MAKE_MEM_UNDEFINED(p, sizeof(*p));
 	}
-	if (cachep->flags & SLAB_STORE_USER)
-		*dbg_userword(cachep, objp) = caller;
 
 	objnr = obj_to_index(cachep, slabp, objp);
 
@@ -2899,10 +3073,14 @@
 	int entries = 0;
 
 	/* Check slab's freelist to see if this obj is there. */
-	for (i = slabp->free; i != BUFCTL_END; i = slab_bufctl(slabp)[i]) {
+	for (i = slabp->free; i != BUFCTL_END; ) {
+		kmem_bufctl_t *const p = &slab_bufctl(slabp)[i];
 		entries++;
 		if (entries > cachep->num || i >= cachep->num)
 			goto bad;
+		VALGRIND_MAKE_MEM_DEFINED(p, sizeof(*p));
+		i = *p;
+		VALGRIND_MAKE_MEM_UNDEFINED(p, sizeof(*p));
 	}
 	if (entries != cachep->num - slabp->inuse) {
 bad:
@@ -2948,6 +3126,7 @@
 		batchcount = BATCHREFILL_LIMIT;
 	}
 	l3 = cachep->nodelists[node];
+	VALGRIND_MAKE_MEM_DEFINED(l3, sizeof(*l3));
 
 	BUG_ON(ac->avail > 0 || !l3);
 	spin_lock(&l3->list_lock);
@@ -2960,15 +3139,18 @@
 		struct list_head *entry;
 		struct slab *slabp;
 		/* Get slab alloc is to come from. */
+		VALGRIND_MAKE_MEM_DEFINED(&l3->slabs_partial.next, sizeof(entry));
 		entry = l3->slabs_partial.next;
 		if (entry == &l3->slabs_partial) {
 			l3->free_touched = 1;
+			VALGRIND_MAKE_MEM_DEFINED(&l3->slabs_free.next, sizeof(entry));
 			entry = l3->slabs_free.next;
 			if (entry == &l3->slabs_free)
 				goto must_grow;
 		}
 
 		slabp = list_entry(entry, struct slab, list);
+		VALGRIND_MAKE_MEM_DEFINED(slabp, sizeof(*slabp));
 		check_slabp(cachep, slabp);
 		check_spinlock_acquired(cachep);
 
@@ -2990,17 +3172,21 @@
 		check_slabp(cachep, slabp);
 
 		/* move slabp to correct slabp list: */
-		list_del(&slabp->list);
-		if (slabp->free == BUFCTL_END)
-			list_add(&slabp->list, &l3->slabs_full);
-		else
-			list_add(&slabp->list, &l3->slabs_partial);
+		slab_list_del(&slabp->list);
+		if (slabp->free == BUFCTL_END) {
+			slab_list_add(&slabp->list, &l3->slabs_full);
+		}
+		else {
+			slab_list_add(&slabp->list, &l3->slabs_partial);
+		}
+		VALGRIND_MAKE_MEM_UNDEFINED(slabp, sizeof(*slabp));
 	}
 
 must_grow:
 	l3->free_objects -= ac->avail;
 alloc_done:
 	spin_unlock(&l3->list_lock);
+	VALGRIND_MAKE_MEM_UNDEFINED(l3, sizeof(*l3));
 
 	if (unlikely(!ac->avail)) {
 		int x;
@@ -3045,21 +3231,29 @@
 #endif
 		poison_obj(cachep, objp, POISON_INUSE);
 	}
-	if (cachep->flags & SLAB_STORE_USER)
-		*dbg_userword(cachep, objp) = caller;
+	if (cachep->flags & SLAB_STORE_USER) {
+		void **const p = dbg_userword(cachep, objp);
+		VALGRIND_MAKE_MEM_DEFINED(p, sizeof(*p));
+		*p = caller;
+	}
 
 	if (cachep->flags & SLAB_RED_ZONE) {
-		if (*dbg_redzone1(cachep, objp) != RED_INACTIVE ||
-				*dbg_redzone2(cachep, objp) != RED_INACTIVE) {
+		unsigned long long *const p1 = dbg_redzone1(cachep, objp);
+		unsigned long long *const p2 = dbg_redzone2(cachep, objp);
+		
+		VALGRIND_MAKE_MEM_DEFINED(p1, sizeof(*p1));
+		VALGRIND_MAKE_MEM_DEFINED(p2, sizeof(*p2));
+		if (*p1 != RED_INACTIVE || *p2 != RED_INACTIVE) {
 			slab_error(cachep, "double free, or memory outside"
 						" object was overwritten");
 			printk(KERN_ERR
 				"%p: redzone 1:0x%llx, redzone 2:0x%llx\n",
-				objp, *dbg_redzone1(cachep, objp),
-				*dbg_redzone2(cachep, objp));
+				objp, *p1, *p2);
 		}
-		*dbg_redzone1(cachep, objp) = RED_ACTIVE;
-		*dbg_redzone2(cachep, objp) = RED_ACTIVE;
+		*p1 = RED_ACTIVE;
+		*p2 = RED_ACTIVE;
+		VALGRIND_MAKE_MEM_UNDEFINED(p1, sizeof(*p1));
+		VALGRIND_MAKE_MEM_UNDEFINED(p2, sizeof(*p2));
 	}
 #ifdef CONFIG_DEBUG_SLAB_LEAK
 	{
@@ -3072,8 +3266,6 @@
 	}
 #endif
 	objp += obj_offset(cachep);
-	if (cachep->ctor && cachep->flags & SLAB_POISON)
-		cachep->ctor(objp, cachep, 0);
 #if ARCH_SLAB_MINALIGN
 	if ((u32)objp & (ARCH_SLAB_MINALIGN-1)) {
 		printk(KERN_ERR "0x%p: not aligned to ARCH_SLAB_MINALIGN=%d\n",
@@ -3316,12 +3508,12 @@
 	check_slabp(cachep, slabp);
 	l3->free_objects--;
 	/* move slabp to correct slabp list: */
-	list_del(&slabp->list);
+	slab_list_del(&slabp->list);
 
 	if (slabp->free == BUFCTL_END)
-		list_add(&slabp->list, &l3->slabs_full);
+		slab_list_add(&slabp->list, &l3->slabs_full);
 	else
-		list_add(&slabp->list, &l3->slabs_partial);
+		slab_list_add(&slabp->list, &l3->slabs_partial);
 
 	spin_unlock(&l3->list_lock);
 	goto done;
@@ -3352,7 +3544,7 @@
  */
 static __always_inline void *
 __cache_alloc_node(struct kmem_cache *cachep, gfp_t flags, int nodeid,
-		   void *caller)
+		   void *caller, size_t size)
 {
 	unsigned long save_flags;
 	void *ptr;
@@ -3388,6 +3580,12 @@
   out:
 	local_irq_restore(save_flags);
 	ptr = cache_alloc_debugcheck_after(cachep, flags, ptr, caller);
+//printf("__cache_alloc_node %p  size=%d  pc=%p\n", ptr, size, __builtin_return_address(0));
+	VALGRIND_MALLOCLIKE_BLOCK(ptr, size, 0, 0);
+	if (cachep->ctor /*&& cachep->flags & SLAB_POISON*/) {
+//printf("__cache_alloc_node ctor=%p  arg=%p  caller=%p\n", cachep->ctor, objp, caller);
+		cachep->ctor(objp, cachep, 0);
+	}
 
 	return ptr;
 }
@@ -3425,7 +3623,7 @@
 #endif /* CONFIG_NUMA */
 
 static __always_inline void *
-__cache_alloc(struct kmem_cache *cachep, gfp_t flags, void *caller)
+__cache_alloc(struct kmem_cache *cachep, gfp_t flags, void *caller, size_t size)
 {
 	unsigned long save_flags;
 	void *objp;
@@ -3438,6 +3636,13 @@
 	objp = __do_cache_alloc(cachep, flags);
 	local_irq_restore(save_flags);
 	objp = cache_alloc_debugcheck_after(cachep, flags, objp, caller);
+//printf("__cache_alloc %p  size=%d  pc=%p\n",
+//   objp, size, (caller ? caller : __builtin_return_address(0)));
+	VALGRIND_MALLOCLIKE_BLOCK(objp, size, 0, 0);
+	if (cachep->ctor /*&& cachep->flags & SLAB_POISON*/) {
+//printf("__cache_alloc ctor=%p  arg=%p  caller=%p\n", cachep->ctor, objp, caller);
+		cachep->ctor(objp, cachep, 0);
+	}
 	prefetchw(objp);
 
 	return objp;
@@ -3457,8 +3662,9 @@
 		struct slab *slabp;
 
 		slabp = virt_to_slab(objp);
+		VALGRIND_MAKE_MEM_DEFINED(slabp, sizeof(*slabp));
 		l3 = cachep->nodelists[node];
-		list_del(&slabp->list);
+		slab_list_del(&slabp->list);
 		check_spinlock_acquired_node(cachep, node);
 		check_slabp(cachep, slabp);
 		slab_put_obj(cachep, slabp, objp, node);
@@ -3467,7 +3673,9 @@
 		check_slabp(cachep, slabp);
 
 		/* fixup slab chains */
+		VALGRIND_MAKE_MEM_DEFINED(slabp, sizeof(*slabp));
 		if (slabp->inuse == 0) {
+			VALGRIND_MAKE_MEM_DEFINED(l3, sizeof(*l3));
 			if (l3->free_objects > l3->free_limit) {
 				l3->free_objects -= cachep->num;
 				/* No need to drop any previously held
@@ -3478,15 +3686,16 @@
 				 */
 				slab_destroy(cachep, slabp);
 			} else {
-				list_add(&slabp->list, &l3->slabs_free);
+				slab_list_add(&slabp->list, &l3->slabs_free);
 			}
 		} else {
 			/* Unconditionally move a slab to the end of the
 			 * partial list on free - maximum time for the
 			 * other objects to be freed, too.
 			 */
-			list_add_tail(&slabp->list, &l3->slabs_partial);
+			slab_list_add_tail(&slabp->list, &l3->slabs_partial);
 		}
+		VALGRIND_MAKE_MEM_UNDEFINED(slabp, sizeof(*slabp));
 	}
 }
 
@@ -3502,6 +3711,7 @@
 #endif
 	check_irq_off();
 	l3 = cachep->nodelists[node];
+	VALGRIND_MAKE_MEM_DEFINED(l3, sizeof(*l3));
 	spin_lock(&l3->list_lock);
 	if (l3->shared) {
 		struct array_cache *shared_array = l3->shared;
@@ -3523,20 +3733,29 @@
 		int i = 0;
 		struct list_head *p;
 
+		VALGRIND_MAKE_MEM_DEFINED(l3, sizeof(*l3));
 		p = l3->slabs_free.next;
+		VALGRIND_MAKE_MEM_UNDEFINED(l3, sizeof(*l3));
+
 		while (p != &(l3->slabs_free)) {
 			struct slab *slabp;
 
 			slabp = list_entry(p, struct slab, list);
+			VALGRIND_MAKE_MEM_DEFINED(&slabp->inuse, sizeof(slabp->inuse));
 			BUG_ON(slabp->inuse);
+			VALGRIND_MAKE_MEM_UNDEFINED(&slabp->inuse, sizeof(slabp->inuse));
 
 			i++;
+			VALGRIND_MAKE_MEM_DEFINED(&p->next, sizeof(p->next));
 			p = p->next;
+			VALGRIND_MAKE_MEM_UNDEFINED(&p->next, sizeof(p->next));
 		}
+
 		STATS_SET_FREEABLE(cachep, i);
 	}
 #endif
 	spin_unlock(&l3->list_lock);
+	VALGRIND_MAKE_MEM_UNDEFINED(l3, sizeof(*l3));
 	ac->avail -= batchcount;
 	memmove(ac->entry, &(ac->entry[batchcount]), sizeof(void *)*ac->avail);
 }
@@ -3551,6 +3770,7 @@
 
 	check_irq_off();
 	objp = cache_free_debugcheck(cachep, objp, __builtin_return_address(0));
+	VALGRIND_FREELIKE_BLOCK(objp + obj_offset(cachep), 0);
 
 	if (cache_free_alien(cachep, objp))
 		return;
@@ -3574,9 +3794,12 @@
  * Allocate an object from this cache.  The flags are only relevant
  * if the cache has no available objects.
  */
-void *kmem_cache_alloc(struct kmem_cache *cachep, gfp_t flags)
+void *kmem_cache_alloc(struct kmem_cache *cachep, gfp_t flags, size_t size)
 {
-	return __cache_alloc(cachep, flags, __builtin_return_address(0));
+	void *const rv = __cache_alloc(cachep, flags, __builtin_return_address(0), size);
+//printf("kmem_cache_alloc pc=%p  size=%d\n", __builtin_return_address(0), size);
+//	VALGRIND_MALLOCLIKE_BLOCK(rv, size, 0, 0);
+	return rv;
 }
 EXPORT_SYMBOL(kmem_cache_alloc);
 
@@ -3588,11 +3811,14 @@
  * Allocate an object from this cache and set the allocated memory to zero.
  * The flags are only relevant if the cache has no available objects.
  */
-void *kmem_cache_zalloc(struct kmem_cache *cache, gfp_t flags)
+void *kmem_cache_zalloc(struct kmem_cache *cache, gfp_t flags, size_t size)
 {
-	void *ret = __cache_alloc(cache, flags, __builtin_return_address(0));
-	if (ret)
+	void *ret = __cache_alloc(cache, flags, __builtin_return_address(0), size);
+	if (ret) {
 		memset(ret, 0, obj_size(cache));
+//printf("kmem_cache_zalloc %p  %p\n", ret, __builtin_return_address(0));
+//		VALGRIND_MALLOCLIKE_BLOCK(ret, size, 0, 1);
+	}
 	return ret;
 }
 EXPORT_SYMBOL(kmem_cache_zalloc);
@@ -3642,8 +3868,10 @@
 #ifdef CONFIG_NUMA
 void *kmem_cache_alloc_node(struct kmem_cache *cachep, gfp_t flags, int nodeid)
 {
-	return __cache_alloc_node(cachep, flags, nodeid,
+	void *const rv = __cache_alloc_node(cachep, flags, nodeid,
 			__builtin_return_address(0));
+	VALGRIND_MALLOCLIKE_BLOCK(rv, 0,0,0);  // XXX 2007-12-17
+	return rv;
 }
 EXPORT_SYMBOL(kmem_cache_alloc_node);
 
@@ -3690,6 +3918,7 @@
 static __always_inline void *__do_kmalloc(size_t size, gfp_t flags,
 					  void *caller)
 {
+	void *rv;
 	struct kmem_cache *cachep;
 
 	/* If you want to save a few bytes .text space: replace
@@ -3700,7 +3929,10 @@
 	cachep = __find_general_cachep(size, flags);
 	if (unlikely(cachep == NULL))
 		return NULL;
-	return __cache_alloc(cachep, flags, caller);
+	rv = __cache_alloc(cachep, flags, caller, size);
+//printf("__do_kmalloc rv=%p  pc=%p\n", rv, caller);
+//	VALGRIND_MALLOCLIKE_BLOCK(rv, size, 0, 0);
+	return rv;
 }
 
 
@@ -3808,6 +4040,7 @@
 
 	if (unlikely(!objp))
 		return;
+//printf("kfree objp=%p\n", objp);
 	local_irq_save(flags);
 	kfree_debugcheck(objp);
 	c = virt_to_cache(objp);
@@ -3859,6 +4092,7 @@
 		}
 
 		l3 = cachep->nodelists[node];
+		if (l3) VALGRIND_MAKE_MEM_DEFINED(l3, sizeof(*l3));
 		if (l3) {
 			struct array_cache *shared = l3->shared;
 
@@ -3876,6 +4110,7 @@
 			l3->free_limit = (1 + nr_cpus_node(node)) *
 					cachep->batchcount + cachep->num;
 			spin_unlock_irq(&l3->list_lock);
+			VALGRIND_MAKE_MEM_UNDEFINED(l3, sizeof(*l3));
 			kfree(shared);
 			free_alien_cache(new_alien);
 			continue;
@@ -3968,6 +4203,8 @@
 		struct array_cache *ccold = new->new[i];
 		if (!ccold)
 			continue;
+//printf("do_tune_cpucache\n");
+		//VALGRIND_MALLOCLIKE_BLOCK(ccold, sizeof(*ccold), 0, 1);  // init
 		spin_lock_irq(&cachep->nodelists[cpu_to_node(i)]->list_lock);
 		free_block(cachep, ccold->entry, ccold->avail, cpu_to_node(i));
 		spin_unlock_irq(&cachep->nodelists[cpu_to_node(i)]->list_lock);
@@ -4084,7 +4321,7 @@
 		/* Give up. Setup the next iteration. */
 		goto out;
 
-	list_for_each_entry(searchp, &cache_chain, next) {
+	slab_list_for_each_entry(searchp, &cache_chain, next) {
 		check_irq_on();
 
 		/*
@@ -4102,6 +4339,7 @@
 		 * These are racy checks but it does not matter
 		 * if we skip one check or scan twice.
 		 */
+		VALGRIND_MAKE_MEM_DEFINED(l3, sizeof(*l3));
 		if (time_after(l3->next_reap, jiffies))
 			goto next;
 
@@ -4109,6 +4347,7 @@
 
 		drain_array(searchp, l3, l3->shared, 0, node);
 
+		VALGRIND_MAKE_MEM_DEFINED(l3, sizeof(*l3));
 		if (l3->free_touched)
 			l3->free_touched = 0;
 		else {
@@ -4119,6 +4358,7 @@
 			STATS_ADD_REAPED(searchp, freed);
 		}
 next:
+		VALGRIND_MAKE_MEM_UNDEFINED(l3, sizeof(*l3));
 		cond_resched();
 	}
 	check_irq_on();
@@ -4207,13 +4447,13 @@
 		check_irq_on();
 		spin_lock_irq(&l3->list_lock);
 
-		list_for_each_entry(slabp, &l3->slabs_full, list) {
+		slab_list_for_each_entry(slabp, &l3->slabs_full, list) {
 			if (slabp->inuse != cachep->num && !error)
 				error = "slabs_full accounting error";
 			active_objs += cachep->num;
 			active_slabs++;
 		}
-		list_for_each_entry(slabp, &l3->slabs_partial, list) {
+		slab_list_for_each_entry(slabp, &l3->slabs_partial, list) {
 			if (slabp->inuse == cachep->num && !error)
 				error = "slabs_partial inuse accounting error";
 			if (!slabp->inuse && !error)
@@ -4221,7 +4461,7 @@
 			active_objs += slabp->inuse;
 			active_slabs++;
 		}
-		list_for_each_entry(slabp, &l3->slabs_free, list) {
+		slab_list_for_each_entry(slabp, &l3->slabs_free, list) {
 			if (slabp->inuse && !error)
 				error = "slabs_free/inuse accounting error";
 			num_slabs++;
@@ -4333,7 +4573,7 @@
 	/* Find the cache in the chain of caches. */
 	mutex_lock(&cache_chain_mutex);
 	res = -EINVAL;
-	list_for_each_entry(cachep, &cache_chain, next) {
+	slab_list_for_each_entry(cachep, &cache_chain, next) {
 		if (!strcmp(cachep->name, kbuf)) {
 			if (limit < 1 || batchcount < 1 ||
 					batchcount > limit || shared < 0) {
@@ -4455,9 +4695,9 @@
 		check_irq_on();
 		spin_lock_irq(&l3->list_lock);
 
-		list_for_each_entry(slabp, &l3->slabs_full, list)
+		slab_list_for_each_entry(slabp, &l3->slabs_full, list)
 			handle_slab(n, cachep, slabp);
-		list_for_each_entry(slabp, &l3->slabs_partial, list)
+		slab_list_for_each_entry(slabp, &l3->slabs_partial, list)
 			handle_slab(n, cachep, slabp);
 		spin_unlock_irq(&l3->list_lock);
 	}
diff -ur linux-2.6.22.5-old/mm/slob.c linux-2.6.22.5/mm/slob.c
--- linux-2.6.22.5-old/mm/slob.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/mm/slob.c	2007-12-16 13:24:54.000000000 -0800
@@ -335,7 +335,7 @@
 
 void *kmem_cache_zalloc(struct kmem_cache *c, gfp_t flags)
 {
-	void *ret = kmem_cache_alloc(c, flags);
+	void *ret = kmem_cache_alloc(c, flags, sizeof(**ret));
 	if (ret)
 		memset(ret, 0, c->size);
 
diff -ur linux-2.6.22.5-old/mm/swap.c linux-2.6.22.5/mm/swap.c
--- linux-2.6.22.5-old/mm/swap.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/mm/swap.c	2007-12-12 09:57:04.000000000 -0800
@@ -191,6 +191,7 @@
 {
 	struct pagevec *pvec = &get_cpu_var(lru_add_active_pvecs);
 
+	VALGRIND_MAKE_MEM_DEFINED(page, sizeof(*page));
 	page_cache_get(page);
 	if (!pagevec_add(pvec, page))
 		__pagevec_lru_add_active(pvec);
diff -ur linux-2.6.22.5-old/net/bridge/br_fdb.c linux-2.6.22.5/net/bridge/br_fdb.c
--- linux-2.6.22.5-old/net/bridge/br_fdb.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/net/bridge/br_fdb.c	2007-12-16 13:25:05.000000000 -0800
@@ -320,7 +320,7 @@
 {
 	struct net_bridge_fdb_entry *fdb;
 
-	fdb = kmem_cache_alloc(br_fdb_cache, GFP_ATOMIC);
+	fdb = kmem_cache_alloc(br_fdb_cache, GFP_ATOMIC, sizeof(*fdb));
 	if (fdb) {
 		memcpy(fdb->addr.addr, addr, ETH_ALEN);
 		atomic_set(&fdb->use_count, 1);
diff -ur linux-2.6.22.5-old/net/core/dst.c linux-2.6.22.5/net/core/dst.c
--- linux-2.6.22.5-old/net/core/dst.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/net/core/dst.c	2007-12-16 14:18:36.000000000 -0800
@@ -125,7 +125,7 @@
 		if (ops->gc())
 			return NULL;
 	}
-	dst = kmem_cache_zalloc(ops->kmem_cachep, GFP_ATOMIC);
+	dst = kmem_cache_zalloc(ops->kmem_cachep, GFP_ATOMIC, sizeof(*dst));
 	if (!dst)
 		return NULL;
 	atomic_set(&dst->__refcnt, 0);
diff -ur linux-2.6.22.5-old/net/core/flow.c linux-2.6.22.5/net/core/flow.c
--- linux-2.6.22.5-old/net/core/flow.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/net/core/flow.c	2007-12-16 13:25:05.000000000 -0800
@@ -211,7 +211,7 @@
 		if (flow_count(cpu) > flow_hwm)
 			flow_cache_shrink(cpu);
 
-		fle = kmem_cache_alloc(flow_cachep, GFP_ATOMIC);
+		fle = kmem_cache_alloc(flow_cachep, GFP_ATOMIC, sizeof(*fle));
 		if (fle) {
 			fle->next = *head;
 			*head = fle;
diff -ur linux-2.6.22.5-old/net/core/neighbour.c linux-2.6.22.5/net/core/neighbour.c
--- linux-2.6.22.5-old/net/core/neighbour.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/net/core/neighbour.c	2007-12-16 14:18:59.000000000 -0800
@@ -254,7 +254,7 @@
 			goto out_entries;
 	}
 
-	n = kmem_cache_zalloc(tbl->kmem_cachep, GFP_ATOMIC);
+	n = kmem_cache_zalloc(tbl->kmem_cachep, GFP_ATOMIC, sizeof(*n));
 	if (!n)
 		goto out_entries;
 
diff -ur linux-2.6.22.5-old/net/core/skbuff.c linux-2.6.22.5/net/core/skbuff.c
--- linux-2.6.22.5-old/net/core/skbuff.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/net/core/skbuff.c	2007-12-16 14:18:12.000000000 -0800
@@ -154,7 +154,7 @@
 	cache = fclone ? skbuff_fclone_cache : skbuff_head_cache;
 
 	/* Get the HEAD */
-	skb = kmem_cache_alloc_node(cache, gfp_mask & ~__GFP_DMA, node);
+	skb = kmem_cache_alloc_node(cache, gfp_mask & ~__GFP_DMA, node, sizeof(*skb));
 	if (!skb)
 		goto out;
 
@@ -387,7 +387,7 @@
 		n->fclone = SKB_FCLONE_CLONE;
 		atomic_inc(fclone_ref);
 	} else {
-		n = kmem_cache_alloc(skbuff_head_cache, gfp_mask);
+		n = kmem_cache_alloc(skbuff_head_cache, gfp_mask, sizeof(*n));
 		if (!n)
 			return NULL;
 		n->fclone = SKB_FCLONE_UNAVAILABLE;
diff -ur linux-2.6.22.5-old/net/core/sock.c linux-2.6.22.5/net/core/sock.c
--- linux-2.6.22.5-old/net/core/sock.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/net/core/sock.c	2007-12-16 13:25:05.000000000 -0800
@@ -854,7 +854,7 @@
 	struct kmem_cache *slab = prot->slab;
 
 	if (slab != NULL)
-		sk = kmem_cache_alloc(slab, priority);
+		sk = kmem_cache_alloc(slab, priority, sizeof(*sk));
 	else
 		sk = kmalloc(prot->obj_size, priority);
 
diff -ur linux-2.6.22.5-old/net/dccp/ackvec.c linux-2.6.22.5/net/dccp/ackvec.c
--- linux-2.6.22.5-old/net/dccp/ackvec.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/net/dccp/ackvec.c	2007-12-16 13:25:05.000000000 -0800
@@ -153,7 +153,7 @@
 
 struct dccp_ackvec *dccp_ackvec_alloc(const gfp_t priority)
 {
-	struct dccp_ackvec *av = kmem_cache_alloc(dccp_ackvec_slab, priority);
+	struct dccp_ackvec *av = kmem_cache_alloc(dccp_ackvec_slab, priority, sizeof(**av));
 
 	if (av != NULL) {
 		av->dccpav_buf_head	= DCCP_MAX_ACKVEC_LEN - 1;
diff -ur linux-2.6.22.5-old/net/ipv4/fib_hash.c linux-2.6.22.5/net/ipv4/fib_hash.c
--- linux-2.6.22.5-old/net/ipv4/fib_hash.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/net/ipv4/fib_hash.c	2007-12-16 13:25:04.000000000 -0800
@@ -486,13 +486,13 @@
 		goto out;
 
 	err = -ENOBUFS;
-	new_fa = kmem_cache_alloc(fn_alias_kmem, GFP_KERNEL);
+	new_fa = kmem_cache_alloc(fn_alias_kmem, GFP_KERNEL, sizeof(*new_fa));
 	if (new_fa == NULL)
 		goto out;
 
 	new_f = NULL;
 	if (!f) {
-		new_f = kmem_cache_alloc(fn_hash_kmem, GFP_KERNEL);
+		new_f = kmem_cache_alloc(fn_hash_kmem, GFP_KERNEL, sizeof(*new_f));
 		if (new_f == NULL)
 			goto out_free_new_fa;
 
diff -ur linux-2.6.22.5-old/net/ipv4/fib_trie.c linux-2.6.22.5/net/ipv4/fib_trie.c
--- linux-2.6.22.5-old/net/ipv4/fib_trie.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/net/ipv4/fib_trie.c	2007-12-16 13:25:04.000000000 -0800
@@ -1208,7 +1208,7 @@
 			u8 state;
 
 			err = -ENOBUFS;
-			new_fa = kmem_cache_alloc(fn_alias_kmem, GFP_KERNEL);
+			new_fa = kmem_cache_alloc(fn_alias_kmem, GFP_KERNEL, sizeof(*new_fa));
 			if (new_fa == NULL)
 				goto out;
 
@@ -1255,7 +1255,7 @@
 		goto out;
 
 	err = -ENOBUFS;
-	new_fa = kmem_cache_alloc(fn_alias_kmem, GFP_KERNEL);
+	new_fa = kmem_cache_alloc(fn_alias_kmem, GFP_KERNEL, sizeof(*new_fa));
 	if (new_fa == NULL)
 		goto out;
 
diff -ur linux-2.6.22.5-old/net/ipv4/inet_hashtables.c linux-2.6.22.5/net/ipv4/inet_hashtables.c
--- linux-2.6.22.5-old/net/ipv4/inet_hashtables.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/net/ipv4/inet_hashtables.c	2007-12-16 14:19:33.000000000 -0800
@@ -31,7 +31,7 @@
 						 struct inet_bind_hashbucket *head,
 						 const unsigned short snum)
 {
-	struct inet_bind_bucket *tb = kmem_cache_alloc(cachep, GFP_ATOMIC);
+	struct inet_bind_bucket *tb = kmem_cache_alloc(cachep, GFP_ATOMIC, sizeof(*tb));
 
 	if (tb != NULL) {
 		tb->port      = snum;
diff -ur linux-2.6.22.5-old/net/ipv4/inetpeer.c linux-2.6.22.5/net/ipv4/inetpeer.c
--- linux-2.6.22.5-old/net/ipv4/inetpeer.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/net/ipv4/inetpeer.c	2007-12-16 13:25:04.000000000 -0800
@@ -395,7 +395,7 @@
 		return NULL;
 
 	/* Allocate the space outside the locked region. */
-	n = kmem_cache_alloc(peer_cachep, GFP_ATOMIC);
+	n = kmem_cache_alloc(peer_cachep, GFP_ATOMIC, sizeof(*n));
 	if (n == NULL)
 		return NULL;
 	n->v4daddr = daddr;
diff -ur linux-2.6.22.5-old/net/ipv4/inet_timewait_sock.c linux-2.6.22.5/net/ipv4/inet_timewait_sock.c
--- linux-2.6.22.5-old/net/ipv4/inet_timewait_sock.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/net/ipv4/inet_timewait_sock.c	2007-12-16 14:19:52.000000000 -0800
@@ -91,7 +91,7 @@
 {
 	struct inet_timewait_sock *tw =
 		kmem_cache_alloc(sk->sk_prot_creator->twsk_prot->twsk_slab,
-				 GFP_ATOMIC);
+				 GFP_ATOMIC, sizeof(*tw));
 	if (tw != NULL) {
 		const struct inet_sock *inet = inet_sk(sk);
 
diff -ur linux-2.6.22.5-old/net/ipv6/xfrm6_tunnel.c linux-2.6.22.5/net/ipv6/xfrm6_tunnel.c
--- linux-2.6.22.5-old/net/ipv6/xfrm6_tunnel.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/net/ipv6/xfrm6_tunnel.c	2007-12-16 13:25:05.000000000 -0800
@@ -180,7 +180,7 @@
 	spi = 0;
 	goto out;
 alloc_spi:
-	x6spi = kmem_cache_alloc(xfrm6_tunnel_spi_kmem, GFP_ATOMIC);
+	x6spi = kmem_cache_alloc(xfrm6_tunnel_spi_kmem, GFP_ATOMIC, sizeof(*x6spi));
 	if (!x6spi)
 		goto out;
 
diff -ur linux-2.6.22.5-old/net/netfilter/nf_conntrack_core.c linux-2.6.22.5/net/netfilter/nf_conntrack_core.c
--- linux-2.6.22.5-old/net/netfilter/nf_conntrack_core.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/net/netfilter/nf_conntrack_core.c	2007-12-16 13:25:05.000000000 -0800
@@ -608,7 +608,7 @@
 		goto out;
 	}
 
-	conntrack = kmem_cache_alloc(nf_ct_cache[features].cachep, GFP_ATOMIC);
+	conntrack = kmem_cache_alloc(nf_ct_cache[features].cachep, GFP_ATOMIC, sizeof(*conntrack));
 	if (conntrack == NULL) {
 		DEBUGP("nf_conntrack_alloc: Can't alloc conntrack from cache\n");
 		goto out;
diff -ur linux-2.6.22.5-old/net/netfilter/nf_conntrack_expect.c linux-2.6.22.5/net/netfilter/nf_conntrack_expect.c
--- linux-2.6.22.5-old/net/netfilter/nf_conntrack_expect.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/net/netfilter/nf_conntrack_expect.c	2007-12-16 13:25:05.000000000 -0800
@@ -197,7 +197,7 @@
 {
 	struct nf_conntrack_expect *new;
 
-	new = kmem_cache_alloc(nf_conntrack_expect_cachep, GFP_ATOMIC);
+	new = kmem_cache_alloc(nf_conntrack_expect_cachep, GFP_ATOMIC, sizeof(*new));
 	if (!new)
 		return NULL;
 
diff -ur linux-2.6.22.5-old/net/netfilter/xt_hashlimit.c linux-2.6.22.5/net/netfilter/xt_hashlimit.c
--- linux-2.6.22.5-old/net/netfilter/xt_hashlimit.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/net/netfilter/xt_hashlimit.c	2007-12-16 13:25:05.000000000 -0800
@@ -142,7 +142,7 @@
 		return NULL;
 	}
 
-	ent = kmem_cache_alloc(hashlimit_cachep, GFP_ATOMIC);
+	ent = kmem_cache_alloc(hashlimit_cachep, GFP_ATOMIC, sizeof(*ent));
 	if (!ent) {
 		if (net_ratelimit())
 			printk(KERN_ERR
diff -ur linux-2.6.22.5-old/net/netlink/af_netlink.c linux-2.6.22.5/net/netlink/af_netlink.c
--- linux-2.6.22.5-old/net/netlink/af_netlink.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/net/netlink/af_netlink.c	2007-12-16 14:32:43.000000000 -0800
@@ -927,7 +927,9 @@
 	struct hlist_node *node;
 	struct sock *sk;
 
+//printf("netlink_broadcast A skb=%p\n", skb);
 	skb = netlink_trim(skb, allocation);
+//printf("netlink_broadcast B skb=%p\n", skb);
 
 	info.exclude_sk = ssk;
 	info.pid = pid;
diff -ur linux-2.6.22.5-old/net/sctp/socket.c linux-2.6.22.5/net/sctp/socket.c
--- linux-2.6.22.5-old/net/sctp/socket.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/net/sctp/socket.c	2007-12-16 13:25:05.000000000 -0800
@@ -5401,7 +5401,7 @@
 {
 	struct sctp_bind_bucket *pp;
 
-	pp = kmem_cache_alloc(sctp_bucket_cachep, GFP_ATOMIC);
+	pp = kmem_cache_alloc(sctp_bucket_cachep, GFP_ATOMIC, sizeof(*pp));
 	SCTP_DBG_OBJCNT_INC(bind_bucket);
 	if (pp) {
 		pp->port = snum;
diff -ur linux-2.6.22.5-old/net/socket.c linux-2.6.22.5/net/socket.c
--- linux-2.6.22.5-old/net/socket.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/net/socket.c	2007-12-16 13:25:05.000000000 -0800
@@ -236,7 +236,7 @@
 {
 	struct socket_alloc *ei;
 
-	ei = kmem_cache_alloc(sock_inode_cachep, GFP_KERNEL);
+	ei = kmem_cache_alloc(sock_inode_cachep, GFP_KERNEL, sizeof(*ei));
 	if (!ei)
 		return NULL;
 	init_waitqueue_head(&ei->socket.wait);
diff -ur linux-2.6.22.5-old/net/sunrpc/rpc_pipe.c linux-2.6.22.5/net/sunrpc/rpc_pipe.c
--- linux-2.6.22.5-old/net/sunrpc/rpc_pipe.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/net/sunrpc/rpc_pipe.c	2007-12-16 13:25:04.000000000 -0800
@@ -143,7 +143,7 @@
 rpc_alloc_inode(struct super_block *sb)
 {
 	struct rpc_inode *rpci;
-	rpci = (struct rpc_inode *)kmem_cache_alloc(rpc_inode_cachep, GFP_KERNEL);
+	rpci = (struct rpc_inode *)kmem_cache_alloc(rpc_inode_cachep, GFP_KERNEL, sizeof(*rpci));
 	if (!rpci)
 		return NULL;
 	return &rpci->vfs_inode;
diff -ur linux-2.6.22.5-old/net/tipc/handler.c linux-2.6.22.5/net/tipc/handler.c
--- linux-2.6.22.5-old/net/tipc/handler.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/net/tipc/handler.c	2007-12-16 13:25:05.000000000 -0800
@@ -62,7 +62,7 @@
 	}
 
 	spin_lock_bh(&qitem_lock);
-	item = kmem_cache_alloc(tipc_queue_item_cache, GFP_ATOMIC);
+	item = kmem_cache_alloc(tipc_queue_item_cache, GFP_ATOMIC, sizeof(*item));
 	if (!item) {
 		err("Signal queue out of memory\n");
 		spin_unlock_bh(&qitem_lock);
diff -ur linux-2.6.22.5-old/net/xfrm/xfrm_input.c linux-2.6.22.5/net/xfrm/xfrm_input.c
--- linux-2.6.22.5-old/net/xfrm/xfrm_input.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/net/xfrm/xfrm_input.c	2007-12-16 13:25:04.000000000 -0800
@@ -27,7 +27,7 @@
 {
 	struct sec_path *sp;
 
-	sp = kmem_cache_alloc(secpath_cachep, GFP_ATOMIC);
+	sp = kmem_cache_alloc(secpath_cachep, GFP_ATOMIC, sizeof(*sp));
 	if (!sp)
 		return NULL;
 
diff -ur linux-2.6.22.5-old/security/keys/key.c linux-2.6.22.5/security/keys/key.c
--- linux-2.6.22.5-old/security/keys/key.c	2007-08-22 16:23:54.000000000 -0700
+++ linux-2.6.22.5/security/keys/key.c	2007-12-16 13:23:38.000000000 -0800
@@ -280,7 +280,7 @@
 	}
 
 	/* allocate and initialise the key and its description */
-	key = kmem_cache_alloc(key_jar, GFP_KERNEL);
+	key = kmem_cache_alloc(key_jar, GFP_KERNEL, sizeof(*key));
 	if (!key)
 		goto no_memory_2;
 
